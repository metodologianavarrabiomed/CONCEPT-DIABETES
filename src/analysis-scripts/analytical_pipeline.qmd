---
title: "CONCEPT DIABETES: Analytical pipeline"
author: Unidad de metodología Navarrabiomed-HUN-UPNA; IdiSNA 
editor: visual
crossref:
  lof-title: "List of Figures"
  fig-labels: arabic    # (default is arabic)
  tbl-labels: arabic    # (default is arabic)
  subref-labels: alpha a # (default is alpha a)
#date: 
# bibliography: 
format: 
  html:
    embed-resources: true
    toc: true
    toc-depth: 4
    highlight-style: pygments
    code-fold: true
    html-math-method: katex
execute: 
  warning: false
  cache: false
---

```{css, echo = FALSE}
.justify {
  text-align: justify !important
}
```

## 1. Introduction

### 1.1. Project description
::: {.justify}
CONCEPT-DIABETES is part of CONCEPT, a coordinated research project initiative that was born under the umbrella of REDISSEC, the Spanish Research Network on Health Services Research and Chronic Conditions [www.redissec.com], and which continues under RICAPPS the Spanish Research Network on Chronicity, Primary Care, and Health Promotion [www.ricapps.es]. This project aims at analyzing chronic care effectiveness and efficiency in a number of cohorts built on real world data (RWD). In the specific case of CONCEPT-DIABETES, the focus will be on assessing the effectiveness of a set of clinical practice actions and quality improvement strategies at different levels (patient-level, health-care provider level and health system level) on the management and health results of patients with type 2 diabetes (T2D) using process mining methodology.

It is a population-based retrospective observational study centered on all T2D patients diagnosed in four Regional Health Services within the Spanish National Health Service, that includes information from all their contacts with the health services using the electronic medical record systems including Primary Care data, Specialist Care data, Hospitalizations, Urgent Care data, Pharmacy Claims, and also other registers such as the mortality and the population register. We will assess to what extent recommended interventions from evidence-based guidelines are implemented in real life and which are their effects on health outcomes. Process mining methods will be used to analyze the data, and comparison with standard methods will be also conducted.
::: 
### 1.2. Cohort definition
::: {.justify}
The cohort is defined as patients with type 2 diabetes:

-   Inclusion criteria: Patients that, at 2017-01-01 or during the follow-up from 2017-01-01 to 2022-12-31, had active health card (active TIA - tarjeta sanitaria activa) and one of the inclusion codes given in the 'inclusion code list ('T90' if CIAP-2, '250' if 'CIE-9CM' or 'E11' if CIE-10-ES).

-   Exclusion criteria: Patients that had none of the exclusion codes given in the exclusion codes list ('T89' if CIAP-2, '250.01' if CIE-9CM, '250.03' if CIE-9CM, '250.11' if CIE-9CM, '250.13' if CIE-9CM, '250.21' if CIE-9CM, '250.23' if CIE-9CM, '250.31' if CIE-9CM, '250.33' if CIE-9CM, '250.41' if CIE-9CM, '250.43' if CIE-9CM, '250.51' if CIE-9CM, '250.53' if CIE-9CM, '250.61' if CIE-9CM, '250.63' if CIE-9CM, '250.71' if CIE-9CM, '250.73' if CIE-9CM, '250.81' if CIE-9CM, '250.83' if CIE-9CM, '250.91' if CIE-9CM, '250.93' if CIE-9CM or 'E10' if CIE-10-ES) during their follow-up or patients with no contact with the health system from 2017-01-01 to 2022-12-31.

-   Study period: 2017-01-01 until 2022-12-31.
::: 
### 1.3. Process indicators
::: {.justify}
Process indicators are guidelines' measures that indicate whether the guidelines are being implemented as planned. Different studies pay special attention to them. First, process indicators are essential for assessing the three dimensions of healthcare quality: effectiveness, safety, and patient-centeredness. They are measured relatively easily and often do not require risk-adjustment, making their interpretation straightforward. Poor performance on process indicators can be directly attributed to the actions of healthcare providers, providing a clear indication for improvement, such as better adherence to clinical guidelines. Moreover, process indicators allow for the identification of areas for quality improvement, which is crucial in the complex healthcare environment. These indicators cover a wide range of health factors and help focus resources and efforts to improve the health and well-being of the population. Therefore, the attention given to health process indicators is justified by their crucial role in evaluating and improving healthcare quality and population health.
::: 
### 1.4. Treatment guidelines
::: {.justify}
One of the main intermediate outcome indicators to which clinical guidelines pay special attention is a good glycaemic control, since its absence is clearly related to micro and macro-vascular complications. In clinical practice, sub-optimal glycaemic control can be mainly attributed to two reasons: the patients' non-adherence to prescribed treatment; and the healthcare providers' clinical or therapeutic guidelines' non-adherence.

Treatment decisions are based on glycated hemoglobin measurements. In this context the redGDPS foundation provides DM2 treatment algorithm, a diagram that aims to help professionals to quickly and easily choose the most appropriate treatment for people with diabetes.
::: 
<object data="./Algoritmo_DM2_ENG_2023.pdf" type="application/pdf" width="800px" height="400px">

<embed src="./Algoritmo_DM2_ENG_2023.pdf">

<p>DM2 treatment algorithm</p>

</embed>

</object>

## 2. Running code

### 2.1. Libraries

The used python libraries are:

```{python}
#| label: Load python packages (to show)
#| eval: FALSE
#| echo: TRUE
#| warning: FALSE
#| output: FALSE
import sys
import pm4py, subprocess
import pandas as pd
import numpy as np
import itertools
import matplotlib.pyplot as plt
import textdistance
import gensim.corpora as corpora
from tqdm import trange, tqdm
from scipy.spatial.distance import squareform
from scipy.cluster.hierarchy import fcluster, linkage, dendrogram
from sklearn.cluster import AgglomerativeClustering 
from sklearn.feature_extraction.text import TfidfVectorizer
from yellowbrick.cluster import KElbowVisualizer
from pm4py.objects.petri_net.obj import PetriNet, Marking
from pm4py.visualization.petri_net import visualizer
from gensim.models import LdaModel
from datetime import  datetime, timedelta
from dateutil.relativedelta import relativedelta
import duckdb
import re
import logging
```

```{python}
#| label: Load python packages
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
import sys
import pm4py, subprocess
import pandas as pd
import numpy as np
import itertools
import matplotlib.pyplot as plt
import textdistance
import gensim.corpora as corpora
from tqdm import trange, tqdm
from scipy.spatial.distance import squareform
from scipy.cluster.hierarchy import fcluster, linkage, dendrogram
from sklearn.cluster import AgglomerativeClustering 
from sklearn.feature_extraction.text import TfidfVectorizer
from yellowbrick.cluster import KElbowVisualizer
from pm4py.objects.petri_net.obj import PetriNet, Marking
from pm4py.visualization.petri_net import visualizer
from gensim.models import LdaModel
from datetime import  datetime, timedelta
from dateutil.relativedelta import relativedelta
import duckdb
import re
import logging
import seaborn as sns
from rapidfuzz.distance import Levenshtein
```

The used R libraries are:

```{r}
#| label: Load r libraries
#| warning: FALSE

library(tidyverse)
library(lubridate)
library(jsonlite)
library(ggplot2)
library(bupaR)
library(processmapR)
library(dplyr)
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
library(here)
library(survival)
library(lcmm)
library(coxme)
library(muhaz)
library(ggfortify)
library(bayestestR)
library(purrr)
library(duckdb)
library(logger)
library(finalfit)
library(flextable)
library(knitr)
library(Comorbilidades)
library(lme4)
```

### 2.2. Data preprocessing
::: {.justify}
First of all, it is important to prepare correctly the data for the analysis. The next function creates some sql views that are going to be useful later:
::: 
```{python, warning: FALSE}
#| label: data preprocess
#| warning: FALSE
def general_preprocess(con):
    '''
    Generating  views
    Args:
        con : db connector variable
    '''

    con.sql("CREATE OR REPLACE VIEW cmbd_incidents_view AS SELECT * FROM main.cmbd \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date >='2017-01-01')")
    con.sql("CREATE OR REPLACE VIEW ss_use_incidents_view AS SELECT * FROM main.ss_use \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date >='2017-01-01')")
    con.sql("CREATE OR REPLACE VIEW param_incidents_view_ AS SELECT DISTINCT * FROM main.param \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date >='2017-01-01') \
                AND (param_value!=0 OR param_name!='bmi')")
    con.sql("CREATE OR REPLACE VIEW param_incidents_view AS \
            SELECT DISTINCT patient_id,param_name,MAX(param_value) AS param_value,param_date\
        FROM param_incidents_view_ GROUP BY patient_id,param_name,param_date")
    con.sql("CREATE OR REPLACE VIEW param_cat_incidents_view AS SELECT DISTINCT * FROM main.param_cat \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date >='2017-01-01')")
    con.sql("CREATE OR REPLACE VIEW patient_incidents_view AS SELECT *,\
            FLOOR(DATEDIFF('day',month_nac,DATE '2017-01-01') / 365.25) \
                AS 'age', \
            FLOOR(DATEDIFF('day',month_nac, dx_date) / 365.25) \
                AS 'age_dx', \
            DATE_ADD(month_nac, INTERVAL 75 YEAR) AS 'turn_to_75', \
            DATE_ADD(month_nac, INTERVAL 65 YEAR) AS 'turn_to_65' \
                FROM main.patient WHERE patient_id IN (SELECT patient_id \
                        FROM main.patient WHERE dx_date >='2017-01-01')")
    con.sql("CREATE OR REPLACE VIEW comorb_incidents_view AS SELECT * FROM main.comorb \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date >='2017-01-01') AND \
            comorb_date_ini <= (SELECT dx_date FROM patient_incidents_view \
          WHERE  patient_incidents_view.patient_id = main.comorb.patient_id)")
    con.sql("CREATE OR REPLACE VIEW treat_incidents_view AS SELECT * FROM main.treat \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date >='2017-01-01')")
    con.sql("CREATE OR REPLACE VIEW exams_incidents_view AS SELECT * FROM main.exams \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date >='2017-01-01')")
                
    con.sql("CREATE OR REPLACE VIEW param_incidents_view_age_date AS SELECT param_incidents_view.patient_id, \
            param_name, param_value, param_date, turn_to_65, turn_to_75 FROM \
                param_incidents_view LEFT JOIN patient_incidents_view ON \
         param_incidents_view.patient_id = patient_incidents_view.patient_id")

    con.sql("CREATE OR REPLACE VIEW cmbd_incidents_postdx_view AS \
            SELECT * FROM cmbd_incidents_view \
                WHERE admission_date > (SELECT dx_date \
                                        FROM patient_incidents_view \
    WHERE patient_incidents_view.patient_id = cmbd_incidents_view.patient_id) \
                    AND contact_type=1 AND contact_program=1")
                    
    to_list = lambda l: "('"+"','".join(l)+"')" 
    trastornos_mentales = "F10.20, F11.20, F12.20, F13.20, F14.20, F15.20, F16.20, F19.20, F20.0, F20.1, F20.2, F20.5, F20.81, F20.89, F20.9, F21, F22, F23, F24, F25.9, F28, F29, F30.10, F30.11, F30.12, F30.13, F30.2, F30.3, F30.4, F30.8, F31.10, F31.11, F31.12, F31.13, F31.2, F31.30, F31.31, F31.32, F31.4, F31.5, F31.60, F31.61, F31.62, F31.63, F31.64, F31.73, F31.74, F31.75, F31.76, F31.77, F41.8, F31.78, F31.81, F31.9, F32.0, F32.1, F32.2, F32.3, F32.4, F32.5, F32.8, F33.0, F33.1, F33.2, F33.3, F33.41, F33.42, F33.9, F34.0, F34.1, F34.8, F39, F40.01, F40.02, F40.10, F40.218, F40.240, F40.241, F40.8, F40.9, F41.0, F41.1, F41.9, F42, F44.0, F44.1, F44.4, F44.6, F44.81, F44.89, F44.9, F45.0, F45.1, F45.21, F45.22, F45.8, F45.9, F48.1, F48.8, F48.9, F60.0, F60.1,F60.2, F60.3, F60.4, F60.5, F60.6, F60.7, F60.81, F60.89, F60.9, F68.11, F68.12, F68.8,F84.0, F84.3, F84.5, F84.8, F84.9, F99".replace(' ','').split(',')
    embarazo = ['O00-O9A']
    diabetes = "E10.10, E10.11, E10.641, E11.00, E11.01, E11.10, E11.11, E11.641".replace(' ','').split(',')
    epoc1 = "J41.0, J41.1, J41.8, J42, J43.0, J43.1, J43.2, J43.8, J43.9, J44.0, J44.1, J44.9, J47.0, J47.1, J47.9 J20.0, J20.1, J20.2, J20.3, J20.4, J20.5, J20.6, J20.7, J20.8, J20.9, J40".replace(' ','').split(',')
    epoc1_if2 = "J41.0, J41.1, J41.8, J42, J43.0, J43.1, J43.2, J43.8, J43.9, J44.0, J44.1, J44.9, J45.20, J45.21, J45.22, J45.30, J45.31, J45.32, J45.40, J45.41, J45.42, J45.50, J45.51, J45.52, J45.901, J45.902, J45.909, J45.990, J45.991, J45.998, J47.0, J47.1, J47.9".replace(' ','').split(',')
    epoc2 = "J96.00, J96.01, J96.02, J96.20, J96.21, J96.22".replace(' ','').split(',')
    epoc2_if2 = " J44.0, J44.1, J47.0, J47.1, J47.9".replace(' ','').split(',')
    ICC = "I09.81, I11.0, I13.0, I13.2, I50.1, I50.20, I50.21, I50.22, I50.23, I50.30, I50.31, I50.32, I50.33, I50.40, I50.41, I50.42, I50.43, I50.9".replace(' ','').split(',')
    fibrosis = "E84.0, E84.11, E84.19, E84.8, E84.9, J84.83, J84.841, J84.842, J84.843, J84.848, P27.0, P27.1, P27.8, P27.9, Q25.4, Q25.45, Q25.47, Q25.48, Q25.5, Q25.6, Q25.71, Q25.72, Q25.73, Q31.1, Q31.2, Q31.3, Q31.5, Q31.8, Q31.9, Q32.0, Q32.1, Q32.2, Q32.3, Q32.4, Q33.0, Q33.1, Q33.2, Q33.3, Q33.4, Q33.5, Q33.6, Q33.8, Q33.9, Q34.0, Q34.1, Q34.8, Q34.9, Q39.0, Q39.1, Q39.2, Q39.3, Q39.4, Q89.3".replace(' ','').split(',')
    EI = "I21.01, I21.02, I21.09, I21.11, I21.19, I21.21, I21.29, I21.3, I21.4, I21.9, I21.A1, I21.A9, I22.0, I22.1, I22.2, I22.8, I22.9, I20.0, I20.1, I20.8, I20.9, I24.0, I24.8".replace(' ','').split(',')
    IR = "I12.0, I12.9, I13.10, I13.11, N17.0, N17.1, N17.2, N17.8, N17.9, N18.1, N18.2, N18.3, N18.4, N18.5, N18.6, N18.9, N19".replace(' ','').split(',')
    deshidratacion = "E87.0, E87.1, E86.0, E86.1, E86.9".replace(' ','').split(',') 
    asma = "J45.20, J45.21, J45.22, J45.31, J45.32, J45.41, J45.42, J45.51, J45.52, J45.901, J45.902, J45.990, J45.991, J45.998, J96.0".replace(' ','').split(',')
    asmaif2 = "J45.20, J45.21, J45.22, J45.31, J45.32, J45.41, J45.42, J45.51, J45.52, J45.901, J45.902, J45.990, J45.991, J45.998".replace(' ','').split(',')
    epoc_er = "J98.8, J98.9, J84.10, J41.1, J41.8, J42, J43, J44.0, J44.1, J44.9, J47".replace(' ','').split(',')
    con.sql(f"CREATE OR REPLACE VIEW cmbd_incidents_postdx_first_view AS \
            SELECT patient_id, admission_date, diagnosis1_code FROM (SELECT *,\
                      ROW_NUMBER() OVER(PARTITION BY patient_id \
                                        ORDER BY admission_date) AS rn \
                          FROM cmbd_incidents_postdx_view WHERE \
                (diagnosis1_code IN {to_list(diabetes)} AND \
                 diagnosis2_code NOT IN {to_list(embarazo+trastornos_mentales)}) \
                OR (diagnosis1_code IN {to_list(epoc1)} AND \
                 diagnosis2_code IN {to_list(epoc1_if2)}) \
                OR (diagnosis1_code IN {to_list(epoc2)} AND \
                 diagnosis2_code IN {to_list(epoc2_if2)}) \
                OR (diagnosis1_code IN {to_list(ICC)} AND \
                 diagnosis2_code IN {to_list(embarazo+EI+IR)}) \
                OR (diagnosis1_code IN {to_list(deshidratacion)} AND \
                 diagnosis2_code NOT IN {to_list(embarazo+trastornos_mentales)})\
                OR (diagnosis1_code IN {to_list(asma)} AND \
                    diagnosis2_code IN {to_list(asmaif2)} AND \
                 diagnosis2_code NOT IN {to_list(ICC+fibrosis+embarazo+trastornos_mentales+epoc_er)})\
                ) t WHERE rn = 1;") 
                
    con.sql("CREATE OR REPLACE VIEW param_incidents_predx_view AS SELECT * FROM (\
            SELECT * FROM (SELECT patient_id, param_name, param_value, param_date \
                            FROM param_incidents_view) sub \
                WHERE param_date <= (SELECT dx_date FROM patient_incidents_view \
                    WHERE patient_incidents_view.patient_id = sub.patient_id));")
        
    con.sql("CREATE OR REPLACE VIEW param_incidents_predx_last_view AS \
            SELECT patient_id, param_name, param_date, param_value \
                FROM (SELECT patient_id, param_name, param_date, param_value,\
                      ROW_NUMBER() OVER(PARTITION BY patient_id, param_name \
                                        ORDER BY param_date DESC) AS rn \
                          FROM param_incidents_predx_view \
                          WHERE param_value!=999) t WHERE rn = 1;")

    con.sql("CREATE OR REPLACE VIEW param_incidents_postdx_view AS SELECT * FROM (\
            SELECT * FROM (SELECT patient_id, param_name, param_value, param_date \
                            FROM param_incidents_view) sub \
                WHERE param_date > (SELECT dx_date FROM patient_incidents_view \
                    WHERE patient_incidents_view.patient_id = sub.patient_id));")
        
    con.sql("CREATE OR REPLACE VIEW param_incidents_postdx_first_view AS \
            SELECT patient_id, param_name, param_date, param_value \
                FROM (SELECT patient_id, param_name, param_date, param_value,\
                      ROW_NUMBER() OVER(PARTITION BY patient_id, param_name \
                                        ORDER BY param_date ASC) AS rn \
                          FROM param_incidents_postdx_view \
                          WHERE param_value!=999) t WHERE rn = 1;")
                    
    con.sql("CREATE OR REPLACE VIEW param_cat_incidents_predx_view AS SELECT * FROM (\
            SELECT * FROM (SELECT patient_id, param_cat_name, param_cat_value, param_cat_date \
                            FROM param_cat_incidents_view) sub \
                WHERE param_cat_date <= (SELECT dx_date FROM patient_incidents_view \
                    WHERE patient_incidents_view.patient_id = sub.patient_id));")
    con.sql("CREATE OR REPLACE VIEW param_cat_incidents_predx_last_view AS \
            SELECT patient_id, param_cat_name, param_cat_date, param_cat_value \
                FROM (SELECT patient_id, param_cat_name, param_cat_date, param_cat_value,\
                      ROW_NUMBER() OVER(PARTITION BY patient_id, param_cat_name \
                                        ORDER BY param_cat_date DESC) AS rn \
                          FROM param_cat_incidents_predx_view) t WHERE rn = 1;") 
                    
    con.sql("CREATE OR REPLACE VIEW param_prevalents_pre_view AS \
            SELECT DISTINCT patient_id, param_name, param_value, param_date FROM main.param \
             WHERE param_date < '2017-01-01' AND patient_id IN (\
                SELECT patient_id FROM main.patient WHERE dx_date < '2017-01-01')")
    con.sql("CREATE OR REPLACE VIEW param_prevalents_pre_last_view AS \
            SELECT patient_id, param_name, param_date, param_value \
                FROM (SELECT patient_id, param_name, param_date, param_value,\
                      ROW_NUMBER() OVER(PARTITION BY patient_id, param_name \
                                        ORDER BY param_date DESC) AS rn \
                          FROM param_prevalents_pre_view \
                              WHERE param_value!=999) t WHERE rn = 1;")
                    
    con.sql("CREATE OR REPLACE VIEW param_cat_prevalents_pre_view AS \
            SELECT DISTINCT * FROM main.param_cat \
             WHERE param_cat_date < '2017-01-01' AND patient_id IN (\
                SELECT patient_id FROM main.patient WHERE dx_date < '2017-01-01')")
    con.sql("CREATE OR REPLACE VIEW param_cat_prevalents_pre_last_view AS \
            SELECT patient_id, param_cat_name, param_cat_date, param_cat_value \
                FROM (SELECT patient_id, param_cat_name, param_cat_date, param_cat_value,\
                      ROW_NUMBER() OVER(PARTITION BY patient_id, param_cat_name \
                                        ORDER BY param_cat_date DESC) AS rn \
                          FROM param_cat_prevalents_pre_view) t WHERE rn = 1;") 
 

```

### 2.3. Event log creation

#### 2.3.1. Healthcare event log
::: {.justify}
For using process mining an event log is needed. Healthcare event log is made in this section with the services visited by incident patients.
::: 
```{python}
#| label: Healtcare eventlog creation

def evlog_services(con):
    '''Generation of service visits eventlog

    Args:
      con : db connector variable
    '''
    con.sql("CREATE OR REPLACE VIEW s_order AS \
            SELECT visit_service, \
                ROW_NUMBER() OVER (ORDER BY visit_service) AS order \
                    FROM  (SELECT DISTINCT visit_service \
                           FROM ss_use_incidents_view)")
    con.sql("CREATE OR REPLACE VIEW  ss_order AS \
            SELECT sv.*,so.order \
            FROM ss_use_incidents_view sv \
            LEFT JOIN s_order so ON sv.visit_service = so.visit_service")
    con.sql("CREATE OR REPLACE VIEW  service AS \
            SELECT *, ROW_NUMBER() OVER (ORDER BY patient_id,date,Event) AS actins \
            FROM (SELECT DISTINCT patient_id, \
                  CAST(visit_date AS TIMESTAMP) +  (ss_order.order || 'minutes')::INTERVAL AS date, \
                visit_service AS Event\
                    FROM ss_order)") 
    con.sql("CREATE OR REPLACE VIEW service_sexage AS \
            SELECT s.patient_id,s.date,s.Event,s.actins,\
                p.sex,p.age_dx,p.dx_date FROM service s \
                    LEFT JOIN patient_incidents_view p \
                        ON s.patient_id = p.patient_id \
                            WHERE s.date>=p.dx_date")
    con.sql("CREATE OR REPLACE VIEW service_sexage_cond AS \
            SELECT ss.patient_id,ss.date AS date_,ss.Event,ss.actins,\
                ss.sex,ss.age_dx,p.type,p.date AS end_date \
                    FROM service_sexage ss \
                        LEFT JOIN patient_condition p \
                            ON ss.patient_id = p.patient_id \
                                WHERE ss.date<=p.date")
    con.sql("CREATE OR REPLACE VIEW ss_log AS \
            SELECT patient_id AS ID,Event,actins,sex,age_dx,type,end_date, \
                'start' AS cycle, \
                CAST(date_ AS TIMESTAMP) AS date,\
                FROM service_sexage_cond \
            UNION ALL SELECT patient_id AS ID,Event,actins,sex,age_dx,type,end_date, \
                'end' AS cycle, \
                CAST(date_ AS TIMESTAMP) + INTERVAL 10 SECOND AS date,\
                FROM service_sexage_cond")

```

#### 2.3.2. Process indicators' event log
::: {.justify}
With the objective of studying process indicators a function to make a process indicators' event log is coded below. There, in addition to laboratory measures and realized exams, three artificial events have been included to aid the analysis: 'INI' event denotes each patient's diabetes diagnosis date, 'yFIN' events indicate the end of each annual interval and 'FIN' event is the date of the end of the last completed annual interval.
::: 
```{python, warning: FALSE}
#| label: process indicators' event log creation
#| warning: FALSE
def evlog_process_ind(con):
    '''Generation of process indicators' eventlog

    Args:
      con : db connector variable
    '''
    
    con.sql("CREATE OR REPLACE VIEW pre_process_ind AS SELECT *,'start' AS cycle,\
                ROW_NUMBER() OVER (ORDER BY patient_id,date) AS actins \
            FROM (SELECT DISTINCT patient_id,'hba1c' AS event, \
            CAST(param_date AS TIMESTAMP) + INTERVAL 60 SECOND AS date \
            FROM param_incidents_view WHERE param_name = 'hba1c' \
            UNION ALL SELECT DISTINCT patient_id,'col' AS event, \
                    CAST(param_date AS TIMESTAMP) + INTERVAL 120 SECOND AS date \
            FROM param_incidents_view WHERE param_name IN  ('col','hdl','ldl') \
            UNION ALL SELECT DISTINCT patient_id,'blood_p' AS event, \
                    CAST(param_date AS TIMESTAMP) + INTERVAL 180 SECOND AS date \
            FROM param_incidents_view WHERE param_name IN  ('sbp','dbp') \
            UNION ALL SELECT DISTINCT patient_id,'indalbcr' AS event, \
                    CAST(param_date AS TIMESTAMP) + INTERVAL 240 SECOND AS date \
            FROM param_incidents_view WHERE param_name='indalbcr' \
            UNION ALL SELECT DISTINCT patient_id,'filtglom' AS event, \
                    CAST(param_date AS TIMESTAMP) + INTERVAL 300 SECOND AS date \
            FROM param_incidents_view WHERE param_name='filtglom' \
            UNION ALL SELECT DISTINCT patient_id,'bmi' AS event, \
                    CAST(param_date AS TIMESTAMP) + INTERVAL 360 SECOND AS date \
            FROM param_incidents_view WHERE param_name IN ('bmi','weight') \
            UNION ALL SELECT DISTINCT patient_id,'ocular_exam' AS event, \
                    CAST(test_date AS TIMESTAMP) + INTERVAL 420 SECOND AS date \
            FROM exams_incidents_view \
            WHERE test_name IN ('ocular_exam_PC','ocular_exam_ophthalmologist') \
            UNION ALL SELECT DISTINCT patient_id,'foot_exam' AS event, \
                    CAST(test_date AS TIMESTAMP) + INTERVAL 480 SECOND AS date \
            FROM exams_incidents_view WHERE test_name='foot_exam' \
            UNION ALL SELECT patient_id,'INI' AS event, \
                    CAST(dx_date AS TIMESTAMP) AS date \
            FROM patient_incidents_view \
            UNION ALL SELECT patient_id, 'yFIN' AS event,\
                    CAST(dx_date AS TIMESTAMP) + INTERVAL 365 DAYS AS date \
            FROM patient_incidents_view \
            UNION ALL SELECT patient_id, 'yFIN' AS event,\
                    CAST(dx_date AS TIMESTAMP) + INTERVAL 730 DAYS AS date \
            FROM patient_incidents_view \
            UNION ALL SELECT patient_id, 'yFIN' AS event,\
                    CAST(dx_date AS TIMESTAMP) + INTERVAL 1095 DAYS AS date \
            FROM patient_incidents_view \
            UNION ALL SELECT patient_id, 'yFIN' AS event,\
                    CAST(dx_date AS TIMESTAMP) + INTERVAL 1461 DAYS AS date \
            FROM patient_incidents_view \
            UNION ALL SELECT patient_id, 'yFIN' AS event,\
                    CAST(dx_date AS TIMESTAMP) + INTERVAL 1826 DAYS AS date \
            FROM patient_incidents_view \
            UNION ALL SELECT patient_id, 'FIN' AS event,\
                    CAST(COALESCE(deregistration_date,'2023-01-01') AS TIMESTAMP) AS date \
            FROM patient_incidents_view)") 
    
    
    
    
    con.sql("CREATE OR REPLACE TABLE process_ind AS SELECT a.* FROM pre_process_ind a \
            JOIN (SELECT patient_id, MIN(date) as ini_date,MAX(date) as fin_date \
            FROM pre_process_ind d WHERE event IN ('INI', 'yFIN') AND \
                date<(SELECT c.date FROM pre_process_ind c \
                      WHERE c.event = 'FIN' AND c.patient_id = d.patient_id) \
            GROUP BY patient_id) b ON a.patient_id = b.patient_id \
            WHERE (a.date BETWEEN b.ini_date AND b.fin_date) OR a.event = 'FIN'")
    con.sql("CREATE OR REPLACE TABLE process_ind1 AS SELECT * FROM \
            (WITH RankedActions AS (SELECT patient_id, date, event,\
                    ROW_NUMBER() OVER (PARTITION BY patient_id ORDER BY date) AS rn \
                        FROM process_ind WHERE event = 'yFIN') \
             SELECT DISTINCT A.* FROM process_ind A \
                 JOIN RankedActions R ON A.patient_id = R.patient_id WHERE \
                     R.rn = 1 AND (A.date <= R.date OR A.event = 'FIN'))")  
    con.sql("CREATE OR REPLACE TABLE process_ind2 AS SELECT * FROM \
            (WITH RankedActions AS (SELECT patient_id, date, event,\
                    ROW_NUMBER() OVER (PARTITION BY patient_id ORDER BY date) AS rn \
                        FROM process_ind WHERE event = 'yFIN') \
             SELECT DISTINCT A.* FROM process_ind A \
                 JOIN RankedActions R ON A.patient_id = R.patient_id WHERE \
                     R.rn = 2 AND (A.date <= R.date OR A.event = 'FIN'))")        
    con.sql("CREATE OR REPLACE TABLE process_ind3 AS SELECT * FROM \
            (WITH RankedActions AS (SELECT patient_id, date, event,\
                    ROW_NUMBER() OVER (PARTITION BY patient_id ORDER BY date) AS rn \
                        FROM process_ind WHERE event = 'yFIN') \
             SELECT DISTINCT A.* FROM process_ind A \
                 JOIN RankedActions R ON A.patient_id = R.patient_id WHERE \
                     R.rn = 3 AND (A.date <= R.date OR A.event = 'FIN'))")        
    con.sql("CREATE OR REPLACE TABLE process_ind4 AS SELECT * FROM \
            (WITH RankedActions AS (SELECT patient_id, date, event,\
                    ROW_NUMBER() OVER (PARTITION BY patient_id ORDER BY date) AS rn \
                        FROM process_ind WHERE event = 'yFIN') \
             SELECT DISTINCT A.* FROM process_ind A \
                 JOIN RankedActions R ON A.patient_id = R.patient_id WHERE \
                     R.rn = 4 AND (A.date <= R.date OR A.event = 'FIN'))")        
    con.sql("CREATE OR REPLACE TABLE process_ind5 AS SELECT * FROM \
            (WITH RankedActions AS (SELECT patient_id, date, event,\
                    ROW_NUMBER() OVER (PARTITION BY patient_id ORDER BY date) AS rn \
                        FROM process_ind WHERE event = 'yFIN') \
             SELECT DISTINCT A.* FROM process_ind A \
                 JOIN RankedActions R ON A.patient_id = R.patient_id WHERE \
                     R.rn = 5 AND (A.date <= R.date OR A.event = 'FIN'))") 
        
```

#### 2.3.3. Treatment event log
::: {.justify}
The sort of functions below take data model's treatment and parameter tables to create an event log of glycated hemoglobin measures and treatment of patients. Glycated hemoglobin measurement events are divided into two different states, those that have a value smaller than "L" and the others. L's value depends on patient's diabetes duration, age and comorbilities and complications. Therefore with the help of expert clinicians we decided that L would take the following values:

-   L=7 if age\<75 and no cardiovascular disease, heart failure, chronic kidney disease or fragility.
-   L=8 if age\<65 and any cardiovascular disease, heart failure, chronic kidney disease or fragility.
-   L=8.5 if else.

As they are measures these events do not have any duration. In the case of treatments on the other hand a duration period exists. For treatments, events definition is based on drugs prescriptions if exists or dispensing dates and a fixed period time if else. Functions below make event logs with the previous considerations. Treatment analysis of this document is thought to do by the predominant clinical condition of patients according to DM2 treatment algorithm. In other words, patients are grouped by their predominant clinical condition and the analysis is realized independently to each group.
::: 
```{python, warning: FALSE}
#| label: treatments' event log creation
#| warning: FALSE
logging.basicConfig(level=logging.INFO)
def separate_patients_by_condition(con):
    '''
    Filtering data by predominant clinical condition according to redGDPS
    Args:
        con : db connector variable
    Return:
        presc_data_p (float): percentage of not null data in prescription dates
        
    https://www.sciencedirect.com/science/article/pii/S1751991821000176?via%3Dihub#tbl0015
    https://www.sanidad.gob.es/estadEstudios/estadisticas/estadisticas/estMinisterio/SIAP/map_cie9mc_cie10_ciap2.htm
    
    https://cienciadedatosysalud.org/wp-content/uploads/Metodologia_Atlas_Prescripcion_enero_2023-1.pdf
    '''
    cvd_code_list = ['K74','K75','K76','K89','K90','K91','K92']
    hf = 'K77'
    ckd = 'U99.01'
    ob = "T82"

    to_list = lambda l: "('"+"','".join(l)+"')"     
                    
                    
    presc_data_p = con.sql(f" SELECT (COUNT(prescription_date_ini)) / COUNT(*) \
                           AS p FROM treat_incidents_view").fetchall()[0][0]
    cie9_df = pd.read_csv('./CIE9.csv').rename(columns={'CIE9':'CIE',
                                                        'BDCAP':'CIAP'})
    cie9_df['comorb_codif'] = 'ICD9'
    cie10_df = pd.read_csv('./CIE10.csv').rename(columns={'CIE10':'CIE',
                                                          'BDCAP':'CIAP'})
    cie10_df['comorb_codif'] = 'ICD10'
    cie2ciap = pd.concat([cie9_df[['comorb_codif','CIE','CIAP']],
                          cie10_df[['comorb_codif','CIE','CIAP']]])
    con.sql("CREATE OR REPLACE VIEW comorb_incidents_view_all_following \
            AS SELECT * FROM main.comorb \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date >='2017-01-01')")
    con.sql("CREATE OR REPLACE VIEW comorb_incidents_ciap_view AS \
            SELECT * FROM comorb_incidents_view_all_following \
                LEFT JOIN cie2ciap \
                    ON comorb_incidents_view_all_following.comorb_codif = cie2ciap.comorb_codif \
                        AND comorb_incidents_view_all_following.comorb_code = cie2ciap.CIAP")
    con.sql("CREATE OR REPLACE VIEW comorb_incidents_active_view AS SELECT *, \
            CASE WHEN comorb_codif = 'CIAP2' THEN comorb_code ELSE CIAP END AS CIAP2 \
                FROM comorb_incidents_ciap_view WHERE comorb_date_end IS NULL;")

    # Which is the predominal clinical condition previous to 2017-01-01?
    f_list = set()
    ob_list = set()        
    ckd_list = set()        
    hf_list = set()        
    cvd_list = set()        

    to_cvd_change_list = cvd_code_list
    to_hf_change_list = [hf]
    to_ckd_change_list = [ckd,'filtglom']
    to_f_change_list = ['f_date']
    to_ob_change_list = [ob,'bmi>=30']
    
    
    from_cvd_change_list = ['death']
    from_hf_change_list = from_cvd_change_list+to_cvd_change_list
    from_ckd_change_list = from_hf_change_list+to_hf_change_list
    from_f_change_list = from_ckd_change_list+to_ckd_change_list
    from_ob_change_list = from_f_change_list+to_f_change_list+['bmi<30']
    from_else_change_list = from_ob_change_list[:-1]+to_ob_change_list
    
    relevance_order = pd.DataFrame()
    relevance_order['code'] = from_ob_change_list+to_ob_change_list+['end']
    relevance_order['order'] = range(len(relevance_order))

    
       
    # https://ukkidney.org/health-professionals/information-resources/uk-eckd-guide/ckd-stages
    # Include obesity and kcd detection by parameters values                             
    param_filt = con.sql("SELECT * FROM param_incidents_view \
                         WHERE param_name = 'filtglom' AND param_value<60;"
                         ).df().sort_values(['patient_id','param_date'])
    param_filt['time_diff'] = param_filt.groupby(
        'patient_id')['param_date'].diff()
    df_filt = param_filt[param_filt['time_diff'] < pd.Timedelta(days=90)
                           ].drop_duplicates(subset='patient_id',keep='first')[
                               ['patient_id','param_date','param_name']
                               ].rename(columns={
                                   'param_name':'code',
                                   'param_date':'admission_date'})
    con.sql("CREATE OR REPLACE VIEW comorb_incidents_long_view AS SELECT DISTINCT *,\
            COALESCE(t.order, 404) AS relevance FROM\
            (SELECT patient_id, comorb_date_ini AS admission_date, CIAP2 AS code \
                FROM comorb_incidents_active_view \
            UNION ALL SELECT patient_id, admission_date, code FROM df_filt \
            UNION ALL SELECT patient_id, turn_to_75 AS admission_date, 'f_date' \
                AS code FROM patient_incidents_view WHERE turn_to_75<'2023-01-01'\
            UNION ALL SELECT patient_id, death_date AS admission_date, 'death' \
                AS code FROM patient_incidents_view WHERE death_date IS NOT NULL\
            UNION ALL SELECT patient_id, DATE '2023-01-01' AS admission_date, 'end' \
                AS code FROM patient_incidents_view\
            UNION ALL SELECT patient_id,param_date AS admission_date, \
        CASE WHEN param_value < 30 THEN 'bmi<30' ELSE 'bmi>=30' END AS code \
            FROM param_incidents_predx_last_view WHERE param_name = 'bmi' \
            UNION ALL SELECT patient_id, param_date AS admission_date, \
        CASE WHEN param_value < 30 THEN 'bmi<30' ELSE 'bmi>=30' END AS code \
            FROM param_incidents_view sub WHERE param_name = 'bmi' \
                AND  param_date > (SELECT dx_date FROM patient_incidents_view \
                                   WHERE patient_incidents_view.patient_id = sub.patient_id)) v \
                LEFT JOIN relevance_order t ON v.code=t.code;")
    
    f_list.update(set(con.sql("SELECT DISTINCT patient_id \
                              FROM patient_incidents_view WHERE turn_to_75<=dx_date"
                              ).df()['patient_id']))
        
    ob_list.update(set(con.sql("SELECT DISTINCT patient_id \
                               FROM param_incidents_predx_last_view sub \
                                   WHERE param_name = 'bmi' AND param_value>=30"
                                   ).df()['patient_id']))
    #Include patients with bmi>=30 in the first measure of bmi without having it predx
    ob_list.update(set(con.sql(
        f"SELECT DISTINCT patient_id \
        FROM param_incidents_postdx_first_view sub \
        WHERE param_name = 'bmi' AND param_value>=30 \
            AND patient_id NOT IN (SELECT DISTINCT patient_id \
                                    FROM param_incidents_predx_last_view \
                                        WHERE param_name='bmi');"
                ).df()['patient_id']))
                
    ckd_list.update(set(con.sql(f"SELECT DISTINCT patient_id \
                           FROM comorb_incidents_long_view sub \
                               WHERE code IN {to_list(to_ckd_change_list)} \
                                   AND admission_date <= (SELECT dx_date \
                        FROM patient_incidents_view \
                            WHERE patient_incidents_view.patient_id = sub.patient_id);"
                            ).df()['patient_id']))        
    hf_list.update(set(con.sql(f"SELECT DISTINCT patient_id \
                           FROM comorb_incidents_long_view sub \
                               WHERE code IN {to_list(to_hf_change_list)} \
                                   AND admission_date <= (SELECT dx_date \
                        FROM patient_incidents_view \
                            WHERE patient_incidents_view.patient_id = sub.patient_id);"
                            ).df()['patient_id']))        
    cvd_list.update(set(con.sql(f"SELECT DISTINCT patient_id \
                           FROM comorb_incidents_long_view sub \
                               WHERE code IN {to_list(to_cvd_change_list)} \
                                   AND admission_date <= (SELECT dx_date \
                        FROM patient_incidents_view \
                            WHERE patient_incidents_view.patient_id = sub.patient_id);"
                            ).df()['patient_id']))        
      
    
    cvd_list = list(cvd_list)
    hf_list = list(hf_list.difference(cvd_list))
    ckd_list = list(ckd_list.difference(cvd_list+hf_list))
    f_list = list(f_list.difference(cvd_list+hf_list+ckd_list))
    ob_list = list(ob_list.difference(cvd_list+hf_list+ckd_list+f_list))
    else_list = list(set(con.sql("SELECT DISTINCT patient_id \
                                 FROM patient_incidents_view"
                                 ).df()['patient_id']
                         ).difference(cvd_list+hf_list+ckd_list+f_list+ob_list))
               
    # When is a change on predominant clinical condition made?  
    con.sql(f"CREATE OR REPLACE VIEW comorb_incidents_long_view_dx AS SELECT * \
            FROM comorb_incidents_long_view sub \
                WHERE admission_date > (SELECT dx_date \
                    FROM patient_incidents_view \
                        WHERE patient_incidents_view.patient_id = sub.patient_id);")

    query_function =  lambda cond: "(WITH rankedevents_*** AS (\
        SELECT patient_id,code,admission_date,ROW_NUMBER() \
          OVER(PARTITION BY patient_id ORDER BY admission_date,relevance) AS event_rank \
              FROM comorb_incidents_long_view_dx WHERE  patient_id IN {to_list(***_list)} \
                  AND code IN {to_list(from_***_change_list)} ) \
            SELECT patient_id, '***' AS type,code, admission_date AS date \
                FROM rankedevents_*** WHERE  event_rank=1 AND date<'2023-01-01') \
                                    UNION ALL (WITH rankedevents__*** AS (\
        SELECT patient_id,code,admission_date,ROW_NUMBER() \
          OVER(PARTITION BY patient_id ORDER BY admission_date) AS event_rank \
              FROM comorb_incidents_long_view_dx WHERE  patient_id IN {to_list(***_list)} \
                  AND code IN {to_list(['end']+from_***_change_list)} ) \
            SELECT patient_id, '***' AS type,code, admission_date AS date \
                FROM rankedevents__*** WHERE  event_rank=1 AND code='end')\
                ".replace('***',cond)
    con.sql(eval('f"CREATE OR REPLACE TABLE patient_condition AS {}"'.format(' UNION ALL '.join(
        [query_function(cond) for cond in ['cvd','hf','ckd','f','ob','else']]))))

    con.sql(f"CREATE OR REPLACE VIEW patient_condition_translation AS \
          SELECT patient_id,type AS initial_status,code, \
          CASE WHEN code='end' THEN type \
          WHEN code='bmi<30' THEN 'else' \
          WHEN code IN {to_list(to_ob_change_list)} THEN 'ob' \
          WHEN code='f_date' THEN 'f' \
          WHEN code IN {to_list(to_ckd_change_list)} THEN 'ckd' \
          WHEN code IN {to_list(to_hf_change_list)} THEN 'hf' \
          WHEN code IN {to_list(to_cvd_change_list)} THEN 'cvd'\
          WHEN code='death' THEN code \
          END AS final_status, \
          DATEDIFF('day',dx_date,date) AS duration,date \
          FROM (SELECT pc.*,pi.dx_date \
          FROM patient_condition pc LEFT JOIN patient_incidents_view pi ON \
          pc.patient_id=pi.patient_id)") 
    con.sql("CREATE OR REPLACE VIEW patient_condition_hosp AS \
        SELECT p.patient_id,p.initial_status,p.final_status, \
        CASE WHEN p.date <= COALESCE(c.admission_date,'2042-12-31') \
        THEN p.date ELSE c.admission_date END AS date, \
        CASE WHEN p.date < COALESCE(c.admission_date,'2042-12-31') \
        THEN 'cond' ELSE 'hosp' END AS cause \
        FROM patient_condition_translation p \
            LEFT JOIN cmbd_incidents_postdx_first_view c \
                ON p.patient_id = c.patient_id")
    return presc_data_p

def evlog_creation_by_prescriptions(con,
                                 cond,
                                 code2drug_info_path='./diabetes_drugs.csv'):
    '''Preprocessing and event log obtention with prescriptions
  
    Args:
      con : db connector variable
      cond (str): predominal clinical condition's code
      code2drug_info_path (str): drugs' and their codes' info's table's path
  
    ADNI: ANTIDIABETICOS NO INSULINICOS
  
    The treatment of type 2 diabetes mellitus with ADNI includes a wide range of 
    drugs which, depending on their drugs which, according to their mechanisms of 
    action, can be grouped as follows: 
     Increased endogenous insulin sensitivity:
        o Biguanides: metformin (MET).
        o Thiazolidinediones: pioglitazone (PIO).
     Increased endogenous insulin secretion/release:
        o Sulfonylureas (SU).
        o Meglitinides: repaglinide (REP)
     Reduction of digestive glucose absorption:
        o Alpha-glucosidase inhibitors.
        o Vegetable fiber and derivatives.
     Incretin effect enhancers.
        o Inhibitors of DPP-4 (iDPP-4).
        o GLP-1 analogues (aGLP-1).
     Inhibitors of renal glucose reuptake
        o SGLT-2 inhibitors (iSGLP-2)

    '''
    fin_date = con.sql(f"SELECT patient_id,date FROM patient_condition \
                       WHERE type = '{cond}'").df()
    dx_date = con.sql(f"SELECT patient_id, dx_date FROM  patient_incidents_view \
                      WHERE patient_id IN (SELECT patient_id \
                         FROM patient_condition \
                             WHERE patient_condition.type = '{cond}')").df()
    dx_date = dict(zip(dx_date.patient_id,dx_date.dx_date))
    fin_date = dict(zip(fin_date.patient_id,fin_date.date))
    code2drug = pd.read_csv(code2drug_info_path,index_col=0).to_dict()
    code2drug_f = lambda atc: code2drug.get(atc,{'class':'NONE'}
                                           ).get('class','NONE2'
                                                 ).replace('+','&')
    treat_df = con.sql(f"SELECT * FROM treat_incidents_view \
                       WHERE patient_id IN (SELECT patient_id \
                                            FROM patient_condition \
                                                WHERE patient_condition.type = '{cond}') \
                           AND substring(atc_code,1,3) = 'A10' \
                           AND prescription_date_ini IS NOT NULL").df()
    treat_df['Event'] = treat_df['atc_code'].apply(code2drug_f)
    treat_df = treat_df[~treat_df['Event'].isin(['NONE','NONE2'])
                        ].drop_duplicates(subset=['patient_id',
                                                  'prescription_date_ini',
                                                  'prescription_date_end',
                                                  'Event'])
    treat_df['actins'] = range(len(treat_df))
    treat_df_start = treat_df[['patient_id','prescription_date_ini',
                              'Event','actins']].rename(columns = 
                                       {'prescription_date_ini':'date'})
    treat_df_end = treat_df[['patient_id','prescription_date_end',
                              'Event','actins']].rename(columns = 
                                       {'prescription_date_end':'date'})
    
    treat_df_start['cycle'] = 'start'
    treat_df_end['cycle'] = 'end'
    treat_df_end['date'] = treat_df_end['date'].fillna(
        datetime.strptime('2023-01-01', "%Y-%m-%d")).apply(
    lambda x: min([x,datetime.strptime('2023-01-01', "%Y-%m-%d")])-timedelta(days=1))
            
    act_n = max(treat_df['actins'])
    if cond in ['cvd','hf','ckd','f']:
        param_df = con.sql(f"SELECT patient_id,param_date AS date, \
                           CASE WHEN param_value < {8} THEN 'HBA<L' \
                               WHEN param_value >= {8} AND param_value < {8.5} \
                                   AND param_date < turn_to_65 THEN 'HBA>L' \
                               WHEN param_value >= {8} AND param_value < {8.5} \
                                   AND param_date >= turn_to_65 THEN 'HBA<L' \
                               ELSE 'HBA>L' END AS Event,\
                           ROW_NUMBER() OVER (ORDER BY param_date) + {act_n} AS actins\
                               FROM param_incidents_view_age_date \
                                   WHERE patient_id IN (SELECT patient_id \
                                    FROM patient_condition \
                                        WHERE patient_condition.type = '{cond}') \
                                    AND param_name = 'hba1c' \
                                    AND param_value IS NOT NULL \
                                    AND param_date IS NOT NULL").df()
    else:
        param_df = con.sql(f"SELECT patient_id,param_date AS date, \
                           CASE WHEN param_value < {7} THEN 'HBA<L' \
                               WHEN param_value >= {7} AND param_value < {8.5} \
                                   AND param_date < turn_to_75 THEN 'HBA>L' \
                               WHEN param_value >= {7} AND param_value < {8.5} \
                                   AND param_date >= turn_to_75 THEN 'HBA<L' \
                               ELSE 'HBA>L' END AS Event,\
                           ROW_NUMBER() OVER (ORDER BY param_date) + {act_n} AS actins\
                               FROM param_incidents_view_age_date \
                                   WHERE patient_id IN (SELECT patient_id \
                                    FROM patient_condition \
                                        WHERE patient_condition.type = '{cond}') \
                                    AND param_name = 'hba1c' \
                                    AND param_value IS NOT NULL \
                                    AND param_date IS NOT NULL").df()        

    param_df_start = param_df.copy()
    param_df_start['cycle'] = 'start'
    param_df_end = param_df.copy()
    param_df_end['cycle'] = 'end'

    df = pd.concat([param_df_start,treat_df_start,param_df_end,treat_df_end]
                   ).drop_duplicates()
    
    df = df.sort_values(by = ['patient_id','date','Event','cycle'],
                        ascending = [True,True,True,False])
    df.index = range(len(df))
    patient_list = list(set(df['patient_id']))
    df['nid'] = [patient_list.index(df['patient_id'][n]) for n in range(len(df))]

    #####################################################################
    
    event_log = dict()
    event_log['patient_id'] = []
    event_log['date'] = []
    event_log['nid'] = []
    event_log['Event'] = []
    event_log['cycle'] = []
    days_after_m = 5
    id_list = list(set(df['patient_id']))
    events = list(set([drug for e in set(df['Event']) for drug in e.split('&')]))
    hba0, hba1 = events.index('HBA<L'), events.index('HBA>L')
    row = len(events)
    no_hba = [i for i in range(row) if i not in [hba0,hba1]]
    for id in tqdm(id_list):
        df_id = df[df['patient_id']==id]
        nid = id_list.index(id)
        actins = set(df_id['actins'])
        date_min = min([min(set(df_id['date'])),dx_date[id]])
        date_max =  fin_date.get(id,datetime.strptime('2023-01-01', "%Y-%m-%d"))
        dd = [date_min + timedelta(days=x) for x in range(
          (date_max-date_min).days + 1)]
        col = len(dd)
        ev_status = np.zeros((row,col))
        for act in actins:
            ini = list(df_id['date'][np.logical_and(df_id['actins']==act,
                                                  df_id['cycle']=='start')])[0]
            if ini>dd[-1]:
                continue
            ev =  list(df_id['Event'][df_id['actins']==act])[0]            
            fin = list(df_id['date'][np.logical_and(df_id['actins']==act,
                                                  df_id['cycle']=='end')])[0]
            fin = min(fin,dd[-1])
            ev_cols = [events.index(ev_) for ev_ in ev.split('&')]
            ev_status = change_matrix_values(ev_status,ev_cols,
                                             list(range(dd.index(ini),
                                                        dd.index(fin)+1)),1)
                            
        measures = list(np.concatenate((ev_status[hba0,:].nonzero()[0],
                                        ev_status[hba1,:].nonzero()[0])))
        ev_status = ev_status.astype(int)              
        #delete treatments in measure events        
        ev_status = change_matrix_values(ev_status,no_hba,measures,0)
        #correction to eliminate events after hemoglobin measurement that are
        #the continuation of the previous treatment and not the new treatment.
        #Example: If a patient has 'A' treatment and because of hemoglobin's
        #         measure they change their treatment to 'B', originally their
        #         trace could appear as A>measure>A>B, but the true trace
        #         should be A>measure>B. Therefore, in a fixed period time 
        #         after each measurement 'days_after_m', if we detect that 
        #         mistake we delete it. 

        for j in measures:
            if ev_status.shape[1]<=j+1 or days_after_m<3:
                continue
            first_col = ev_status[:,j+1]
            dif_col = np.where(np.any(ev_status[:, j+2:j+days_after_m]!=
                                      first_col[:, np.newaxis],
                                      axis=0))[0]
          
            if  (dif_col.size > 0) and (not
                    np.array_equal(ev_status[:,j-1],
                                    ev_status[:,j+dif_col[0]+2])) and (
                    np.array_equal(ev_status[:,j-1],
                                    ev_status[:,j+1])):
                ev_status = change_matrix_values(ev_status,no_hba,
                                                  range(j+1,j+dif_col[0]+2),0)

          
        col = dd.index(dx_date[id])
        col_0 = dd.index(dx_date[id])
        col_max = dd.index(fin_date[id]) if str(fin_date[id])!='nan' else len(dd)
        min_change_days = 7
        while col<col_max-1:
            if not np.array_equal(ev_status[:,col],ev_status[:,col+1]):
                ev = col2treat(ev_status,events,col_0)
                if  ('HBA' not in ev and col-col_0<min_change_days):
                    col+=1
                    col_0 = col
                    continue
                event_log['patient_id'].extend([id,id])
                event_log['date'].extend([dd[col_0],dd[col]])
                event_log['Event'].extend([ev,ev])
                event_log['nid'].extend([nid,nid])
                event_log['cycle'].extend(['start','end'])
                
                col+=1
                col_0 = col
            else:
                col+=1
        ev = col2treat(ev_status,events,col_0)
        if 'HBA' in ev or col-col_0>=min_change_days:
            event_log['patient_id'].extend([id,id])
            event_log['date'].extend([dd[col_0],dd[col]])
            event_log['Event'].extend([ev,ev])
            event_log['nid'].extend([nid,nid])
            event_log['cycle'].extend(['start','end'])
    
            
    evlog = pd.DataFrame.from_dict(event_log)   
    evlog = evlog.sort_values(['patient_id','date'])
    evlog.rename(columns = {'patient_id':'ID'}, inplace = True)
    evlog.index = range(len(evlog))
    evlog['cycle'] = ['start','end']*int(0.5*len(evlog))
    evlog['actins'] = [n//2 for n in range(len(evlog))]
    con.sql(f"CREATE OR REPLACE TABLE evlog_raw_{cond} AS SELECT * FROM evlog")
 
def evlog_creation_by_dispensations(con, 
                              cond,
                              code2drug_info_path='./diabetes_drugs.csv',
                              nac_path='./Nomenclator_de_Facturacion.csv'):
    '''Preprocessing and event log obtention with dispensations

    Args:
      con : db connector variable
      cond (str): predominal clinical condition's code
      code2drug_info_path (str): drugs' and their codes' info's table's path
      nac_path (str): drugs' and their containers' info's table's path
    
    ADNI: ANTIDIABETICOS NO INSULINICOS
    
    The treatment of type 2 diabetes mellitus with ADNI includes a wide range of 
    drugs which, depending on their drugs which, according to their mechanisms of 
    action, can be grouped as follows: 
     Increased endogenous insulin sensitivity:
        o Biguanides: metformin (MET).
        o Thiazolidinediones: pioglitazone (PIO).
     Increased endogenous insulin secretion/release:
        o Sulfonylureas (SU).
        o Meglitinides: repaglinide (REP)
     Reduction of digestive glucose absorption:
        o Alpha-glucosidase inhibitors.
        o Vegetable fiber and derivatives.
     Incretin effect enhancers.
        o Inhibitors of DPP-4 (iDPP-4).
        o GLP-1 analogues (aGLP-1).
     Inhibitors of renal glucose reuptake
        o SGLT-2 inhibitors (iSGLP-2)
    
    '''

    treat_min_days = 2
    days_error = 60-treat_min_days
    days_after_m = 7
    fin_date = con.sql(f"SELECT patient_id,date FROM patient_condition \
                       WHERE type = '{cond}'").df()
    dx_date = con.sql(f"SELECT patient_id, dx_date FROM  patient_incidents_view \
                      WHERE patient_id IN (SELECT patient_id \
                         FROM patient_condition \
                             WHERE patient_condition.type = '{cond}')").df()
    dx_date = dict(zip(dx_date.patient_id,dx_date.dx_date))
    fin_date = dict(zip(fin_date.patient_id,fin_date.date))
    code2drug = pd.read_csv(code2drug_info_path,index_col=0).to_dict()
    code2drug_f = lambda atc: code2drug.get(atc,{'class':'NONE'}
                                           ).get('class','NONE2'
                                                 ).replace('+','&')
    treat_df = con.sql(f"SELECT * FROM treat_incidents_view \
                       WHERE patient_id IN (SELECT patient_id \
                                            FROM patient_condition \
                                                WHERE patient_condition.type = '{cond}') \
                           AND substring(atc_code,1,3) = 'A10' \
                           AND dispensing_date IS NOT NULL").df()
    treat_df['Event'] = treat_df['atc_code'].apply(code2drug_f)
    treat_df = treat_df[~treat_df['Event'].isin(['NONE','NONE2'])]
    nac_dict = nac2comprimidos(nac_path,set(treat_df['nac_code']))
    treat_df['nac_code'] = treat_df['nac_code'].apply(
        lambda x: nac_dict.get(x,days_error))
    treat_df['containers_number'] = treat_df['containers_number'].fillna(1)
    treat_df['nac_code'] = treat_df['nac_code']*treat_df['containers_number']
    treat_df = treat_df[['patient_id','dispensing_date','Event','nac_code']
                        ].rename(columns = {'dispensing_date':'date'}
                                 ).sort_values(by = ['patient_id','date' ],
                      ascending = [True, True])
                     
    if cond in ['cvd','hf','ckd','f']:
        df = con.sql(f"SELECT *, 'start' AS cycle,\
                     ROW_NUMBER() OVER (ORDER BY patient_id, date) AS actins \
                         FROM (SELECT patient_id,param_date AS date, \
                           CASE WHEN param_value < {8} THEN 'HBA<L' \
                                WHEN param_value >= {8} AND param_value < {8.5} \
                                   AND param_date < turn_to_65 THEN 'HBA>L' \
                                WHEN param_value >= {8} AND param_value < {8.5} \
                                   AND param_date >= turn_to_65 THEN 'HBA<L' \
                                ELSE 'HBA>L' END AS Event, 0 AS nac_code\
                               FROM param_incidents_view_age_date \
                                   WHERE patient_id IN (SELECT patient_id \
                                    FROM patient_condition \
                                        WHERE patient_condition.type = '{cond}') \
                                       AND param_name = 'hba1c' \
                                    AND param_value IS NOT NULL \
                                    AND param_date IS NOT NULL\
                                UNION ALL SELECT * FROM treat_df) \
                    UNION ALL SELECT patient_id, date, Event, nac_code, 'end' AS cycle,\
                     ROW_NUMBER() OVER (ORDER BY patient_id, param_date) AS actins \
                         FROM (SELECT patient_id,param_date AS date, param_date,\
                           CASE WHEN param_value < {8} THEN 'HBA<L' \
                                WHEN param_value >= {8} AND param_value < {8.5} \
                                   AND param_date < turn_to_65 THEN 'HBA>L' \
                                WHEN param_value >= {8} AND param_value < {8.5} \
                                   AND param_date >= turn_to_65 THEN 'HBA<L' \
                                ELSE 'HBA>L' END AS Event, 0 AS nac_code\
                               FROM param_incidents_view_age_date \
                                   WHERE patient_id IN (SELECT patient_id \
                                    FROM patient_condition \
                                        WHERE patient_condition.type = '{cond}') \
                                       AND param_name = 'hba1c' \
                                    AND param_value IS NOT NULL \
                                    AND param_date IS NOT NULL\
                                UNION ALL SELECT patient_id,\
                                CAST(date AS TIMESTAMP)+INTERVAL {treat_min_days} \
                                    DAYS AS date, date AS param_date, \
                                        Event, nac_code FROM treat_df)").df()
    else:
        df = con.sql(f"SELECT *, 'start' AS cycle,\
                     ROW_NUMBER() OVER (ORDER BY patient_id, date) AS actins \
                         FROM (SELECT patient_id,param_date AS date, \
                           CASE WHEN param_value < {7} THEN 'HBA<L' \
                                WHEN param_value >= {7} AND param_value < {8.5} \
                                   AND param_date < turn_to_75 THEN 'HBA>L' \
                                WHEN param_value >= {7} AND param_value < {8.5} \
                                   AND param_date >= turn_to_75 THEN 'HBA<L' \
                                ELSE 'HBA>L' END AS Event, 0 AS nac_code\
                               FROM param_incidents_view_age_date \
                                   WHERE patient_id IN (SELECT patient_id \
                                    FROM patient_condition \
                                        WHERE patient_condition.type = '{cond}') \
                                       AND param_name = 'hba1c' \
                                    AND param_value IS NOT NULL \
                                UNION ALL SELECT * FROM treat_df) \
                    UNION ALL SELECT patient_id, date, Event, nac_code, 'end' AS cycle,\
                     ROW_NUMBER() OVER (ORDER BY patient_id, param_date) AS actins \
                         FROM (SELECT patient_id,param_date AS date, param_date,\
                           CASE WHEN param_value < {7} THEN 'HBA<L' \
                                WHEN param_value >= {7} AND param_value < {8.5} \
                                   AND param_date < turn_to_75 THEN 'HBA>L' \
                                WHEN param_value >= {7} AND param_value < {8.5} \
                                   AND param_date >= turn_to_75 THEN 'HBA<L' \
                                ELSE 'HBA>L' END AS Event, 0 AS nac_code\
                               FROM param_incidents_view_age_date \
                                   WHERE patient_id IN (SELECT patient_id \
                                    FROM patient_condition \
                                        WHERE patient_condition.type = '{cond}') \
                                       AND param_name = 'hba1c' \
                                    AND param_value IS NOT NULL \
                                UNION ALL SELECT patient_id,\
                                CAST(date AS TIMESTAMP)+INTERVAL {treat_min_days} \
                                    DAYS AS date, date AS param_date, \
                                        Event, nac_code FROM treat_df)").df()

    patient_list = list(set(df['patient_id']))
    df['nid'] = [patient_list.index(df['patient_id'][n]) for n in range(len(df))] 
    df = df.sort_values(by = ['patient_id', 'actins','cycle'],
                        ascending = [True, True, False])
    df.index = range(len(df))
    
    #####################################################################

    event_log = dict()
    event_log['patient_id'] = []
    event_log['date'] = []
    event_log['nid'] = []
    event_log['Event'] = []
    event_log['cycle'] = []
    
    id_list = list(set(df['patient_id']))
    events = list(set([drug for e in set(df['Event']) for drug in e.split('&')]))
    hba0, hba1 = events.index('HBA<L'), events.index('HBA>L')
    row = len(events)
    no_hba = [i for i in range(row) if i not in [hba0,hba1]]
    for id in tqdm(id_list):
        df_id = df[df['patient_id']==id]
        nid = id_list.index(id)
        actins = set(df_id['actins'])
        date_min = min([min(set(df_id['date'])),dx_date[id]])
        date_max =  max(set(df_id['date']))
        if str(fin_date[id])!='nan':
            date_max = max([date_max,fin_date[id]])
        else:
            date_max = max([date_max,datetime.strptime('2023-01-01', "%Y-%m-%d")])
        dd = [date_min + timedelta(days=x) for x in range(
          (date_max-date_min).days + 1)]
        col = len(dd)
        ev_status = np.zeros((row,col))
        max_nac = int(max(df_id['nac_code'])*1.2)
        #event matrix where columns are days and rows treatments
        #0:no treatment, 1:treatment, 2:posible treatment,
        #3:after measuring period
        for act in actins:
            ini = list(df_id['date'][np.logical_and(df_id['actins']==act,
                                                  df_id['cycle']=='start')])[0]
            ev =  list(df_id['Event'][df_id['actins']==act])[0]            
            fin = ini+timedelta(days=treat_min_days) if 'HBA' not in ev else ini
            ev_cols = [events.index(ev_) for ev_ in ev.split('&')]
            ev_status = change_matrix_values(ev_status,ev_cols,
                                             list(range(dd.index(ini),
                                                        dd.index(fin)+1)),1)
            if 'HBA' not in ev:
                possible_day_duration = int(list(
                    df_id['nac_code'][np.logical_and(df_id['actins']==act,
                    df_id['cycle']=='start')])[0]*1.2)
                until_day = min([dd.index(ini)+possible_day_duration,col])
                ev_status = change_matrix_values(ev_status,ev_cols,
                                                 list(range(dd.index(fin),
                                                            until_day)),2)
                            
                                        
                
                
        measures = list(np.concatenate((ev_status[hba0,:].nonzero()[0],
                                        ev_status[hba1,:].nonzero()[0])))
        #event compaction.
        #Example: If a patient has 'A' treatment and they are dispensing 'A'
        #         drug multiple times, their trace could appear as A>A>A>A, 
        #         but the true trace should appear as 'A' treatment lasting
        #         its corresponding time. Therefore, if the difference between
        #         the last day and the first day of two consecutive same drugs's
        #         dispensation is less than the number of tablets of the 
        #         container two events are jointed in one with the first day of
        #         the first event as initial date and last day of the last 
        #         event as the end date.
        ev_status = ev_status.astype(int)
        for i in no_hba:
            seq = str(list(ev_status[i,:]))
            for delta_days in range(1,max_nac):
                pattern = ', '+str([1]+[2]*delta_days+[1])[1:-1]
                new_pattern = ', '+str([1]+[1]*delta_days+[1])[1:-1]
                seq = seq.replace(pattern,new_pattern)
            ev_status[i,:] = eval(seq) 
              
        ev_status = change_matrix_values(ev_status,no_hba,measures,3)
        for i,j in list(itertools.combinations(no_hba,2)):
            seq_i = str(list(ev_status[i,:]))
            seq_j = str(list(ev_status[j,:]))
            for delta_days in range(1,max_nac):
                pattern_i = ', '+str([1]+[1]*delta_days+[3])[1:-1]
                if re.search(pattern_i,seq_i)==None:
                    continue
                pattern_j = ', '+str([1]+[2]*delta_days+[3])[1:-1]
                new_pattern_j = ', '+str([1]+[1]*delta_days+[3])[1:-1]
                seq_j = seq_j.replace(pattern_j,new_pattern_j)
            for delta_days in range(1,max_nac):
                pattern_j = ', '+str([1]+[1]*delta_days+[3])[1:-1]
                if re.search(pattern_j,seq_j)==None:
                    continue
                pattern_i = ', '+str([1]+[2]*delta_days+[3])[1:-1]
                new_pattern_i = ', '+str([1]+[1]*delta_days+[3])[1:-1]
                seq_i = seq_i.replace(pattern_i,new_pattern_i)
            ev_status[i,:] = eval(seq_i)
            ev_status[j,:] = eval(seq_j)

        measures_w_dp = [[i+d_p for d_p in range(days_after_m+1)
                          if i+d_p<col] for i in measures]    
        measures_w_dp = list(itertools.chain(*measures_w_dp))
        ev_status = change_matrix_values(ev_status,no_hba,measures_w_dp,3)

        for i in no_hba:
            seq = str(list(ev_status[i,:]))
            seq = seq.replace('2','0').replace('3','0')
            ev_status[i,:] = eval(seq)               
                
        col = dd.index(dx_date[id])
        col_0 = dd.index(dx_date[id])
        col_max = dd.index(fin_date[id]) if str(fin_date[id])!='nan' else len(dd)
        min_change_days = 42
        while col<col_max-1:
            if not np.array_equal(ev_status[:,col],ev_status[:,col+1]):
                ev = col2treat(ev_status,events,col_0)
                if  (ev=='_' and col-col_0<min_change_days):
                    col+=1
                    col_0 = col
                    continue
                event_log['patient_id'].extend([id,id])
                event_log['date'].extend([dd[col_0],dd[col]])
                event_log['Event'].extend([ev,ev])
                event_log['nid'].extend([nid,nid])
                event_log['cycle'].extend(['start','end'])
                
                col+=1
                col_0 = col
            else:
                col+=1
        ev = col2treat(ev_status,events,col_0)
        if ev!='_' or col-col_0>=min_change_days:
            event_log['patient_id'].extend([id,id])
            event_log['date'].extend([dd[col_0],dd[col]])
            event_log['Event'].extend([ev,ev])
            event_log['nid'].extend([nid,nid])
            event_log['cycle'].extend(['start','end'])
    
            
    evlog = pd.DataFrame.from_dict(event_log)   
    evlog = evlog.sort_values(['patient_id','date'])
    evlog.rename(columns = {'patient_id':'ID'}, inplace = True)
    evlog.index = range(len(evlog))
    evlog['cycle'] = ['start','end']*int(0.5*len(evlog))
    evlog['actins'] = [n//2 for n in range(len(evlog))]
    con.sql(f"CREATE OR REPLACE TABLE evlog_raw_{cond} AS SELECT * FROM evlog")
  
def change_matrix_values(matrix,list_rows,list_cols, new_value=0):
    '''change selected rows' and columns' matrix`s values
    Args:
      matrix (array): matrix wanted to modify
      list_rows (list): matrix's rows wanted to modify
      list_cols (list): matrix's columns wanted to modify
      new_value (int): new wanted value
      
    Output:
      matrix (array): modified matrix
    '''
    pos = list(itertools.product(list_rows,list_cols))
    for i,j in pos:
        matrix[i,j] = new_value
    return matrix

def col2treat(matrix,rows,col):
    '''translate treatments from a binary vector
  
    Args:
      matrix (array): events calendary in binary information
      rows (str): events list
      col (int): column of matrix wanted to translate
    
    Output:
      treatment (str):
    '''
    treatment = '+'.join(sorted([rows[ev
                            ] for ev in range(len(rows)) 
                                 if matrix[ev,col]!=0]))
    if treatment!='':
        return treatment
    else:
        return '_'
    
def nac2comprimidos(nac_path,code_set):
    '''Creating dictionary of nac drugs container's number of tablets
  
    Args:
      nac_path (str): nac table's path
      code_set (set): nac code list
    Outputs:
        nac_dict (dic): nac codes as keys and their number of tablets as values
    '''

    nac = pd.read_csv(nac_path)
    nac['Código Nacional'] = nac['Código Nacional'].astype(str)
    nac_dict = {}

    for n in range(len(nac)):
        if nac['Código Nacional'][n] in code_set:
            text = nac['Nombre del producto farmacéutico'][n].lower()
            if re.search(r'\d+(?=\s*comprim)', text)!=None:
                nac_dict[nac['Código Nacional'][n]
                         ] = int(re.search(r'\d+(?=\s*comprim)', text).group())
            elif re.search(r'\d+(?=\s*comprim)', 
                           re.sub(r'\([^()]*\)', '', text))!=None:
                nac_dict[nac['Código Nacional'][n]
                         ] = int(re.search(r'\d+(?=\s*comprim)', 
                                re.sub(r'\([^()]*\)', '', text)).group())          
            elif re.search(r'con pelicula (\d+)', text)!=None:
                nac_dict[nac['Código Nacional'][n]
                         ] = int(re.search(r'con pelicula (\d+)',
                                    text).group().split()[-1])
    return nac_dict
```

### 2.4. Description of traces

#### 2.4.1. Estimation of distances
::: {.justify}
One of the most important aim of process mining is to show and explain processes. However, the great variety of traces does not allow us to draw any clear conclusion and it is often necessary to simplify our data. Another option that we can do before simplifying, to avoid the excessive losing of information and give another perspective to the analysis is to cluster the traces and to analyze them by cluster. To do that we have to measure somehow differences between traces; the distance between them. There are some distances that we can use to this task: edit distances, vector term similarity, LDA based distances, embedding based distances... Some of them are shown below as functions to calculate the distance matrix of traces:
::: 
```{python}
#| label: Distance matrix functions

#######   EDIT DISTANCE   ####### 
def calculate_dm_ED(traces,measure_f):
    '''Calculate distance matrix with some edit distance.
    
    Args:
      traces (list): patients' traces
      measure_f: some edit distance function
      
    Returns:
      dm: distance matrix
    '''
    id2word = corpora.Dictionary(traces)

    traces_e = [[id2word.token2id[t[n]] for n in range(len(t))] for t in traces]
    traces_e_str = list(set([str(traces_e[i]
                                 ) for i in range(len(traces_e))]))    
    len_t_r = len(traces_e_str)
    len_t = len(traces_e)
    dm = np.zeros((len_t,len_t), dtype = np.float32)
    same = measure_f(traces_e[0],traces_e[0])
    d_dic = {str(t):dict() for t in traces_e_str}
    for i in range(len_t_r):
        d_dic[traces_e_str[i]][traces_e_str[i]] = same
        for j in range(i+1,len_t_r):
            d_ij = measure_f(eval(traces_e_str[i]),
                             eval(traces_e_str[j]))
            d_dic[traces_e_str[i]][traces_e_str[j]] = d_ij
            d_dic[traces_e_str[j]][traces_e_str[i]] = d_ij

    for i in range(len_t):
        dm[i][i] = same
        for j in range(i+1,len_t):
            t_i = str(traces_e[i])
            t_j = str(traces_e[j])            
            d_ij = d_dic[t_i][t_j]
            dm[i][j] = d_ij
            dm[j][i] = d_ij
    if same == 1:
        dm = 1 - dm  
    
    return dm

#######   TERM VECTOR SIMILARITY   #######      
def calculate_dm_TV(traces):
    '''Calculate distance matrix with term vector similarity.
    
    Args:
      traces (list): list of traces
      
    Returns:
      dm (array): distance matrix
      vectorizer: TfidfVectorizer
      X: traces vectorized with TfidVectorizer
        
    '''
    corpus = [' '.join(t) for t in traces]
    vectorizer = TfidfVectorizer(tokenizer=str.split)
    X = vectorizer.fit_transform(corpus)
    print('calculatin dm ...')
    dm = np.asarray(np.matmul(X.todense(),X.todense().T))
    dm = 1 - dm.round(decimals=4)           
    return dm, vectorizer, X

#######   LDA BASED DISTANCE   #######      
def calculate_dm_LDA(traces,T=10):
    '''Calculate distance matrix with LDA model.
    
    Args:
      traces (list): list of traces
      T (int): number of topics of LDA model
    Returns:
      dm (array): distance matrix
      lda_model: LdaModel
      id2word (dict): tokenized events as keys and events by values
        
    '''

    # Create Dictionary
    id2word = corpora.Dictionary(traces)
    
    # Term Document Frequency
    corpus = [id2word.doc2bow(text) for text in traces]
    # Make LDA model
    lda_model = LdaModel(corpus=corpus,
                         id2word=id2word,
                         num_topics=T,
                         alpha = 1,
                         eta = 'auto',
                         random_state = 123)
    get_c_topic = np.array(
        lda_model.get_document_topics(corpus,minimum_probability = -0.1))
    sigma = np.asarray([[get_c_topic[i][j][1] 
              for j in range(T)] for i in range(len(corpus))])

    sigma2 = np.asarray(np.matmul(sigma,sigma.T))
    len_t = len(traces)
    dm = np.zeros((len_t,len_t), dtype = np.float32)
    
    same = sigma2[0][0]/np.sqrt(sigma2[0][0]*sigma2[0][0])
    for i in trange(len_t):
        dm[i][i] = same
        for j in range(i+1,len_t):
            d_ij = sigma2[i][j]/np.sqrt(sigma2[i][i]*sigma2[j][j])
            dm[i][j] = d_ij
            dm[j][i] = d_ij
    
            

    dm = 1-dm
    return dm, lda_model, id2word

```

#### 2.4.2. Clustering of traces
::: {.justify}
Once the distance matrix is obtained, we can proceed with the clustering. Each clustering method has its characteristics and its peculiarities. For example, we have to consider we have a distance matrix and not a data frame in which we apply directly the method. A hierarchical clustering algorithm seems to be a good choice in our case because in addition to the above it allows to choose the optimal number of clusters.

The next code box contains two different functions to choose the optimal number of clusters:
::: 
```{python}
#| label: Functions to choose optimal number of clusters
def dendogram(dm,output_png='../../outputs/dendogram.png'):
  '''Plot and save dendogram.
    
    Args:
      dm (array): distance matrix
      output_png (str): saved dendogram's path

  '''

  dm_condensed = squareform(dm)
  
  matrix = linkage(
      dm_condensed,
      method='complete'
      )
  sys.setrecursionlimit(10000000)
  dn = dendrogram(matrix,truncate_mode='lastp',p=80)
  sys.setrecursionlimit(1000)
  plt.title('Dendrogram')
  plt.ylabel('Distance')
  plt.xlabel('Patients traces')
  plt.savefig(output_png)
  plt.clf()

def kelbow(dm,
           cond,
           elbow_metric='distortion',
           locate_elbow=False,
           output_path='../../outputs/'):
  
  '''Plots to choose optimal clusters.
    
    Args:
      dm (array): distance matrix
      cond (str): predominal clinical condition's code 
      elbow_metric (str): name of the method
      locate_elbow (boolean): True if want to return optimal number of clusters
    Returns:
      k_opt (int)(optional): optimal number of clusters according to method
  '''

  model = AgglomerativeClustering(metric = "precomputed",
                                  linkage = 'complete')
  # k is range of number of clusters.
  visualizer_ = KElbowVisualizer(model,
                                k=(2,25),
                                timings=False,
                                xlabel = 'cluster numbers',
                                metric=elbow_metric,
                                locate_elbow=locate_elbow)
  # Fit data to visualizer
  output_file = output_path+elbow_metric+'_'+cond+'.png'
  visualizer_.fit(dm)
  # Finalize and render figure
  visualizer_.show(outpath=output_file,clear_figure=True)
  k_opt=None
  if locate_elbow:
    k_opt = visualizer_.elbow_value_ 
    return k_opt
```

The function 'clust' clusterizes traces in prefixed number of clusters:

```{python}
def clust(clust_n,dist_matrix,df_,id2trace,patients):
  '''clusterize distance matrix.
    
    Args:
      clust_n (int): number of clusters obtained
      dist_matrix (array): distance matrix
      df_ (dataframe): event log
      id2trace (dict): patient ids as keys and their traces as values
      patients (list): patients' ids in same order as in dm
    Returns:
      df_ (dataframe): dataframe with patients and their clusters
  '''
  traces = list(id2trace[id] for id in sorted(id2trace.keys()))     


  model = AgglomerativeClustering(n_clusters=clust_n,
                                  metric = "precomputed",
                                  linkage = 'complete')
  model.fit(dist_matrix)
  labels = model.labels_

  cluster_list ={id: labels[traces.index(id2trace[id])
                            ] for id in patients}

  df_['cluster'] = [cluster_list[df_['ID'][i]] for i in range(len(df_))]
  return df_
```

#### 2.4.3. Description of clusters and traces

The implementation below is made to show the most frequent traces in each cluster:

```{python}
#| label: Clusters visualization functions

def make_data_dict(log,top_k,col_id):
  '''Obtain most frequent traces and their statistics
    
    Args:
      log (dataframe): event log 
      top_k (int): number of traces want to show
      col_id (str): patients id column's name in df_
    Returns:
      data_dict (dict): traces as keys and ther statistics as values   
  '''

  len_id = len(set(log[col_id]))
  log_freq = pm4py.stats.get_variants(log)
  freq_list = [(t,log_freq[t],len(t)) for t in set(log_freq.keys())]
  trace = [list(t[0]) for t in sorted(freq_list, key=lambda x: 
                                              (len_id-x[1],x[2]))[:top_k]]
  cases = [t[1] for t in sorted(freq_list, key=lambda x: 
                                              (len_id-x[1],x[2]))[:top_k]]
  top_k = min(top_k,len(cases))
  percentage = [100*cases[c]/len_id for c in range(top_k)]
  cum_percentage = [sum(percentage[:p+1]) for p in range(top_k)]
  data_dict = {"Trace": trace,
               "Percentage": percentage,
               "Cases": cases,
               "Cumulative Percentage": cum_percentage}
  return data_dict
  
  
def update_color_dict(color_dict,data_dict):
  '''update of the color dict to include new events
    
    Args:
      color_dict (dict): events as keys and colors as values 
      data_dict (dict):  traces as keys and ther statistics as values
    Returns:
      color_dict (dict): events as keys and colors as values    
  '''
  cmap = plt.cm.get_cmap('tab20')
  for event in set(itertools.chain.from_iterable(data_dict['Trace'])):
      if event not in color_dict and len(color_dict)==20:
         cmap = plt.cm.get_cmap('tab20b')
      if event not in color_dict:    
        try:
          color_dict.update({event:cmap(len(color_dict))})
        except:
          color_dict.update({event:cmap(2*(len(color_dict)-20))})
  return color_dict 


def trace_plotter(data_dict,
                  color_dict,
                  acronym,
                  output_file,
                  font_size=10,
                  percentage_box_width=0.8,
                  size=(15,9)):
  '''configuration of the trace_explorer plot
    
    Args:
      color_dict (dict): events as keys and colors as values 
      data_dict (dict):  traces as keys and their statistics as values
      acronym (dict): events as keys and their acronyms as values
      output_file (str): figure's path
      font_size (int): font size
      percentage_box_width (float): event boxes' width
      size (tuple): figure's size
  '''

  fig, ax = plt.subplots(figsize=size)
  percentage_position = max(len(t) for t in data_dict["Trace"]
                            ) + percentage_box_width*3 +0.5
  for row, (trace, percentage,cases,cum_percentage
            ) in enumerate(zip(data_dict["Trace"],
                               data_dict["Percentage"],
                               data_dict["Cases"],
                               data_dict["Cumulative Percentage"]),
                               start=1):
    for col, acr in enumerate(trace, start=1):
        ax.add_patch(plt.Rectangle((col - 0.5, row - 0.45), 1, 0.9,
                                    facecolor=color_dict[acr],
                                    edgecolor='white'))
        ax.text(col, 
                row, 
                acr, 
                ha='center', 
                va='center', 
                color='white',
                fontsize = font_size, 
                fontweight='bold')
        ax.add_patch(plt.Rectangle((
          percentage_position -percentage_box_width*2.5,
          row - 0.45), percentage_box_width, 0.9,
          facecolor='grey', edgecolor='white'))
        ax.text(percentage_position-percentage_box_width*2,
                row,
                f'{percentage:.2f}%',
                ha='center',
                va='center',
                color='white',
                fontsize = font_size+2)
        ax.add_patch(plt.Rectangle((
          percentage_position - percentage_box_width*1.5,
          row - 0.45), percentage_box_width, 0.9,
          facecolor='grey', edgecolor='white'))
        ax.text(percentage_position-percentage_box_width,
                row,
                f'{cases}',
                ha='center',
                va='center',
                color='white',
                fontsize = font_size+4)
        ax.add_patch(plt.Rectangle((percentage_position-percentage_box_width*0.5, 
                                    row - 0.45), percentage_box_width, 0.9,
                                    facecolor='grey', edgecolor='white'))
        ax.text(percentage_position,
                row,
                f'{cum_percentage:.2f}%', 
                ha='center',
                va='center',
                color='white',
                fontsize = font_size+2)
      
  ax.set_xlim(0.5, percentage_position+0.5)
  ax.set_xticks(range(1, int(percentage_position-1)))
  ax.set_ylabel('Traces',fontsize = font_size+3)
  ax.set_ylim(len(data_dict["Trace"]) + 0.45, 0.55) # y-axis is reversed
  ax.set_yticks([])
  ax.set_xlabel('Activities',fontsize = font_size+3)
  
  handles = [plt.Rectangle((0, 0), 0, 0, facecolor=color_dict[acr],
                            edgecolor='black', label=acronym[acr])
              for acr in acronym if acr in set(
                itertools.chain.from_iterable(data_dict['Trace']))]
  ax.legend(handles=handles, 
            bbox_to_anchor=[1.02, 1.02],
            loc='upper left',
            fontsize = font_size+6)
  for dir in ['left', 'right', 'top']:
      ax.spines[dir].set_visible(False)
  plt.tight_layout()
  plt.savefig(output_file)
  plt.close()


def trace_explorer(con,
                   cond,
                   top_k=5,
                   id_col='ID',
                   ev_col='Event',
                   date_col='date',
                   clust_col='cluster',
                   color_dict={}):
  '''Plot each clusters most frequent traces
    
    Args:
      con : db connector variable
      cond (str): predominal clinical condition's code
      top_k (int):  traces as keys and their statistics as values
      id_col (str): patients id column's name in evlog_file
      ev_col (str): events column's name in evlog_file
      date_col (str): events dates column's name in evlog_file
      clust_col (str): cluster column's name in evlog_file
      color_dict (dict): events as keys and colors as values  
  '''
  log_ = pm4py.format_dataframe(con.sql(f"SELECT * FROM eventlog_{cond}_clust_filtered").df(),
                                case_id=id_col,
                                activity_key=ev_col,
                                timestamp_key=date_col)                  
  log_ = log_.sort_values([id_col,date_col])
  log_ = log_[log_['cycle']=='start'] 
  for clust in set(log_[clust_col]):
      log = log_[log_[clust_col]==clust]
      len_id = len(set(log[id_col]))
      acronym = {t:t for t in sorted(set(log[ev_col]))}
      data_dict = make_data_dict(log,top_k,id_col)
      color_dict = update_color_dict(color_dict, data_dict)
      trace_plotter(data_dict,color_dict,acronym,
                    '../../outputs/t_cluster_%s_%i.png' % (cond,clust))
  return color_dict

```

To get the process maps of each cluster next R functions can be used:

```{r}
#| label: Process maps in R

load_log <- function(con,
                     query,case_id="ID",
                     activity_id="Event", 
                     lifecycle_id="cycle",
                     activity_instance_id="actins",
                     timestamp="date"){
  
  eventlog <- dbGetQuery(con,query)  
  eventlog = eventlog[order(eventlog$ID),]
  #To transform date to a format we can work with
  eventlog$date = as.POSIXct(eventlog$date, tz = "", format="%Y-%m-%d" ,
                                   tryFormats = c("%Y/%m/%d",
                                                  "%Y/%m/%d"),
                                   optional = FALSE) 
  
  
  
  evLog = eventlog %>%
    mutate(resource = NA) %>%
    mutate(cycle = fct_recode(cycle,
                              "start" = "start",
                              "complete" = "end")) %>%
    eventlog(
      case_id = case_id,
      activity_id = activity_id, 
      lifecycle_id = lifecycle_id, 
      activity_instance_id = activity_instance_id, 
      timestamp = timestamp, 
      resource_id = 'resource'
    )
  return(evLog)
}
make_process_map <- function(log,t_freq,output_file){
  log %>%
    filter_activity_frequency(percentage = 1) %>% # show only most frequent
    filter_trace_frequency(percentage = t_freq) %>%
    process_map(type_nodes = performance(mean,units='days'),
                sec_nodes = frequency('relative_case'),
                type_edges = frequency('absolute'),
                sec_edges = frequency('relative_case'),
                render = T) %>% 
    export_svg %>% 
    charToRaw %>%
    rsvg_png (output_file,width=2000)
}
make_process_map_healthcare <- function(log,t_freq,output_file){
  log %>%
    filter_activity_frequency(percentage = 1) %>% # show only most frequent
    filter_trace_frequency(percentage = t_freq) %>%
    process_map(type_nodes = frequency('absolute'),
                sec_nodes = frequency('relative_case'),
                type_edges = frequency('relative_case'),
                sec_edges = performance(mean,units='days'),
                render = T) %>% 
    export_svg %>% 
    charToRaw %>%
    rsvg_png (output_file,width=4000)
}
process_map_by_cluster <- function(evLog,t_freq,cond_code){
  for (clust in unique(evLog$cluster)) {
    log <- evLog %>% 
      filter(cluster == clust)
    make_process_map(log,t_freq,gsub("src/analysis-scripts/",
                                     "",here("outputs",sprintf(
                                       "pm_cluster_%s_%d.png", 
                                       cond_code, clust) )))

  }
}
```

### 2.5. Conformance checking

#### 2.5.1. Adherence analysis for process indicators
::: {.justify}
Conformance checking is a technique used to check process compliance by comparing event logs for a discovered process with the existing reference model (target model) of the same process. Basing on diabetes guidelines, with a software called Carassius, we created next Petri Nets that are going to be useful to analyze whether traces obey the guidelines the first five years:
::: 
![Petri Net of process indicators of the first year](../../outputs/PN_process1.png){#fig-petrinet_process1 fig-align="center" width="100%"}

![Petri Net of process indicators of the first two years](../../outputs/PN_process2.png){#fig-petrinet_process2 fig-align="center" width="100%"}

![Petri Net of process indicators of the first three years](../../outputs/PN_process3.png){#fig-petrinet_process3 fig-align="center" width="100%"}

![Petri Net of process indicators of the first four years](../../outputs/PN_process4.png){#fig-petrinet_process4 fig-align="center" width="100%"}

![Petri Net of process indicators of the first five years](../../outputs/PN_process5.png){#fig-petrinet_process5 fig-align="center" width="100%"}

::: {.justify}
Fitness is the metric that measures how much a trace is distanced from a given process model, or from the guidelines in this case. There are different methods to calculate this metric but in the code below is used the token base replay method.
::: 
```{python}
#| label: Fitness  calculation (process_indicators)
def id2process_fitness(con,
                       query,
                       pn_file,
                       pn_png_file,
                       ini_place='place37',
                       fin_place='place148',
                       id_col = 'patient_id',
                       event_col = 'event',
                       date_col='date',):
    '''Calculate the fitness of a given process indicators' event log
    
    Args:
      con: db connector variable
      cond (str): predominal clinical condition's code
      query (str): query to select event log
      pn_file (str): petri net's path
      ini_place (str): initial place in the petri net
      fin_place (str): final place in the petri net
      id_col (str): ids' column's name in event log
      event_col (str): events' column's name in event log
      date_col (str): events' dates' column's name in event log
    Returns:
      df (dataframe): dataframe of ids' fitness
  '''
    net, initial_marking, final_marking = pm4py.read_pnml(pn_file)
    initial_marking = Marking()
    initial_marking[list(net.places)[[str(p) for p in net.places].index(
        ini_place)]] = 1
    final_marking = Marking()
    final_marking[list(net.places)[[str(p) for p in net.places].index(
        fin_place)]] = 1
    pm4py.save_vis_petri_net(net, initial_marking, final_marking,pn_png_file)
    event_log = pm4py.format_dataframe(con.sql(query).df(),
                                case_id=id_col,
                                activity_key=event_col,
                                timestamp_key=date_col) 
    date_list = []
    fit_list = []
    id_list = list(set(event_log[id_col]))
    length_list = []
    for id in tqdm(id_list):
        log = event_log.drop(event_log.index[event_log['case:concept:name'] !=id]
                              ).sort_values('time:timestamp')
        fit_obj = pm4py.conformance.conformance_diagnostics_token_based_replay(
            log, net, initial_marking, final_marking)
        date_list.append(list(log['time:timestamp'])[-2])
        fit_list.append(fit_obj[0]['trace_fitness'])
        length_list.append(len(log))
        
    log_0 = log[log['concept:name'].isin(['INI','FIN','yFIN'])]
    alfa = pm4py.conformance.conformance_diagnostics_token_based_replay(
        log_0, net, initial_marking, final_marking)[0]['trace_fitness']
    
    df =  pd.DataFrame()
    df['ID'] = id_list
    df['fitness'] = [(x-alfa)/(1-alfa) for x in fit_list]
    df['date'] = date_list
    df['trace_length'] = length_list
    return df
```

#### 2.5.2. Adherence analysis for treatment trajectories
::: {.justify}
Basing on the DM2 treatment algorithm previous shown we created the next Petri Nets that are going to be useful as treatment guidelines in reference to glycated hemoglobin measures.
:::

![DM2 Treatment Algorithm's interpretation to patients without predominant clinical condition in Petri Net format](../../outputs/PN_else.png){#fig-petrinet_else fig-align="center" width="100%\""}

![DM2 Treatment Algorithm's interpretation to patients with obesity in Petri Net format](../../outputs/PN_ob.png){#fig-petrinet_ob fig-align="center" width="100%\""}

![DM2 Treatment Algorithm's interpretation to patients with frailty in Petri Net format](../../outputs/PN_f.png){#fig-petrinet_f fig-align="center" width="100%\""}

![DM2 Treatment Algorithm's interpretation to patients with some chronic kidney disease in Petri Net format](../../outputs/PN_ckd.png){#fig-petrinet_ckd fig-align="center" width="100%"}

![DM2 Treatment Algorithm's interpretation to patients with heart failure in Petri Net format](../../outputs/PN_hf.png){#fig-petrinet_hf fig-align="center" width="100%\""}

![DM2 Treatment Algorithm's interpretation to patients with some CV disease in Petri Net format](../../outputs/PN_cvd.png){#fig-petrinet_cvd fig-align="center" width="100%"}

::: {.justify}
Next functions are to return the fitness of therapeutic traces. Unlike before, now the method used to calculate the fitness is the aligned fitness method.
::: 
```{python}
#| label: Fitness  calculation (treatments)
def id2treat_fitness(log ,
               net, 
               initial_marking, 
               final_marking, 
               clust_col='cluster',
               date_col='date',
               ev_col='Event'):
  '''Obtain traces fitness
    
    Args:
      log (dataframe): event log 
      net: petri net
      initial_marking: initial place in the petri net
      final_marking: final place in the petri net
      clust_col (str): cluster column's name in log
      date_col (str): events dates column's name in log
      ev_col (str): events column's name in log
    Returns:
      df (dataframe): traces, their clusters and their fitnesses  
  '''
  id2trace = {id:list(log[ev_col][log['case:concept:name']==id]
                      ) for id in set(log['case:concept:name'])}
  id2ids = {id:[id2 for id2 in set(id2trace.keys()) if id2trace[id]==id2trace[id2]
                ] for id in set(log['case:concept:name'])}
  for id in set(id2ids.keys()):
      try:
          for id2 in id2ids[id]:
              if id2!=id:
                  del id2ids[id2]
      except:
          continue
  
  id2fitness = dict()
  for name in set(id2ids.keys()):
      log2 = log.drop(log.index[log['case:concept:name'] !=name])
      new = log2.copy().iloc[[0, -1]]
      date_list = list(new[date_col])
      index = list(new['@@index'])
      actins = list(new['actins'])
      clust = new[clust_col].values[0]
      new[date_col] =  new['time:timestamp'] = [date_list[0]-timedelta(days=1),
                                                date_list[1]+timedelta(days=1)]
      new[ev_col] = new['concept:name'] = ['INI','FIN']
      new['@@index'] = [index[0]-1,index[1]+1]
      new['actins'] = [actins[0]-1,actins[1]+1]
    
      log2 = pd.concat([log2,new]).sort_values('time:timestamp')
      aligned_fitness = pm4py.conformance_diagnostics_alignments(
                        log2, net, initial_marking, final_marking)[0]['fitness']
      for id in id2ids[name]:
          id2fitness[id] = {'ID':id,
                            'aligned_fitness':aligned_fitness,
                            clust_col: clust}
  
  df = pd.DataFrame(id2fitness).T
  df.index = range(len(df))
  return df
```

The function below takes a treatments' event log and returns each patient's fitness by time interval.

```{python}
#| label: Fitness  calculation by intervals (treatments)
def id2treat_fitness_by_interval(con,
                           cond,
                           pn_file,
                           pn_png_file,
                           ini_place='place100',
                           fin_place='place111',
                           date_n_col='date',
                           fixed_period_time=90):
    '''Obtain traces fitness by intervals of fixed_period_time days
    
    Args:
      con: db connector variable
      cond (str): predominal clinical condition's code
      pn_file (str): petri net's path
      ini_place (str): initial place in the petri net
      fin_place (str): final place in the petri net
      date_n_col (str): events dates column's name in log
      fixed_period_time (int): number of days in each interval
  '''
    net, initial_marking, final_marking = pm4py.read_pnml(pn_file)
    initial_marking = Marking()
    initial_marking[list(net.places)[[str(p) for p in net.places].index(
        ini_place)]] = 1
    final_marking = Marking()
    final_marking[list(net.places)[[str(p) for p in net.places].index(
        fin_place)]] = 1
    pm4py.save_vis_petri_net(net, initial_marking, final_marking,pn_png_file)
    event_log = pm4py.format_dataframe(con.sql(f"SELECT * FROM eventlog_{cond}_clust \
    WHERE cycle = 'start'").df(),
                                case_id='ID',
                                activity_key='Event',
                                timestamp_key=date_n_col) 
    event_log = event_log[event_log['cycle']=='start'] 
    baseline = datetime.strptime('2017-01-01', "%Y-%m-%d")
    endline = datetime.strptime('2023-01-01', "%Y-%m-%d")
    dd = [baseline + timedelta(days=x) for x in range((
              endline-baseline).days + 1)]
    dd_INI = dd[0]-timedelta(days=1)
    dd_FIN = dd[-1]+timedelta(days=1)
    event_log['time:timestamp'] = event_log['time:timestamp'].dt.tz_localize(None)
    event_log[date_n_col] = event_log[date_n_col].dt.tz_localize(None)
    event_log['date_'] = event_log[date_n_col].apply(
        lambda x: dd.index(x))
    event_log[date_n_col] = event_log[date_n_col].apply(
        lambda x: dd.index(x))
    event_log[date_n_col] = event_log.groupby('ID')[date_n_col].apply(
        lambda x: x-x.min())
    
#    hosp = con.sql(f"SELECT *, \
#      DATEDIFF('day',DATE '{str(baseline)[:10]}',admission_date) AS dd_date \
#      FROM cmbd_incidents_postdx_first_view").df()
    hosp = con.sql(f"select *,DATEDIFF('day',DATE '{str(baseline)[:10]}',date) AS dd_date from patient_condition_hosp WHERE ((final_status!=initial_status AND final_status NOT IN ('end','else','ob','f')) OR cause='hosp')").df()
    hosp = dict(zip(hosp.patient_id,hosp.dd_date))
    
    cond_end = con.sql(f"SELECT *, \
      DATEDIFF('day',DATE '{str(baseline)[:10]}',date) AS dd_date \
      FROM patient_condition WHERE type='{cond}'").df()
    cond_end = dict(zip(cond_end.patient_id,cond_end.dd_date))
    
    period2fitness = pd.DataFrame()
    id_list_df = []
    p_start = []
    p_end = []
    fitness = []
    date_0 = []
    status = []
    trace_length = []
    id_list = list(set(event_log['ID']))
    for id in tqdm(id_list):
        event_log_id = event_log[event_log['ID']==id]
        hosp_d = hosp.get(id,100000)-min(event_log_id['date_'])
        col_end_d = cond_end[id]-min(event_log_id['date_'])
        date_max = min(col_end_d,hosp_d)
        date_min = min(event_log_id['time:timestamp'])
        n_periods = date_max//fixed_period_time
        n_periods_r = date_max/fixed_period_time
        if date_max<=fixed_period_time:
            continue
        for n in range(1,n_periods+1):
            event_log_id_n = event_log_id[
                event_log_id[date_n_col]<n*fixed_period_time]
            
            new = event_log_id.copy().iloc[[0, -1]]
            actins = list(new['actins'])
            index = list(new['@@index'])
            new['time:timestamp'] = [dd_INI,dd_FIN]
            new['concept:name'] = ['INI','FIN']
            new['@@index'] = [index[0]-1,index[1]+1]
            new['actins'] = [actins[0]-1,actins[1]+1]
            event_log_id_n = pd.concat([event_log_id_n,new]
                                       ).sort_values('time:timestamp')
            aligned_fitness = pm4py.conformance_diagnostics_alignments(
                             event_log_id_n, net, 
                             initial_marking, final_marking)[0]['fitness']
            id_list_df.append(id)
            p_start.append((n-1)*fixed_period_time)
            p_end_value = n*fixed_period_time
            if n==n_periods:
                p_end_value = date_max-fixed_period_time
            p_end.append(p_end_value)
            fitness.append(aligned_fitness)
            date_0.append(date_min)
            trace_length.append(len(event_log_id_n))
            if (n==n_periods or n==n_periods_r-1) and hosp_d==date_max :
                status.append(1)
                break
            else:
                status.append(0)
    
    period2fitness['ID'] = id_list_df
    period2fitness['t_0'] = p_start
    period2fitness['t_1'] = p_end
    period2fitness['fitness'] = fitness
    period2fitness['ini_date'] = date_0
    period2fitness['status'] = status
    period2fitness['trace_length'] = trace_length
    con.sql(f"CREATE OR REPLACE TABLE period2fitness_{cond} AS SELECT *,\
            MAX(status) OVER (PARTITION BY ID) AS status2  FROM period2fitness \
            WHERE t_0!=t_1") 
```

In the next function is shown a boxplot function to show clusters' fitness distribution.

```{python}
#| label: Fitness boxplot
def treatments_clusters_boxplot(con,
                cond,
                output_png='../../outputs/fitness_by_cluster.png'):
  '''Barplot of the fitness of each cluster
    
    Args:
      con: db connector variable
      cond (str): predominant clinical condition
      output_png (str): created figure's path
  '''
  df = con.sql(f"SELECT f.ID,f.fitness,c.cluster \
            FROM (SELECT * FROM (SELECT *,ROW_NUMBER() OVER (\
                  PARTITION BY ID ORDER BY t_0 DESC) AS rn \
                  FROM period2fitness_{cond}) \
  WHERE rn=1) f LEFT JOIN (SELECT DISTINCT ID,cluster \
  FROM eventlog_{cond}_clust_filtered) c ON c.ID=f.ID"
  ).df().dropna(subset=["cluster"]) 
  
  data = [list(df['fitness'][df['cluster']==i])
            for i in sorted(set(df['cluster']))]
     
  fig = plt.figure(figsize =(10, 7))
  ax = fig.add_axes([0, 0, 1, 1])
  bp = ax.boxplot(data,labels=[int(i) for i in sorted(set(df['cluster']))])
  plt.xlabel("Clusters")
  plt.ylabel("Aligned Fitness")
  plt.savefig(output_png,bbox_inches='tight')
  plt.close(fig)

```

### 2.6. Prediction of clinical outcomes

#### 2.6.1. Time dependent Cox model
::: {.justify}
The link between guideline adherence, in terms of performed process measures, and clinical outcomes is a highly demanded issue in diabetes care. A Cox model is a statistical technique for exploring the relationship between the survival of a patient and several explanatory variables. One of the strengths of the Cox model is its ability to encompass covariates that change over time, such as treatment adherence. A time dependent Cox model can be made using each patient trace's fitness at different time interval.
::: 
#### 2.6.2. Joint Latent Class Model
::: {.justify}
Joint models are used to analyse simultaneously two related phenomena, the evolution of a variable and the occurrence of an event. Joint latent class model (JLCM) consists of a linear mixed model and a proportional hazard model linked by the latent classes. The population is split in several groups, the latent classes, and each class is characterized by a specific evolution of the dependent variable and an associated risk of event. Using fitness as time dependent treatment adherence measure we can made a joint latent class model.
:::

## 3. Cohort description

### 3.1. Incident patients description

```{python}
#| label: preprocessing of the initial dataframes
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info('Preprocess of the initial dataframes')
db_path = '../../inputs/data.duckdb'
con = duckdb.connect(db_path)
general_preprocess(con)
notnan_p = separate_patients_by_condition(con)
evlog_services(con)
con.close()
```

```{r}
#| label: fixing db pathway
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
db_path <- '../../inputs/data.duckdb'
con <- dbConnect(duckdb(), dbdir = db_path)
country2cont = read.csv('./country2continent.csv') %>% 
  transform(country = as.numeric(country))

comorb_ch <- comorb(archivo = dbGetQuery(con,
        "SELECT patient_id AS id,\
        CASE WHEN comorb_code='250' THEN '250.0' \
        WHEN comorb_code IN ('E10','E11','E12','E13','E14') THEN 'E10.0' \
        ELSE comorb_code END AS cod,\
        CASE WHEN comorb_codif='CIAP2' THEN 'CIAP2' \
        WHEN comorb_codif='ICD9' THEN '9' \
        WHEN comorb_codif='ICD10' THEN '10ES'\
        ELSE 'ERROR' END AS codtype,comorb_date_ini AS date \
        FROM comorb_incidents_view  \
        WHERE (comorb_date_end IS NULL OR \
        comorb_date_end >= (SELECT dx_date FROM patient_incidents_view WHERE \
        patient_incidents_view.patient_id = comorb_incidents_view.patient_id)) \
        AND comorb_date_ini <= (SELECT dx_date FROM patient_incidents_view WHERE \
        patient_incidents_view.patient_id = comorb_incidents_view.patient_id)"))
duckdb_register(con, "comorb_ch", comorb_ch)
dbExecute(con,
        "CREATE OR REPLACE TABLE patient_incidents_view_ch AS \
        SELECT p.*, CASE WHEN c.score_ch IS NULL THEN 1\
        ELSE c.score_ch END AS charlson \
        FROM patient_incidents_view p LEFT JOIN comorb_ch c \
        ON p.patient_id = c.id")
```

```{r}
#| label: tbl-patient_inc
#| tbl-cap: "Demographic and socioeconomic characteristics of incidents patients "
#| tbl-colwidths: [60,40]

###INCIDENTS
patient_inc <- dbGetQuery(con,
                       "SELECT *,
                       CASE WHEN sex = 0 THEN 'Male' 
                       ELSE 'Female' END AS sexo FROM patient_incidents_view_ch") 
patient_inc <- patient_inc %>%
  left_join( country2cont %>% select(country, CC), by = "country") %>%
  mutate(education=factor(education, levels=c(0,1,2,3),
      labels=c("Without studies","Primary school",
               "High school","University")),
      copayment=factor(copayment,levels=c(0,1),
                       labels=c("less than 18000","more or equal than 18000")))
patient_inc$CC[patient_inc$country == 724] <- 'Spain'
patient_inc$charlson <- as.factor(patient_inc$charlson)
dependent="sexo"
explanatory=c("age_dx","CC","copayment","education", "avg_income","charlson")  

patient_inc%>%summary_factorlist(dependent,
                              explanatory,
                              total_col = TRUE,
                              cont="mean",
                              cont_cut=7,
                              na_include = TRUE,
                              na_to_prop =  FALSE, 
                              include_col_totals_percent	=FALSE,
                              add_col_totals = TRUE)-> patient_inc_tab

kable(patient_inc_tab, row.names=FALSE, align=c("l", "l", rep("r",5)))

```

```{r}
#| label: tbl-param_inc
#| tbl-cap: "Demographic and socioeconomic characteristics of incidents patients "
#| tbl-colwidths: [60,40]
param_inc <- dbGetQuery(con,"SELECT * FROM param_incidents_predx_last_view")
param_list <- sort(unique(param_inc$param_name))
param_cat_inc <- dbGetQuery(con,
  "SELECT *, \
  CASE WHEN param_cat_name='physical_activity' AND param_cat_value=0 \
  THEN 'Incapacity' \
  WHEN param_cat_name='physical_activity' AND param_cat_value=1 \
  THEN 'Inactive' \
  WHEN param_cat_name='physical_activity' AND param_cat_value=2 \
  THEN 'Partially Active' \
  WHEN param_cat_name='physical_activity' AND param_cat_value=3 \
  THEN 'Active' \
  WHEN param_cat_name='smoking_status' AND param_cat_value=0 \
  THEN 'Non Smoker' \
  WHEN param_cat_name='smoking_status' AND param_cat_value=1 \
  THEN 'Ex-smoker < 1 year' \
  WHEN param_cat_name='smoking_status' AND param_cat_value=2 \
  THEN 'Ex-smoker >= 1 year' \
  WHEN param_cat_name='smoking_status' AND param_cat_value=3 \
  THEN 'Smoker' \
  WHEN param_cat_name='alcohol' AND param_cat_value=0 \
  THEN 'Abstinent' \
  WHEN param_cat_name='alcohol' AND param_cat_value=1 \
  THEN 'Moderate Drinker' \
  WHEN param_cat_name='alcohol' AND param_cat_value=2 \
  THEN 'Heavy Drinker' \
  WHEN param_cat_name='vaccination_flu' AND param_cat_value=0 \
  THEN 'No' \
  WHEN param_cat_name='vaccination_flu' AND param_cat_value=1 \
  THEN 'Yes' \
  WHEN param_cat_name='working_status' AND param_cat_value=0 \
  THEN 'Active' \
  WHEN param_cat_name='working_status' AND param_cat_value=1 \
  THEN 'Unemployed' \
  WHEN param_cat_name='working_status' AND param_cat_value=2 \
  THEN 'Pensionist' \
  ELSE '' END AS param_cat_value_str
  FROM param_cat_incidents_predx_last_view WHERE param_cat_name!='vaccination_covid'")
param_cat_list <- sort(unique(param_cat_inc$param_cat_name))
dependent="sexo"


param_inc2unnest <- param_inc %>% 
  pivot_wider( id_cols=patient_id,names_from=param_name,values_from=param_value)%>%
  left_join( patient_inc %>% select(patient_id, sexo), by = "patient_id")

param_cat_inc2unnest <- param_cat_inc %>% 
  pivot_wider( id_cols=patient_id,names_from=param_cat_name,values_from=param_cat_value_str)%>%
  left_join( patient_inc %>% select(patient_id, sexo), by = "patient_id") 

param_inc_tab <- rbind(
  param_inc2unnest %>%
    summary_factorlist(dependent ,
                       param_list,
                       total_col = TRUE,cont="mean",na_include = TRUE,
                       na_to_prop =  FALSE,add_row_totals = TRUE,
                       include_row_missing_col = TRUE,
                       include_col_totals_percent	=FALSE,add_col_totals = TRUE),
  param_cat_inc2unnest %>%
    summary_factorlist(dependent ,
                       param_cat_list,
                       total_col = TRUE,cont="mean",na_include = TRUE,
                       na_to_prop =  FALSE,cont_cut=8,add_row_totals = TRUE,
                       include_row_missing_col = TRUE))
kable(param_inc_tab, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

```{r}
#| label: tbl-use_inc
#| tbl-cap: "Use of Primary Care Services per year of incidents patients"
#| tbl-colwidths: [60,40]

patient_inc$deregistration_date <- patient_inc$deregistration_date %>%
  replace_na(as.Date('2023-01-01'))
patient_inc <- patient_inc %>% 
  mutate(follow_up_time=as.numeric(difftime(deregistration_date,
                                            dx_date,units="days")/365.25)) %>%
  filter(follow_up_time!=0)

ss_use_inc <- dbGetQuery(con," SELECT * FROM main.ss_use \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date >='2017-01-01') AND \
                  visit_date>= (SELECT dx_date FROM main.patient WHERE \
                  main.patient.patient_id = main.ss_use.patient_id)") %>% mutate(
                        visit_type=factor(visit_type, levels=c(1,2,3,4,5,6,7,8),
                        labels=c("PC_physician", "PC_nurse", "PC_social_worker",
                                 "PC_emergency_service","PC_others",
                                 "Specialized_visit_physician",
                                 "Specialized_visit_nurse",
                                 "Specialized_visit_unknown_professional")))

ss_use_inc1 <- ss_use_inc %>% 
  filter(visit_loc == 1)
use_inc_freq1 <- as.data.frame.matrix(table(ss_use_inc1$patient_id,ss_use_inc1$visit_type))
use_inc_freq1 <- cbind(patient_id = rownames(use_inc_freq1), use_inc_freq1)
use_inc_freq1_time <- left_join(use_inc_freq1, patient_inc %>% select(patient_id, sex, follow_up_time,dx_date), by = "patient_id") %>%
  mutate(PC_physician= PC_physician/follow_up_time,
         PC_nurse=PC_nurse/follow_up_time,
         PC_social_worker=PC_social_worker/follow_up_time,
         PC_emergency_service=PC_emergency_service/follow_up_time,
         PC_others=PC_others/follow_up_time,
         Specialized_visit_physician=Specialized_visit_physician/follow_up_time,
         Specialized_visit_nurse=Specialized_visit_nurse/follow_up_time,
         Specialized_visit_unknown_professional=Specialized_visit_unknown_professional/follow_up_time,
         sexo=factor(sex, levels=c(0,1), labels=c("Male", "Female"))) 

ss_use_inc2 <- ss_use_inc %>% 
  filter(visit_loc == 2)
use_inc_freq2 <- as.data.frame.matrix(table(ss_use_inc2$patient_id,ss_use_inc2$visit_type))
use_inc_freq2 <- cbind(patient_id = rownames(use_inc_freq2), use_inc_freq2)
use_inc_freq2_time <- left_join(use_inc_freq2, patient_inc %>% select(patient_id, sex, follow_up_time,dx_date), by = "patient_id") %>%
  mutate(PC_physician= PC_physician/follow_up_time,
         PC_nurse=PC_nurse/follow_up_time,
         PC_social_worker=PC_social_worker/follow_up_time,
         PC_emergency_service=PC_emergency_service/follow_up_time,
         PC_others=PC_others/follow_up_time,
         Specialized_visit_physician=Specialized_visit_physician/follow_up_time,
         Specialized_visit_nurse=Specialized_visit_nurse/follow_up_time,
         Specialized_visit_unknown_professional=Specialized_visit_unknown_professional/follow_up_time,
         sexo=factor(sex, levels=c(0,1), labels=c("Male", "Female"))) 

ss_use_inc3 <- ss_use_inc %>% 
  filter(visit_loc == 3)
use_inc_freq3 <- as.data.frame.matrix(table(ss_use_inc3$patient_id,ss_use_inc3$visit_type))
use_inc_freq3 <- cbind(patient_id = rownames(use_inc_freq3), use_inc_freq3)
use_inc_freq3_time <- left_join(use_inc_freq3, patient_inc %>% select(patient_id, sex, follow_up_time,dx_date), by = "patient_id") %>%
  mutate(PC_physician= PC_physician/follow_up_time,
         PC_nurse=PC_nurse/follow_up_time,
         PC_social_worker=PC_social_worker/follow_up_time,
         PC_emergency_service=PC_emergency_service/follow_up_time,
         PC_others=PC_others/follow_up_time,
         Specialized_visit_physician=Specialized_visit_physician/follow_up_time,
         Specialized_visit_nurse=Specialized_visit_nurse/follow_up_time,
         Specialized_visit_unknown_professional=Specialized_visit_unknown_professional/follow_up_time,
         sexo=factor(sex, levels=c(0,1), labels=c("Male", "Female"))) 


use_inc_tab <- rbind(
  rbind(data.frame(label = "at care center", levels = '',
                   Male = '', Female = '', Total = ''),
        use_inc_freq1_time %>%
          summary_factorlist(dependent ,c("PC_physician", "PC_nurse", "PC_social_worker",
                                          "PC_emergency_service","PC_others",
                                          "Specialized_visit_physician",
                                          "Specialized_visit_nurse",
                                          "Specialized_visit_unknown_professional"),
                             total_col = TRUE,cont="mean",cont_cut=1,
                             na_include = TRUE,na_to_prop =  FALSE)),
  rbind(data.frame(label = "at home", levels = '',
                   Male = '', Female = '', Total = ''),
        use_inc_freq2_time %>%
          summary_factorlist(dependent ,c("PC_physician", "PC_nurse", "PC_social_worker",
                                          "PC_emergency_service","PC_others",
                                          "Specialized_visit_physician",
                                          "Specialized_visit_nurse",
                                          "Specialized_visit_unknown_professional"),
                             total_col = TRUE,cont="mean",cont_cut=1,
                             na_include = TRUE,na_to_prop =  FALSE)),
  rbind(data.frame(label = "by telephone or similar", levels = '',
                   Male = '', Female = '', Total = ''),
        use_inc_freq3_time %>%
          summary_factorlist(dependent ,c("PC_physician", "PC_nurse", "PC_social_worker",
                                          "PC_emergency_service","PC_others",
                                          "Specialized_visit_physician",
                                          "Specialized_visit_nurse",
                                          "Specialized_visit_unknown_professional"),
                             total_col = TRUE,cont="mean",cont_cut=1,
                             na_include = TRUE,na_to_prop =  FALSE)))

kable(use_inc_tab, row.names=FALSE, align=c("l", "l", rep("r",5)))

```

::: {.justify}
@fig-predominant_cond_m shows predominant clinical condition's first change in incident patients. The number inside boxes is the number of people experienced the change and box color the number of days needed to change. Since, except in the case of obese people, the other states of predominant clinical condition can only get worse, it is observed that the lower triangle is empty.
::: 

```{r}
#| label: predominant_cond_inc

patient_condition <- dbGetQuery(con,
      "SELECT * FROM patient_condition_translation") 

transition_sum <- patient_condition %>%
  group_by(initial_status, final_status) %>%
  summarise(
    total_N = n(),  # Number of repetitions for each transition
    first_quartile = quantile(duration, 0.25),  # First quantile of duration
    flow_time = quantile(duration, 0.5),  # Median
    third_quartile = quantile(duration, 0.75)   # Third quantile of duration
  ) %>% 
  group_by(initial_status) %>%
  mutate(transition_percentage = total_N / sum(total_N) * 100) %>%
  arrange(initial_status, desc(total_N)) %>%
  select(all_of(c("initial_status","final_status","total_N","transition_percentage",
                  "first_quartile","flow_time","third_quartile"))) 
transition_sum$initial_status = factor(transition_sum$initial_status,
                                       levels = c('cvd','hf','ckd','f','ob','else'))
transition_sum$final_status = factor(transition_sum$final_status,
                                levels = c('cvd','hf','ckd','f','ob','else','death'))

process_matrix <- ggplot(
  transition_sum, aes(x = final_status, y = initial_status)) +
  geom_tile(aes(fill = flow_time), color = "white") +
  geom_text(aes(label = total_N), vjust = 1) +
  scale_fill_distiller() +
  labs(title = "Predominant clinical conditions' changes",
       x = "Final Status",
       y = "Initial Status")+
  theme_minimal() +  # Apply a minimal theme for a cleaner look
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14, face = "bold"))  # Adjust text sizes

ggsave(gsub("src/analysis-scripts/","",here("outputs/predominant_condition_matrix.png")),plot=process_matrix)

```

![Predominant clinical condition's first change in incident patients.](../../outputs/predominant_condition_matrix.png){#fig-predominant_cond_m fig-align="center" width="80%"}

### 3.2. Prevalent patients description

```{r}
#| label: tbl-patient_pre
#| tbl-cap: "Demographic and socioeconomic characteristics of prevalents patients"
#| tbl-colwidths: [60,40]
patient_pre <- dbGetQuery(con,
                          "SELECT *,
                       CASE WHEN sex = 0 THEN 'Male' 
                       ELSE 'Female' END AS sexo,
                       FLOOR(DATEDIFF('day',month_nac,DATE '2017-01-01') / 365.25) 
                       AS 'age',
                       FLOOR(DATEDIFF('day',month_nac, dx_date) / 365.25) 
                       AS 'age_dx'FROM main.patient 
                       WHERE dx_date < '2017-01-01'") 
patient_pre <- patient_pre %>%
  left_join( country2cont %>% select(country, CC), by = "country") %>%
  mutate(education=factor(education, levels=c(0,1,2,3),
      labels=c("Without studies","Primary school",
               "High school","University")),
      copayment=factor(copayment,levels=c(0,1),
                       labels=c("less than 18000","more or equal than 18000")))
patient_pre$CC[patient_pre$country == 724] <- 'Spain'
patient_pre$charlson <- as.factor(patient_pre$charlson)
dependent="sexo"
explanatory=c("age","age_dx","CC","copayment","education", "avg_income")  

patient_pre%>%summary_factorlist(dependent,
                                 explanatory,
                                 total_col = TRUE,
                                 cont="mean",
                                 cont_cut=7,
                                 na_include = TRUE,
                                 na_to_prop =  FALSE, 
                                 include_col_totals_percent	=FALSE,
                                 add_col_totals = TRUE)-> patient_pre_tab
kable(patient_pre_tab, row.names=FALSE, align=c("l", "l", rep("r",5)))

```

```{r}
#| label: tbl-param_pre
#| tbl-cap: "Clinical and lifestyle characteristics of prevalent patients"
#| tbl-colwidths: [60,40]

param_pre <- dbGetQuery(con,"SELECT * FROM param_prevalents_pre_last_view")
param_list <- sort(unique(param_pre$param_name))
param_cat_pre <- dbGetQuery(con,
  "SELECT *, \
  CASE WHEN param_cat_name='physical_activity' AND param_cat_value=0 \
  THEN 'Incapacity' \
  WHEN param_cat_name='physical_activity' AND param_cat_value=1 \
  THEN 'Inactive' \
  WHEN param_cat_name='physical_activity' AND param_cat_value=2 \
  THEN 'Partially Active' \
  WHEN param_cat_name='physical_activity' AND param_cat_value=3 \
  THEN 'Active' \
  WHEN param_cat_name='smoking_status' AND param_cat_value=0 \
  THEN 'Non Smoker' \
  WHEN param_cat_name='smoking_status' AND param_cat_value=1 \
  THEN 'Ex-smoker < 1 year' \
  WHEN param_cat_name='smoking_status' AND param_cat_value=2 \
  THEN 'Ex-smoker >= 1 year' \
  WHEN param_cat_name='smoking_status' AND param_cat_value=3 \
  THEN 'Smoker' \
  WHEN param_cat_name='alcohol' AND param_cat_value=0 \
  THEN 'Abstinent' \
  WHEN param_cat_name='alcohol' AND param_cat_value=1 \
  THEN 'Moderate Drinker' \
  WHEN param_cat_name='alcohol' AND param_cat_value=2 \
  THEN 'Heavy Drinker' \
  WHEN param_cat_name='vaccination_flu' AND param_cat_value=0 \
  THEN 'No' \
  WHEN param_cat_name='vaccination_flu' AND param_cat_value=1 \
  THEN 'Yes' \
  WHEN param_cat_name='working_status' AND param_cat_value=0 \
  THEN 'Active' \
  WHEN param_cat_name='working_status' AND param_cat_value=1 \
  THEN 'Unemployed' \
  WHEN param_cat_name='working_status' AND param_cat_value=2 \
  THEN 'Pensionist' \
  ELSE '' END AS param_cat_value_str
  FROM param_cat_prevalents_pre_last_view WHERE param_cat_name!='vaccination_covid'")
param_cat_list <- sort(unique(param_cat_pre$param_cat_name))
dependent="sexo"


param_pre2unnest <- param_pre %>% 
  pivot_wider( id_cols=patient_id,names_from=param_name,values_from=param_value)%>%
  left_join( patient_pre %>% select(patient_id, sexo), by = "patient_id")

param_cat_pre2unnest <- param_cat_pre %>% 
  pivot_wider( id_cols=patient_id,names_from=param_cat_name,values_from=param_cat_value_str)%>%
  left_join( patient_pre %>% select(patient_id, sexo), by = "patient_id") 

param_pre_tab <- rbind(
  param_pre2unnest %>%
    summary_factorlist(dependent ,
                       param_list,
                       total_col = TRUE,cont="mean",na_include = TRUE,
                       na_to_prop =  FALSE,add_row_totals = TRUE,
                       include_row_missing_col = TRUE,
                       include_col_totals_percent	=FALSE,add_col_totals = TRUE),
  param_cat_pre2unnest %>%
    summary_factorlist(dependent ,
                       param_cat_list,
                       total_col = TRUE,cont="mean",na_include = TRUE,
                       na_to_prop =  FALSE,cont_cut=8,add_row_totals = TRUE,
                       include_row_missing_col = TRUE))
kable(param_pre_tab, row.names=FALSE, align=c("l", "l", rep("r",5)))

```

```{r}
#| label: tbl-use_pre
#| tbl-cap: "Use of Primary Care Services of prevalent patients"
#| tbl-colwidths: [60,40]
patient_pre$deregistration_date <- patient_pre$deregistration_date %>%
  replace_na(as.Date('2023-01-01'))
patient_pre <- patient_pre %>% 
  mutate(follow_up_time=as.numeric(difftime(deregistration_date,                                          as.Date('2016-12-31'),units="days")/365.25))%>%
  filter(follow_up_time!=0)



ss_use_pre <- dbGetQuery(con," SELECT * FROM main.ss_use \
            WHERE patient_id IN (SELECT patient_id FROM main.patient \
                                 WHERE dx_date <'2017-01-01') AND
                         visit_date>='2017-01-01'") %>% mutate(
                           visit_type=factor(visit_type, levels=c(1,2,3,4,5,6,7,8),
                          labels=c("PC_physician", "PC_nurse", "PC_social_worker",
                                   "PC_emergency_service","PC_others",
                                   "Specialized_visit_physician",
                                   "Specialized_visit_nurse",
                                   "Specialized_visit_unknown_professional"))
                         )

ss_use_pre1 <- ss_use_pre %>% 
  filter(visit_loc == 1)
use_pre_freq1 <- as.data.frame.matrix(table(ss_use_pre1$patient_id,ss_use_pre1$visit_type))
use_pre_freq1 <- cbind(patient_id = rownames(use_pre_freq1), use_pre_freq1)
use_pre_freq1_time <- left_join(use_pre_freq1, patient_pre %>% select(patient_id, sex, follow_up_time,dx_date), by = "patient_id") %>%
  mutate(PC_physician= PC_physician/follow_up_time,
         PC_nurse=PC_nurse/follow_up_time,
         PC_social_worker=PC_social_worker/follow_up_time,
         PC_emergency_service=PC_emergency_service/follow_up_time,
         PC_others=PC_others/follow_up_time,
         Specialized_visit_physician=Specialized_visit_physician/follow_up_time,
         Specialized_visit_nurse=Specialized_visit_nurse/follow_up_time,
         Specialized_visit_unknown_professional=Specialized_visit_unknown_professional/follow_up_time,
         sexo=factor(sex, levels=c(0,1), labels=c("Male", "Female"))) 

ss_use_pre2 <- ss_use_pre %>% 
  filter(visit_loc == 2)
use_pre_freq2 <- as.data.frame.matrix(table(ss_use_pre2$patient_id,ss_use_pre2$visit_type))
use_pre_freq2 <- cbind(patient_id = rownames(use_pre_freq2), use_pre_freq2)
use_pre_freq2_time <- left_join(use_pre_freq2, patient_pre %>% select(patient_id, sex, follow_up_time,dx_date), by = "patient_id") %>%
  mutate(PC_physician= PC_physician/follow_up_time,
         PC_nurse=PC_nurse/follow_up_time,
         PC_social_worker=PC_social_worker/follow_up_time,
         PC_emergency_service=PC_emergency_service/follow_up_time,
         PC_others=PC_others/follow_up_time,
         Specialized_visit_physician=Specialized_visit_physician/follow_up_time,
         Specialized_visit_nurse=Specialized_visit_nurse/follow_up_time,
         Specialized_visit_unknown_professional=Specialized_visit_unknown_professional/follow_up_time,
         sexo=factor(sex, levels=c(0,1), labels=c("Male", "Female"))) 

ss_use_pre3 <- ss_use_pre %>% 
  filter(visit_loc == 3)
use_pre_freq3 <- as.data.frame.matrix(table(ss_use_pre3$patient_id,ss_use_pre3$visit_type))
use_pre_freq3 <- cbind(patient_id = rownames(use_pre_freq3), use_pre_freq3)
use_pre_freq3_time <- left_join(use_pre_freq3, patient_pre %>% select(patient_id, sex, follow_up_time,dx_date), by = "patient_id") %>%
  mutate(PC_physician= PC_physician/follow_up_time,
         PC_nurse=PC_nurse/follow_up_time,
         PC_social_worker=PC_social_worker/follow_up_time,
         PC_emergency_service=PC_emergency_service/follow_up_time,
         PC_others=PC_others/follow_up_time,
         Specialized_visit_physician=Specialized_visit_physician/follow_up_time,
         Specialized_visit_nurse=Specialized_visit_nurse/follow_up_time,
         Specialized_visit_unknown_professional=Specialized_visit_unknown_professional/follow_up_time,
         sexo=factor(sex, levels=c(0,1), labels=c("Male", "Female"))) 


use_pre_tab <- rbind(
  rbind(data.frame(label = "at care center", levels = '',
                   Male = '', Female = '', Total = ''),
        use_pre_freq1_time %>%
    summary_factorlist(dependent ,c("PC_physician", "PC_nurse", "PC_social_worker",
                                    "PC_emergency_service","PC_others",
                                    "Specialized_visit_physician",
                                    "Specialized_visit_nurse",
                                    "Specialized_visit_unknown_professional"),
                       total_col = TRUE,cont="mean",cont_cut=1,
                       na_include = TRUE,na_to_prop =  FALSE)),
    rbind(data.frame(label = "at home", levels = '',
                     Male = '', Female = '', Total = ''),
        use_pre_freq2_time %>%
    summary_factorlist(dependent ,c("PC_physician", "PC_nurse", "PC_social_worker",
                                    "PC_emergency_service","PC_others",
                                    "Specialized_visit_physician",
                                    "Specialized_visit_nurse",
                                    "Specialized_visit_unknown_professional"),
                        total_col = TRUE,cont="mean",cont_cut=1,
                        na_include = TRUE,na_to_prop =  FALSE)),
    rbind(data.frame(label = "by telephone or similar", levels = '',
                     Male = '', Female = '', Total = ''),
        use_pre_freq3_time %>%
    summary_factorlist(dependent ,c("PC_physician", "PC_nurse", "PC_social_worker",
                                    "PC_emergency_service","PC_others",
                                    "Specialized_visit_physician",
                                    "Specialized_visit_nurse",
                                    "Specialized_visit_unknown_professional"),
                        total_col = TRUE,cont="mean",cont_cut=1,
                        na_include = TRUE,na_to_prop =  FALSE)))

kable(use_pre_tab, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

```{r}
#| label: db shutdown
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
dbDisconnect(con, shutdown = TRUE)
rm(param_cat_inc,param_cat_inc2unnest,param_cat_pre,param_cat_pre2unnest,param_inc,param_inc_tab,param_inc2unnest,param_pre,param_pre_tab,param_pre2unnest,patient_inc,patient_inc_tab,patient_pre,patient_pre_tab,ss_use_inc,ss_use_inc1,ss_use_inc2,ss_use_inc3,ss_use_pre,ss_use_pre1,ss_use_pre2,ss_use_pre3,use_inc_freq1,use_inc_freq1_time,use_inc_freq2,use_inc_freq2_time,use_inc_freq3,use_inc_freq3_time,use_inc_tab,use_pre_freq1,use_pre_freq1_time,use_pre_freq2,use_pre_freq2_time,use_pre_freq3,use_pre_freq3_time,use_pre_tab,transition_sum)
```

## 4. Healthcare pathways

### 4.1. Patients without predominant clinical condition
::: {.justify}
Choosing patients without any predominant clinical condition we obtain an event log that can be represented in the below process map @fig-pm1_healthcare_else. There is shown how the visits are connected, the absolute number of visits made to each service, the proportion of patients has visited each service, the proportion of patients in which source and target visits were executed directly following each other and the mean number of days it took to make the transition. However, a spaghetti map is obtained and nothing can be concluded. Therefore, we have to simplify the process map and for example only show the most frequent traces covering 20% of the event log as in @fig-pm02_healthcare_else. Moreover, in @fig-healthcare_activity_presence_else appears the percentage of patients' traces each activity is present, and @fig-healthcare_process_matrix_else is the process matrix of the 10 most frequented specialists.
::: 
```{r}
#| label: condition variable in r (else) (hc)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'else'
```

```{r}
#| label: proces map healthcare (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} healtcare analysis')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog_healthcare <- load_log(con, paste0(" SELECT * FROM ss_log WHERE type='",
                                         cond,
                                         "' AND Event NOT IN ('APR','URG')"))
make_process_map_healthcare(evLog_healthcare,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_1_%s.png",
                                                     cond))))
make_process_map_healthcare(evLog_healthcare,0.2,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_02_%s.png",
                                                     cond))))
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog_healthcare %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_process_matrix_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
evLog_healthcare %>% 
  anti_join(evLog_healthcare %>% 
              activity_presence() %>% 
              slice(11:100),
            c('Event'='Event')) %>% 
  process_matrix(frequency("relative-case")) %>% plot()
dev.off()    
rm(evLog_healthcare)
dbDisconnect(con, shutdown = TRUE)

```

![Healthcare event log's process map with all traces](../../outputs/evlog_healthcare_pm_1_else.png){#fig-pm1_healthcare_else fig-align="center" width="80%"}

![Healthcare event log's process map with most frequent traces covering 20%](../../outputs/evlog_healthcare_pm_02_else.png){#fig-pm02_healthcare_else fig-align="center" width="80%"}

![Percentage of patients traces a visit is present](../../outputs/healthcare_activity_presence_else.png){#fig-healthcare_activity_presence_else fig-align="center" width="80%"}

![Process matrix of visits](../../outputs/healthcare_process_matrix_else.png){#fig-healthcare_process_matrix_else fig-align="center" width="80%"}

### 4.2. Obesity

```{r}
#| label: condition variable in r (ob) (hc)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'ob'
```

```{r}
#| label: proces map healthcare (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} healtcare analysis')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog_healthcare <- load_log(con, paste0(" SELECT * FROM ss_log WHERE type='",
                                         cond,
                                         "' AND Event NOT IN ('APR','URG')"))
make_process_map_healthcare(evLog_healthcare,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_1_%s.png",
                                                     cond))))
make_process_map_healthcare(evLog_healthcare,0.2,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_02_%s.png",
                                                     cond))))
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog_healthcare %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_process_matrix_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
evLog_healthcare %>% 
  anti_join(evLog_healthcare %>% 
              activity_presence() %>% 
              slice(11:100),
            c('Event'='Event')) %>% 
  process_matrix(frequency("relative-case")) %>% plot()
dev.off()
rm(evLog_healthcare)
dbDisconnect(con, shutdown = TRUE)

```

![Healthcare event log's process map with all traces](../../outputs/evlog_healthcare_pm_1_ob.png){#fig-pm1_healthcare_ob fig-align="center" width="80%"}

![Healthcare event log's process map with most frequent traces covering 20%](../../outputs/evlog_healthcare_pm_02_ob.png){#fig-pm02_healthcare_ob fig-align="center" width="80%"}

![Percentage of patients traces a visit is present](../../outputs/healthcare_activity_presence_ob.png){#fig-healthcare_activity_presence_ob fig-align="center" width="80%"}

![Process matrix of visits](../../outputs/healthcare_process_matrix_ob.png){#fig-healthcare_process_matrix_ob fig-align="center" width="80%"}

### 4.3. Frailty

```{r}
#| label: condition variable in r (f) (hc)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'f'
```

```{r}
#| label: proces map healthcare (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} healtcare analysis')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog_healthcare <- load_log(con, paste0(" SELECT * FROM ss_log WHERE type='",
                                         cond,
                                         "' AND Event NOT IN ('APR','URG')"))
make_process_map_healthcare(evLog_healthcare,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_1_%s.png",
                                                     cond))))
make_process_map_healthcare(evLog_healthcare,0.2,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_02_%s.png",
                                                     cond))))
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog_healthcare %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_process_matrix_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
evLog_healthcare %>% 
  anti_join(evLog_healthcare %>% 
              activity_presence() %>% 
              slice(11:100),
            c('Event'='Event')) %>% 
  process_matrix(frequency("relative-case")) %>% plot()
dev.off()
rm(evLog_healthcare)
dbDisconnect(con, shutdown = TRUE)

```

![Healthcare event log's process map with all traces](../../outputs/evlog_healthcare_pm_1_f.png){#fig-pm1_healthcare_f fig-align="center" width="80%"}

![Healthcare event log's process map with most frequent traces covering 20%](../../outputs/evlog_healthcare_pm_02_f.png){#fig-pm02_healthcare_f fig-align="center" width="80%"}

![Percentage of patients traces a visit is present](../../outputs/healthcare_activity_presence_f.png){#fig-healthcare_activity_presence_f fig-align="center" width="80%"}

![Process matrix of visits](../../outputs/healthcare_process_matrix_f.png){#fig-healthcare_process_matrix_f fig-align="center" width="80%"}

### 4.4. Chronic kidney disease

```{r}
#| label: condition variable in r (ckd) (hc)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'ckd'
```

```{r}
#| label: proces map healthcare (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} healtcare analysis')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog_healthcare <- load_log(con, paste0(" SELECT * FROM ss_log WHERE type='",
                                         cond,
                                         "' AND Event NOT IN ('APR','URG')"))
make_process_map_healthcare(evLog_healthcare,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_1_%s.png",
                                                     cond))))
make_process_map_healthcare(evLog_healthcare,0.2,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_02_%s.png",
                                                     cond))))
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog_healthcare %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_process_matrix_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
evLog_healthcare %>% 
  anti_join(evLog_healthcare %>% 
              activity_presence() %>% 
              slice(11:100),
            c('Event'='Event')) %>% 
  process_matrix(frequency("relative-case")) %>% plot()
dev.off()
rm(evLog_healthcare)
dbDisconnect(con, shutdown = TRUE)

```

![Healthcare event log's process map with all traces](../../outputs/evlog_healthcare_pm_1_ckd.png){#fig-pm1_healthcare_ckd fig-align="center" width="80%"}

![Healthcare event log's process map with most frequent traces covering 20%](../../outputs/evlog_healthcare_pm_02_ckd.png){#fig-pm02_healthcare_ckd fig-align="center" width="80%"}

![Percentage of patients traces a visit is present](../../outputs/healthcare_activity_presence_ckd.png){#fig-healthcare_activity_presence_ckd fig-align="center" width="80%"}

![Process matrix of visits](../../outputs/healthcare_process_matrix_ckd.png){#fig-healthcare_process_matrix_ckd fig-align="center" width="80%"}

### 4.5. Heart failure

```{r}
#| label: condition variable in r (hf) (hc)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'hf'
```

```{r}
#| label: proces map healthcare (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} healtcare analysis')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog_healthcare <- load_log(con, paste0(" SELECT * FROM ss_log WHERE type='",
                                         cond,
                                         "' AND Event NOT IN ('APR','URG')"))
make_process_map_healthcare(evLog_healthcare,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_1_%s.png",
                                                     cond))))
make_process_map_healthcare(evLog_healthcare,0.2,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_02_%s.png",
                                                     cond))))
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog_healthcare %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_process_matrix_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
evLog_healthcare %>% 
  anti_join(evLog_healthcare %>% 
              activity_presence() %>% 
              slice(11:100),
            c('Event'='Event')) %>% 
  process_matrix(frequency("relative-case")) %>% plot()
dev.off()
rm(evLog_healthcare)
dbDisconnect(con, shutdown = TRUE)

```

![Healthcare event log's process map with all traces](../../outputs/evlog_healthcare_pm_1_hf.png){#fig-pm1_healthcare_hf fig-align="center" width="80%"}

![Healthcare event log's process map with most frequent traces covering 20%](../../outputs/evlog_healthcare_pm_02_hf.png){#fig-pm02_healthcare_hf fig-align="center" width="80%"}

![Percentage of patients traces a visit is present](../../outputs/healthcare_activity_presence_hf.png){#fig-healthcare_activity_presence_hf fig-align="center" width="80%"}

![Process matrix of visits](../../outputs/healthcare_process_matrix_hf.png){#fig-healthcare_process_matrix_hf fig-align="center" width="80%"}

### 4.6. CV Disease

```{r}
#| label: condition variable in r (cvd) (hc)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'cvd'
```

```{r}
#| label: proces map healthcare (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} healtcare analysis')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog_healthcare <- load_log(con, paste0(" SELECT * FROM ss_log WHERE type='",
                                         cond,
                                         "' AND Event NOT IN ('APR','URG')"))
make_process_map_healthcare(evLog_healthcare,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_1_%s.png",
                                                     cond))))
make_process_map_healthcare(evLog_healthcare,0.2,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_healthcare_pm_02_%s.png",
                                                     cond))))
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog_healthcare %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("healthcare_process_matrix_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
evLog_healthcare %>% 
  anti_join(evLog_healthcare %>% 
              activity_presence() %>% 
              slice(11:100),
            c('Event'='Event')) %>% 
  process_matrix(frequency("relative-case")) %>% plot()
dev.off()
rm(evLog_healthcare)
dbDisconnect(con, shutdown = TRUE)

```

![Healthcare event log's process map with all traces](../../outputs/evlog_healthcare_pm_1_cvd.png){#fig-pm1_healthcare_cvd fig-align="center" width="80%"}

![Healthcare event log's process map with most frequent traces covering 20%](../../outputs/evlog_healthcare_pm_02_cvd.png){#fig-pm02_healthcare_cvd fig-align="center" width="80%"}

![Percentage of patients traces a visit is present](../../outputs/healthcare_activity_presence_cvd.png){#fig-healthcare_activity_presence_cvd fig-align="center" width="80%"}

![Process matrix of visits](../../outputs/healthcare_process_matrix_cvd.png){#fig-healthcare_process_matrix_cvd fig-align="center" width="80%"}

## 5. Analysis of process indicators

### 5.1. Descriptive analysis
::: {.justify}
We selected incident patients with at least one year of follow-up to create a process indicator's event log. This log includes cholesterol, albumin-creatinine index, glycated hemoglobin, body mass index, blood pressure and glomerular filtration measures, and foot and eye examinations.
::: 
```{python}
#| label: Creating process indicators' event log
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Create process indicators' event log")
con = duckdb.connect(db_path)
evlog_process_ind(con)
con.close()
```

An activity presence analysis is done to see the percentage of presence of each indicator in analyzed traces.

```{r}
#| label: activity presence of process indicators
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
con <- dbConnect(duckdb(), dbdir = db_path)

log_info('Make activity presence of process_indicators')
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs/activity_presence_process_indicators_year1.png")),
    width = 600, height = 750, units = "px")
eventlog <- dbGetQuery(con,
                      "SELECT patient_id,event,date,cycle,actins \
                       FROM process_ind1 WHERE event NOT IN ('INI','FIN') \
                       UNION ALL SELECT patient_id,event, \
                       CAST(date AS TIMESTAMP) + INTERVAL 1 SECOND AS date, \
                       'complete' AS cycle,actins\
                       FROM process_ind1 WHERE event NOT IN ('INI','FIN')")
activity_presence_df <- eventlog %>%
    mutate(resource = NA) %>%
    eventlog(
      case_id = "patient_id",
      activity_id = "event", 
      lifecycle_id = "cycle", 
      activity_instance_id = "actins", 
      timestamp = "date", 
      resource_id = 'resource'
    ) %>% activity_presence()  
plot(activity_presence_df[activity_presence_df$event != "yFIN",]
     )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs/activity_presence_process_indicators_year2.png")),
    width = 600, height = 750, units = "px")
eventlog <- dbGetQuery(con,
                      "SELECT patient_id,event,date,cycle,actins\
                       FROM process_ind2 WHERE actins NOT IN (\
                       SELECT actins FROM process_ind1) \
                       UNION ALL SELECT patient_id,event, \
                       CAST(date AS TIMESTAMP) + INTERVAL 1 SECOND AS date, \
                       'complete' AS cycle,actins\
                       FROM process_ind2 WHERE actins NOT IN (\
                       SELECT actins FROM process_ind1)")
activity_presence_df <- eventlog %>%
    mutate(resource = NA) %>%
    eventlog(
      case_id = "patient_id",
      activity_id = "event", 
      lifecycle_id = "cycle", 
      activity_instance_id = "actins", 
      timestamp = "date", 
      resource_id = 'resource'
    ) %>% activity_presence()  
plot(activity_presence_df[activity_presence_df$event != "yFIN",]
     )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs/activity_presence_process_indicators_year3.png")),
    width = 600, height = 750, units = "px")
eventlog <- dbGetQuery(con,
                      "SELECT patient_id,event,date,cycle,actins\
                       FROM process_ind3 WHERE actins NOT IN (\
                       SELECT actins FROM process_ind2) \
                       UNION ALL SELECT patient_id,event, \
                       CAST(date AS TIMESTAMP) + INTERVAL 1 SECOND AS date, \
                       'complete' AS cycle,actins\
                       FROM process_ind3 WHERE actins NOT IN (\
                       SELECT actins FROM process_ind2)")
activity_presence_df <- eventlog %>%
    mutate(resource = NA) %>%
    eventlog(
      case_id = "patient_id",
      activity_id = "event", 
      lifecycle_id = "cycle", 
      activity_instance_id = "actins", 
      timestamp = "date", 
      resource_id = 'resource'
    ) %>% activity_presence()  
plot(activity_presence_df[activity_presence_df$event != "yFIN",]
     )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs/activity_presence_process_indicators_year4.png")),
    width = 600, height = 750, units = "px")
eventlog <- dbGetQuery(con,
                      "SELECT patient_id,event,date,cycle,actins\
                       FROM process_ind4 WHERE actins NOT IN (\
                       SELECT actins FROM process_ind3) \
                       UNION ALL SELECT patient_id,event, \
                       CAST(date AS TIMESTAMP) + INTERVAL 1 SECOND AS date, \
                       'complete' AS cycle,actins\
                       FROM process_ind4 WHERE actins NOT IN (\
                       SELECT actins FROM process_ind3)")
activity_presence_df <- eventlog %>%
    mutate(resource = NA) %>%
    eventlog(
      case_id = "patient_id",
      activity_id = "event", 
      lifecycle_id = "cycle", 
      activity_instance_id = "actins", 
      timestamp = "date", 
      resource_id = 'resource'
    ) %>% activity_presence()  
plot(activity_presence_df[activity_presence_df$event != "yFIN",]
     )+scale_y_continuous(limits = c(0, 1))
dev.off()

png(filename=gsub("src/analysis-scripts/","",
                  here("outputs/activity_presence_process_indicators_year5.png")),
    width = 600, height = 750, units = "px")
eventlog <- dbGetQuery(con,
                      "SELECT patient_id,event,date,cycle,actins\
                       FROM process_ind5 WHERE actins NOT IN (\
                       SELECT actins FROM process_ind4) \
                       UNION ALL SELECT patient_id,event, \
                       CAST(date AS TIMESTAMP) + INTERVAL 1 SECOND AS date, \
                       'complete' AS cycle,actins\
                       FROM process_ind5 WHERE actins NOT IN (\
                       SELECT actins FROM process_ind4)")
activity_presence_df <- eventlog %>%
    mutate(resource = NA) %>%
    eventlog(
      case_id = "patient_id",
      activity_id = "event", 
      lifecycle_id = "cycle", 
      activity_instance_id = "actins", 
      timestamp = "date", 
      resource_id = 'resource'
    ) %>% activity_presence()  
plot(activity_presence_df[activity_presence_df$event != "yFIN",]
     )+scale_y_continuous(limits = c(0, 1))
dev.off()


dbDisconnect(con, shutdown = TRUE)
```

![Percentage of patients traces an activity is present during the first year](../../outputs/activity_presence_process_indicators_year1.png){#fig-activity_presence_year1 fig-align="center" width="80%"}

![Percentage of patients traces an activity is present during the second year](../../outputs/activity_presence_process_indicators_year2.png){#fig-activity_presence_year2 fig-align="center" width="80%"}

![Percentage of patients traces an activity is present during the third year](../../outputs/activity_presence_process_indicators_year3.png){#fig-activity_presence_year3 fig-align="center" width="80%"}

![Percentage of patients traces an activity is present during the fourth year](../../outputs/activity_presence_process_indicators_year4.png){#fig-activity_presence_year4 fig-align="center" width="80%"}

![Percentage of patients traces an activity is present during the fifth year](../../outputs/activity_presence_process_indicators_year5.png){#fig-activity_presence_year5 fig-align="center" width="80%"}

### 5.2. Adherence to guidelines for process indicators
::: {.justify}
As it has been explained before, in this section, the observed traces are compared with a specific theoretical process. However, instead of utilizing a single Petri net, five Petri nets are employed, one for each year, as the adherence here is considered in annual intervals from diabetes diagnosis date.
::: 
```{python}
#| label: Creating process indicators' conformance analysis
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Create process indicators' conformance analysis")
con = duckdb.connect(db_path)
query = "SELECT * FROM process_ind1"
df_1 = id2process_fitness(con,
                          query,
                          './PN_PI_year1.pnml',
                          pn_png_file='../../outputs/PN_process1.png',
                          ini_place='place37',
                          fin_place='place148',
                          id_col = 'patient_id',
                          event_col = 'event',
                          date_col='date')

query = "SELECT * FROM process_ind2"
df_2 = id2process_fitness(con,
                          query,
                          './PN_PI_year2.pnml',
                          pn_png_file='../../outputs/PN_process2.png',
                          ini_place='place37',
                          fin_place='place148',
                          id_col = 'patient_id',
                          event_col = 'event',
                          date_col='date')
                          
query = "SELECT * FROM process_ind3"
df_3 = id2process_fitness(con,
                          query,
                          './PN_PI_year3.pnml',
                          pn_png_file='../../outputs/PN_process3.png',
                          ini_place='place37',
                          fin_place='place148',
                          id_col = 'patient_id',
                          event_col = 'event',
                          date_col='date')
                          
query = "SELECT * FROM process_ind4"
df_4 = id2process_fitness(con,
                          query,
                          './PN_PI_year4.pnml',
                          pn_png_file='../../outputs/PN_process4.png',
                          ini_place='place37',
                          fin_place='place148',
                          id_col = 'patient_id',
                          event_col = 'event',
                          date_col='date')

query = "SELECT * FROM process_ind5"
df_5 = id2process_fitness(con,
                          query,
                          './PN_PI_year5.pnml',
                          pn_png_file='../../outputs/PN_process5.png',
                          ini_place='place37',
                          fin_place='place148',
                          id_col = 'patient_id',
                          event_col = 'event',
                          date_col='date')
                          
df2year = con.sql("SELECT *,1 AS year FROM df_1 \
                    UNION ALL SELECT *,2 AS year FROM df_2 \
                    UNION ALL SELECT *,3 AS year FROM df_3 \
                    UNION ALL SELECT *,4 AS year FROM df_4 \
                    UNION ALL SELECT *,5 AS year FROM df_5").df()
boxplot1 = sns.boxplot(x = df2year['year'], 
                       y = df2year['fitness'], 
                       palette = 'husl')
fig1 = boxplot1.get_figure()
fig1.savefig("../../outputs/fitness_by_year.png")
plt.close(fig1)

 ## with predominant condition change and hosp   
con.sql("CREATE OR REPLACE TABLE period2process_fitness AS \
            SELECT ID, \
DATEDIFF('day', initial_date,date) AS t_0, \
DATEDIFF('day', initial_date,final_date) AS t_1, fitness,trace_length, initial_date, \
status, MAX(status) OVER (PARTITION BY ID) AS status2 \
FROM (SELECT a.*,COALESCE(b.deregistration_date,'2022-12-31'),\
             COALESCE( LEAD(date, 1) OVER (PARTITION BY ID ORDER BY date), \
             LEAST(deregistration_date, \
                   COALESCE(admission_date,\
                            CAST('2022-12-31' AS DATE)) )) AS final_date, \
             CASE WHEN admission_date=final_date AND (\
             (final_status!=initial_status AND \
              final_status NOT IN ('end','else','ob','f')) OR \
              cause='hosp') \
             THEN 1 ELSE 0 END AS status, \
             MIN(date) OVER (PARTITION BY ID) AS initial_date\
             FROM (SELECT * FROM (SELECT df2year.*, \
                  patient_condition_hosp.date AS admission_date, \
                    patient_condition_hosp.initial_status, \
                    patient_condition_hosp.final_status, \
                    patient_condition_hosp.cause, \
                  FROM df2year LEFT JOIN patient_condition_hosp ON \
                    df2year.ID = patient_condition_hosp.patient_id) \
                      WHERE date<admission_date OR admission_date IS NULL) a \
                  LEFT JOIN patient_incidents_view b ON a.ID=b.patient_id) WHERE t_0!=t_1")
con.sql("CREATE OR REPLACE TABLE window2process_fitness AS \
             SELECT ID, fitness, trace_length,\
             CASE WHEN DATEDIFF('day',date,admission_date)<=yyyy*365 THEN 1 \
                 ELSE 0 END AS status, \
             CASE WHEN status=0 THEN yyyy*365 \
                 ELSE DATEDIFF('day',date,admission_date) END AS time \
             FROM (SELECT * FROM (SELECT df_yyyy.*, \
                  patient_condition_hosp.date AS admission_date \
                  FROM df_yyyy LEFT JOIN patient_condition_hosp ON \
                    df_yyyy.ID = patient_condition_hosp.patient_id) \
                      WHERE (date<admission_date OR admission_date IS NULL) AND \
                          DATEDIFF('day',date,CAST('2022-12-31' AS TIMESTAMP))>=yyyy*365)\
                 ".replace("yyyy",'1'))
con.close()
```

```{r}
#| label: tbl-fitness_pi
#| tbl-cap: "Adherence to process indicators by years"
#| tbl-colwidths: [60,40]
log_info("Process indicators fitness performance")
con <- dbConnect(duckdb(), dbdir = db_path)
tbl_pi_fitness <- dbGetQuery(con, "SELECT ROW_NUMBER() OVER (ORDER BY t_0) AS year, mean, SD, first_quartile,median, third_quartile, n \
        FROM (SELECT  t_0, \
        AVG(fitness) AS mean, \
        STDDEV(fitness) AS SD, \
        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY fitness) AS first_quartile, \
        MEDIAN(fitness) AS median, \
        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY fitness) AS third_quartile, \
        COUNT(*) AS n \
          FROM  period2process_fitness GROUP BY t_0 ORDER BY t_0)")
dbDisconnect(con, shutdown = TRUE)
kable(tbl_pi_fitness, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

![Boxplot of process indicators' traces' fitness by cumulative years)](../../outputs/fitness_by_year.png){#fitness_by_year fig-align="center" width="80%"}

Sex and age and process indicators' fitness are linked with the next plots:

```{python}
#| label: Creating process indicators' conformance analysis by sex and age
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
con = duckdb.connect(db_path)
df2finess = con.sql("SELECT d.*,\
              CASE WHEN p.sex=0 THEN 'male' \
              ELSE 'female' END AS sex, p.age_dx AS age_,\
              CASE WHEN p.age_dx<50 THEN '[0,50)'\
              WHEN p.age_dx>=50 AND p.age_dx<60 THEN '[50,60)' \
              WHEN p.age_dx>=60 AND p.age_dx<70 THEN '[60,70)' \
              WHEN p.age_dx>=70 AND p.age_dx<80 THEN '[70,80)' \
              WHEN p.age_dx>=80 AND p.age_dx<90 THEN '[80,90)' \
              ELSE '[90,+)' END AS age\
              FROM (SELECT *,1 AS year FROM df_1 \
                    UNION ALL SELECT *,2 AS year FROM df_2 \
                    UNION ALL SELECT *,3 AS year FROM df_3 \
                    UNION ALL SELECT *,4 AS year FROM df_4 \
                    UNION ALL SELECT *,5 AS year FROM df_5) d \
              LEFT JOIN patient_incidents_view p ON d.ID = p.patient_id").df()


boxplot2 = sns.boxplot(x = df2finess['sex'], 
                      y = df2finess['fitness'], 
                      hue = df2finess['year'], 
                      palette = 'husl')
plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0, title='Year')
fig2 = boxplot2.get_figure()
fig2.savefig("../../outputs/fitness2sex_by_year.png")
plt.close(fig2)

boxplot3 = sns.boxplot(x = df2finess['age'], 
                      y = df2finess['fitness'], 
                      hue = df2finess['year'], 
                      palette = 'husl',
                      order = ['[0,50)','[50,60)','[60,70)','[70,80)','[80,90)','[90,+)'])
plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0, title='Year')
fig3 = boxplot3.get_figure()
fig3.savefig("../../outputs/fitness2age_by_year.png")
plt.close(fig3)

```

![Boxplot of process indicators' traces' fitness by cumulative year and by sex](../../outputs/fitness2sex_by_year.png){#fitness2sex_by_year fig-align="center" width="80%"}

![Boxplot of process indicators' traces' fitness by cumulative year and by age](../../outputs/fitness2age_by_year.png){#fitness2age_by_year fig-align="center" width="80%"}

Now predominal clinical condition and process indicators' fitness are linked with the next plot:

```{python}
#| label: Creating process indicators' conformance analysis by condition
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
df2cond = con.sql("SELECT d.*, p.type AS type,p.date AS date_fin \
              FROM (SELECT *,1 AS year FROM df_1 \
                    UNION ALL SELECT *,2 AS year FROM df_2 \
                    UNION ALL SELECT *,3 AS year FROM df_3 \
                    UNION ALL SELECT *,4 AS year FROM df_4 \
                    UNION ALL SELECT *,5 AS year FROM df_5) d \
              LEFT JOIN patient_condition p ON d.ID = p.patient_id \
              WHERE d.date<=p.date").df()

boxplot4 = sns.boxplot(x = df2cond['type'], 
                      y = df2cond['fitness'], 
                      hue = df2cond['year'], 
                      palette = 'husl')
plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0, title='Year')
fig4 = boxplot4.get_figure()
fig4.savefig("../../outputs/fitness2cond_by_year.png")
plt.close(fig4)
con.close()
```

![Boxplot of process indicators' traces' fitness by cumulative year and by predominant clinical condition](../../outputs/fitness2cond_by_year.png){#fitness2cond_by_year fig-align="center" width="80%"}

::: {.justify}
A linear model can be employed to describe fitness by examining the effects of key variables. This approach utilizes factors such as sex, age, time, and the individual's clinical predominant condition. By incorporating these variables into a linear model, we can quantify and analyze how each factor influences overall fitness.
:::

```{r}
#| label: process indicators' conformance analysis by different variables
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE

con <- dbConnect(duckdb(), dbdir = db_path)
df <- dbGetQuery(con,"SELECT pp.*, pc.initial_status AS cpc \
            FROM (SELECT p2p.ID, p2p.t_0 AS time, p2p.fitness, piv.age_dx as age,piv.education as education,\
                             CASE WHEN piv.age_dx<50 THEN '[0,50)'\
                             WHEN piv.age_dx>=50 AND piv.age_dx<60 THEN '[50,60)' \
                             WHEN piv.age_dx>=60 AND piv.age_dx<70 THEN '[60,70)' \
                             WHEN piv.age_dx>=70 AND piv.age_dx<80 THEN '[70,80)' \
                             WHEN piv.age_dx>=80 AND piv.age_dx<90 THEN '[80,90)' \
                             ELSE '[90,+)' END AS age_,\
            piv.sex, piv.copayment,piv.charlson FROM period2process_fitness p2p \
            LEFT JOIN patient_incidents_view_ch piv ON p2p.ID=piv.patient_id \
            ) pp LEFT JOIN \
            patient_condition_hosp pc ON pp.ID=pc.patient_id")

dbDisconnect(con, shutdown = TRUE)
df$sex <- as.factor(ifelse(df$sex == 0, 'Male', 'Female'))
df$copayment <- as.factor(ifelse(df$copayment== 0,
                                 "less than 18000","more or equal than 18000"))
df$charlson <- as.factor(df$charlson)
df$cpc <- as.factor(df$cpc)
df$time <- as.factor(df$time)
df$age_ <- as.factor(df$age_)
df$education <- as.factor(df$education)

df <- within(df, cpc <- relevel(cpc, ref = 'else'))
fitness_pi_lm <- lmer(fitness ~ sex  +time+age_+copayment+cpc + (1 | ID), data=df)
rm(df)
summary(fitness_pi_lm)
```

### 5.3. Prediction of clincal outcomes

#### 5.3.1. Time Dependent Cox Model
::: {.justify}
In the next example, we choose fitness, age, sex and charlson's index to try to predict a complication in diabetes (understood a complication as death, a potentially avoidable hospitalization or a predominat clinical condition change to 'cvd','hf' or 'ckd') with a time dependent Cox model, and the summary of it is:
::: 
```{r}
#| label: Time dependent COX (process indicators)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create time dependent Cox model for PI")
con <- dbConnect(duckdb(), dbdir = db_path)
df <- dbGetQuery(con, "SELECT pp.*, pc.initial_status, pc.final_status FROM (SELECT p2p.ID, p2p.t_0, p2p.t_1, p2p.fitness, p2p.status,p2p.status2, piv.age_dx as age, piv.sex, piv.copayment,piv.charlson,piv.country FROM period2process_fitness p2p LEFT JOIN patient_incidents_view_ch piv ON p2p.ID=piv.patient_id) pp LEFT JOIN patient_condition_hosp pc ON pp.ID=pc.patient_id") %>%
  left_join( country2cont %>% select(country, a.3), by = "country")
dbDisconnect(con, shutdown = TRUE)

df$sex <- as.factor(ifelse(df$sex == 0, 'Male', 'Female'))
df$ID2 <- as.numeric(as.factor(df$ID))
df$t_max <- ave(df$t_1, df$ID2, FUN = max)
df$t_min <- ave(df$t_0, df$ID2, FUN = min)
df$country <- df$a.3

time_dep_PI <- coxph(Surv(t_0, t_1, status) ~ age + sex + fitness + charlson,
               data=df)

summary(time_dep_PI)
```

#### 5.3.2. Joint Latent Class Model

Using same predictive variables a joint latent class model of two classes is made:

```{r}
#| label: JLCM model (process indicators)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create JLCM model for PI")
tryCatch(
{### 1 latent class

mj1 <- Jointlcmm(fixed= fitness ~ t_0 ,random =~ t_0, subject="ID2",
                 survival = Surv(t_min,t_max,status2) ~ age+sex+charlson, hazard="Weibull",
                 hazardtype="PH",ng=1,data=df, verbose=FALSE,maxiter=250)
### 2 latent class
mj2PI <- gridsearch(rep = 20, maxiter = 15, minit = mj1, 
                  Jointlcmm(fixed= fitness ~ t_0 ,mixture =~ t_0,
                            random=~t_0,subject="ID2",
                            survival = Surv(t_min,t_max,status2)~ age+sex+charlson,
                            hazard="Weibull",hazardtype="PH",
                            ng=2,data=df, verbose=FALSE),cl=4)

summary(mj2PI)

postprob(mj2PI)

df_pi <- merge(df,mj2PI$pprobY %>%
              mutate(class = case_when(
                class == 1 ~ "class 1",
                class == 2 ~ "class 2")),
              by='ID2',all.x = FALSE)
d1 <- data.frame(t_0=seq(1,1100,length.out=100))
data.new <-data.frame(d1,age=65,sex='Female',charlson=1)
mj2PI.pred <- predictY(mj2PI, data.new , var.time = "t_0")


ggplot(data = df_pi %>% filter(t_0<1100), aes(x = t_0, y = fitness, group = ID2))+ 
  geom_line(colour='grey') + 
  #stat_smooth(aes(group = 1),method = "lm",se=TRUE) +
  stat_summary(aes(group = 1), geom = "point", fun = mean, shape = 16, size = 2) + 
  geom_line(data=data.frame(mj2PI.pred$times,mj2PI.pred$pred,class='class 1'), aes(t_0, Ypred_class1,group = 1), color = "red", linetype = "dashed",size=1) +
  geom_line(data=data.frame(mj2PI.pred$times,mj2PI.pred$pred,class='class 2'), aes(t_0, Ypred_class2,group = 1), color = "red", linetype = "dashed",size=1) +
  facet_grid(. ~ class) +   
  labs(x = "Days", y = "Fitness", col = "class") + 
  guides(col = guide_legend(nrow = 3),)
ggsave(filename=gsub("src/analysis-scripts/","",
                  here("outputs/joint1_PI.png")),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)


survfit(Surv(t_min, t_max, status2) ~ class, data=df_pi %>%
          select(ID2,t_min,t_max,status2,class) %>% unique()) %>%
  autoplot(xlab = "Days", ylab = "Survival probability")
ggsave(filename=gsub("src/analysis-scripts/","",
                  here("outputs/joint2_PI.png")),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)},
error = function(cond_) {
            message(conditionMessage(cond_))
        }
)

log_info('Analyses finish')

```

#### 5.3.3. Two time windows Cox Model

A Cox survival model with two time windows is implemented below:

```{r}
#| label: COX (process indicators)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
con <- dbConnect(duckdb(), dbdir = db_path)

df <- dbGetQuery(con, "SELECT w2p.ID,  w2p.fitness, w2p.status, w2p.time, piv.age, piv.sex, piv.copayment,piv.charlson FROM window2process_fitness w2p LEFT JOIN patient_incidents_view_ch piv ON w2p.ID=piv.patient_id")
dbDisconnect(con, shutdown = TRUE)

df$sex <- as.factor(ifelse(df$sex == 0, 'Male', 'Female'))

cox2w_PI <- coxph(Surv(time, status) ~ age + sex + fitness + charlson,
               data=df)

summary(cox2w_PI)

```

## 6. Analysis of therapeutic traces

### 6.1. Patients without predominant clinical condition

#### 6.1.1. Treatment event log

```{python}
#| label: condition variable in python (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond = 'else'
```

```{r}
#| label: condition variable in r (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'else'
```

```{python}
#| label: Preprocessing of raw event log (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
con = duckdb.connect(db_path)
if notnan_p>0.98:
  logging.info("Generate event log of %s patients from prescriptions", cond)
  evlog_creation_by_prescriptions(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv')
else:
  logging.info("Generate event log of %s patients from dispensations", cond)
  evlog_creation_by_dispensations(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv',
    nac_path='./Nomenclator_de_Facturacion.csv')
```

```{python}
#| label: event log (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Filter event log of %s patients", cond)
df_ = con.sql(f"SELECT * FROM evlog_raw_{cond}").df()

def df2dict(df_):
  '''Filtering length=2 traces and obtain id2trace dict
    
    Args:
      df_ (dataframe): event log 
    Returns:
      df (dataframe): filtered event log (without cycle sense)
      df_ (dataframe): filtered event log
      id2trace_ (dict): patients' ids as keys and their traces (list) as values
  '''
  df = df_[df_['cycle']=='start']
  df.index = range(len(df))
  id2trace_ = dict()            
  for id in set(df['ID']):       
      id2trace_[id] = list(df['Event'][df['ID'] == id])
 
  #drop len<=2 traces
  del_list = []
  for i in range(len(df)):
      if  len(id2trace_[df['ID'][i]])<=2 :
          del_list.append(i)
  for i in del_list:
      try:
          del id2trace_[df['ID'][i]]
      except:
          continue
  df = df.drop(del_list, axis=0)
  df.index = range(len(df))

  del_list2 = []
  for id in set(df_['ID']):
      if id not in id2trace_:
          del_list2+= list(df_[df_['ID']==id].index)
  df_ = df_.drop(del_list2, axis=0)
  df_.index = range(len(df_))
  
  return df_,id2trace_

df_, id2trace = df2dict(df_)
con.sql(f"CREATE OR REPLACE TABLE eventlog_{cond} AS SELECT * FROM df_")
patients = sorted(id2trace.keys())
traces = list(id2trace[id] for id in patients)     
con.close()
```

```{r}
#| label: Loading event log in R (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info('Load {cond} eventlog')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog <- load_log(con, paste0("SELECT * FROM eventlog_",cond))
dbDisconnect(con, shutdown = TRUE)
```
::: {.justify}
Choosing patients without any predominant clinical condition and after some preprocessing we obtain an event log that can be represented in the below process map @fig-pm1_else. There is shown how the events are connected, the mean number of days patients spent in each event, the proportion of patients in which the event was presented, the absolute number of times source and target events were executed directly following each other and the proportion of patients in which source and target events were executed directly following each other. However, a spaghetti map is obtained and nothing can be concluded. Therefore, we have to simplify the process map and for example only show the most frequent traces covering 20% of the event log as in @fig-pm02_else. Moreover, in @fig-activity_presence_else we show percentage of patients' traces each activity is present.
::: 
```{r}
#| label: proces map and activity presence (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} process map')
make_process_map(evLog,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_pm_1_%s.png",
                                                     cond))))
make_process_map(evLog,0.2,gsub("src/analysis-scripts/","",
                                here("outputs",sprintf("evlog_pm_02_%s.png",
                                                     cond))))
log_info('Make activity presence of {cond} patients')
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()
```

![Event log's process map with all traces](../../outputs/evlog_pm_1_else.png){#fig-pm1_else fig-align="center" width="80%"}

![Event log's process map with most frequent traces covering 20%](../../outputs/evlog_pm_02_else.png){#fig-pm02_else fig-align="center" width="80%"}

![Percentage of patients traces an activity is present](../../outputs/activity_presence_else.png){#fig-activity_presence_else fig-align="center" width="80%"}

#### 6.1.2. Clustering traces
::: {.justify}
Once the set of traces to analyze are selected, there is a need to choose a distance measure to clustering. In this example Levenshtein similarity is chosen to calculate the distance matrix.
::: 
```{python}
#| label: dm calculation (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make distance matrix of %s patients", cond)
measure_f = Levenshtein.normalized_similarity
dm = calculate_dm_ED(traces,measure_f)
```
::: {.justify}
When distance matrix is acquired, we are able to cluster. However, the number of clusters have to be fixed before. With these figures we are able to conclude what could be the optimal number of clusters.
::: 
```{python}
#| label: dendograms (else)
#| eval: TRUE
#| echo: FALSE
#| output: FALSE
logging.info("Make dendogram of %s patients", cond)
dendogram(dm,'../../outputs/dendogram_%s.png' % cond)
```

```{python}
#| label: kelbow (else)
#| eval: TRUE
#| echo: FALSE
if len(traces)>25:
  n_clusters = kelbow(dm,cond,elbow_metric='distortion',locate_elbow=True)
#kelbow(dm,elbow_metric='calinski_harabasz',locate_elbow=False)
else:
  n_clusters=1
```

![Distance matrix's dendogram](../../outputs/dendogram_else.png){#fig-dendogram_else fig-align="center" width="80%"}

![Distance matrix's elbow method's graphic](../../outputs/distortion_else.png){#fig-kelbow_else fig-align="center" width="80%"}

```{python}
#| label: clustering (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make clustering of %s patients", cond)
con = duckdb.connect(db_path)
df_ = clust(n_clusters,dm,df_,id2trace,patients)
con.sql(f"CREATE OR REPLACE TABLE clust_{cond} AS SELECT DISTINCT ID,cluster FROM df_")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust AS SELECT \
  eventlog_{cond}.ID,date,nid,Event,cycle,actins,cluster FROM eventlog_{cond} \
  LEFT JOIN clust_{cond} ON eventlog_{cond}.ID = clust_{cond}.ID ")
con.sql(f"CREATE OR REPLACE VIEW cluster_histogram_{cond} AS\
  SELECT cluster, COUNT(DISTINCT ID) AS freq \
  FROM eventlog_{cond}_clust GROUP BY cluster")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust_filtered AS \
   SELECT * FROM eventlog_{cond}_clust \
  WHERE cluster IN (SELECT cluster FROM cluster_histogram_{cond} \
  WHERE freq>=25 OR freq>=(SELECT SUM(freq) * 0.05 \
  FROM cluster_histogram_{cond}))")

del dm
del df_
```
::: {.justify}
Choosing the optimal number of clusters, too small clusters can appear, but we can exclude those of less than 30 traces to avoid having clusters of low representation. The process map and the most frequent traces of one of these clusters that remain are the followings.
::: 
```{python}
#| label: trace explorer (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make trace explorer figures of %s patients", cond)
col_dic = trace_explorer(con,cond)
con.close()
```

```{r}
#| label: process explorer (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make process maps figures of different clusters of {cond} patients')
con <- dbConnect(duckdb(), dbdir = db_path)
process_map_by_cluster(
  load_log(con,
           paste0("SELECT * FROM eventlog_",cond,"_clust_filtered")),
  0.25,cond)
dbDisconnect(con, shutdown = TRUE)
```

::: {#fig-cluster0_else .column-page layout-ncol="2"}
![5 most frequent traces](../../outputs/t_cluster_else_0.png){#fig-traceexplorer0_else}

![Process map covering 25% most frequent traces](../../outputs/pm_cluster_else_0.png){#fig-processmap0_else}

Cluster 0
:::

#### 6.1.3. Adherence to therapeutic guidelines


```{python}
#| label: create fitness by period table (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Create  %s patients prediction models", cond)
con = duckdb.connect(db_path)
id2treat_fitness_by_interval(con, cond,
            pn_file='./PN_%s.pnml' % cond,
            pn_png_file='../../outputs/PN_%s.png' % cond,
            ini_place='place100',fin_place='place111',
            fixed_period_time=90)
con.close()
```

```{r}
#| label: tbl-fitness_else
#| tbl-cap: "Adherence to therapeutic guidelines of patients without predominant clinical conditions."
#| tbl-colwidths: [60,40]
log_info("Fitness performance {cond} patients ")
con <- dbConnect(duckdb(), dbdir = db_path)
tbl_else_fitness <- dbGetQuery(con, paste0("SELECT  AVG(fitness) AS mean, \
        STDDEV(fitness) AS SD, \
        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY fitness) AS first_quartile, \
        MEDIAN(fitness) AS median, \
        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY fitness) AS third_quartile, \
        COUNT(*) AS n \
          FROM  (SELECT *,ROW_NUMBER() OVER (\
                PARTITION BY ID ORDER BY t_0 DESC) AS rn FROM period2fitness_",cond,") \
        WHERE rn=1"))
dbDisconnect(con, shutdown = TRUE)
kable(tbl_else_fitness, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

::: {.justify}
As in the analysis of process indicators adherence here a linear model can be employed to analyse the effect of some variables on fitness:
:::

```{r}
#| label: treatment conformance analysis by different variables (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE

log_info("Create  {cond} patients fitness regressions")
con <- dbConnect(duckdb(), dbdir = db_path)
df <- dbGetQuery(con, paste0("SELECT p2f.ID,p2f.t_0,p2f.t_1,p2f.fitness,\
                             p2f.status,p2f.status2,\
                             piv.age_dx as age,\
                             CASE WHEN piv.age_dx<50 THEN '[0,50)'\
                             WHEN piv.age_dx>=50 AND piv.age_dx<60 THEN '[50,60)' \
                             WHEN piv.age_dx>=60 AND piv.age_dx<70 THEN '[60,70)' \
                             WHEN piv.age_dx>=70 AND piv.age_dx<80 THEN '[70,80)' \
                             WHEN piv.age_dx>=80 AND piv.age_dx<90 THEN '[80,90)' \
                             ELSE '[90,+)' END AS age_,\
                             piv.sex,piv.copayment,piv.charlson \
                             FROM period2fitness_",cond," p2f \
                             LEFT JOIN patient_incidents_view_ch piv \
                             ON p2f.ID=piv.patient_id"))
dbDisconnect(con, shutdown = TRUE)

df$sex <- as.factor(ifelse(df$sex == 0, 'Male', 'Female'))
df$age_ <- as.factor(df$age_)
df$ID2 <- as.numeric(as.factor(df$ID))
df$t_max <- ave(df$t_1, df$ID2, FUN = max)
df$t_min <- ave(df$t_0, df$ID2, FUN = min)
df$copayment <- as.factor(ifelse(df$copayment== 0,
                                 "less than 18000","more or equal than 18000"))
summary(lmer(fitness ~ sex +t_0+age_+copayment+(1 | ID), data=df))

```

::: {.justify}
Once traces are clusterized, with a boxplot is easy to show that each cluster's behavior with respect to the treatment guides is different. Comparing traces with @fig-petrinet_else, calculating the fitness (1 being perfect match with the petri net and 0 being the lowest possible fitness) of each trace and grouping by cluster results in\_ @fig-fitness_by_cluster_else.
::: 
```{python}
#| label: fitness boxplot (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Analyze conformance checking by clusters of %s patients", cond)
con = duckdb.connect(db_path)
treatments_clusters_boxplot(con,cond,
            output_png='../../outputs/fitness_by_cluster_%s.png' % cond)
con.close()
```

![Traces fitness distribution by cluster](../../outputs/fitness_by_cluster_else.png){#fig-fitness_by_cluster_else fig-align="center" width="80%"}

#### 6.1.4. Prediction of clinical outcomes

##### 6.1.4.1. Time Dependent Cox Model
::: {.justify}
In the next example, we choose fitness, age, sex and charlson's index to try to predict a complication in diabetes (understood a complication as death, a potentially avoidable hospitalization or a predominal clinical condition change to 'cvd','hf' or 'ckd') with a time dependet Cox model, and the summary of it is:
::: 

```{r}
#| label: Time dependent COX (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create time dependent Cox {cond} model")
time_dep_else <- coxph(Surv(t_0, t_1, status) ~ age + sex + fitness + charlson,
               data=df)

summary(time_dep_else)
```

##### 6.1.4.2. Joint Latent Class Model

Using same predictive variables a joint latent class model of two classes is made:

```{r}
#| label: JLCM model (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create JLCM {cond} model")
tryCatch(
{### 1 latent class

mj1 <- Jointlcmm(fixed= fitness ~ t_0 ,random =~ t_0, subject="ID2",
                 survival = Surv(t_min,t_max,status2) ~ age+sex+charlson, hazard="Weibull",
                 hazardtype="PH",ng=1,data=df, verbose=FALSE,maxiter=250)
### 2 latent class
mj2else <- gridsearch(rep = 20, maxiter = 15, minit = mj1, 
                  Jointlcmm(fixed= fitness ~ t_0 ,mixture =~ t_0,
                            random=~t_0,subject="ID2",
                            survival = Surv(t_min,t_max,status2)~ age+sex+charlson,
                            hazard="Weibull",hazardtype="PH",
                            ng=2,data=df, verbose=FALSE),cl=4)

summary(mj2else)

postprob(mj2else)

df <- merge(df,mj2else$pprobY %>%
              mutate(class = case_when(
                class == 1 ~ "class 1",
                class == 2 ~ "class 2")),
              by='ID2',all.x = FALSE)
d1 <- data.frame(t_0=seq(1,1100,length.out=100))
data.new <-data.frame(d1,age=65,sex='Female',charlson=1)
mj2else.pred <- predictY(mj2else, data.new , var.time = "t_0")

ggplot(data = df %>% filter(t_0<1100), aes(x = t_0, y = fitness, group = ID2))+ 
  geom_line(colour='grey') + 
  #stat_smooth(aes(group = 1),method = "lm",se=TRUE) +
  stat_summary(aes(group = 1), geom = "point", fun = mean, shape = 16, size = 2) + 
  geom_line(data=data.frame(mj2else.pred$times,mj2else.pred$pred,class='class 1'), aes(t_0, Ypred_class1,group = 1), color = "red", linetype = "dashed",size=1) +
  geom_line(data=data.frame(mj2else.pred$times,mj2else.pred$pred,class='class 2'), aes(t_0, Ypred_class2,group = 1), color = "red", linetype = "dashed",size=1) +
  facet_grid(. ~ class) +   
  labs(x = "Days", y = "Fitness", col = "class") + 
  guides(col = guide_legend(nrow = 3),)
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint1_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)


survfit(Surv(t_min, t_max, status2) ~ class, data=df %>%
          select(ID2,t_min,t_max,status2,class) %>% unique()) %>%
  autoplot(xlab = "Days", ylab = "Survival probability")
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint2_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)},
error = function(cond_) {
            message(conditionMessage(cond_))
        }
)

```

##### 6.1.4.3. Two time windows Cox Model

Moreover a Cox survival model with two time windows is implemented below:

```{r}
#| label: 2 windows cox (else)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create two windows cox {cond} model")
df <- df %>% 
  filter(t_max > 270) %>% 
  filter(t_0==270) %>% 
  select(ID,fitness,status2,age,age_,sex,copayment,charlson,ID2,t_min,t_max)
df$status3 <- ifelse(df$t_max<=630 & df$status2==1, 1, 0)
df$t_max <- pmin(df$t_max-270,360)

cox2w_else <- coxph(Surv(t_max, status3) ~ age + sex + fitness + charlson,
               data=df)

summary(cox2w_else)

```

### 6.2. Obesity

#### 6.2.1. Treatment event log

```{python}
#| label: condition variable in python (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond = 'ob'
```

```{r}
#| label: condition variable in r (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'ob'
```

```{python}
#| label: Preprocessing of raw event log (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
con = duckdb.connect(db_path)
if notnan_p>0.98:
  logging.info("Generate event log of %s patients from prescriptions", cond)
  evlog_creation_by_prescriptions(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv')
else:
  logging.info("Generate event log of %s patients from dispensations", cond)
  evlog_creation_by_dispensations(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv',
    nac_path='./Nomenclator_de_Facturacion.csv')
```

```{python}
#| label: event log (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Filter event log of %s patients", cond)
df_ = con.sql(f"SELECT * FROM evlog_raw_{cond}").df()

df_, id2trace = df2dict(df_)
con.sql(f"CREATE OR REPLACE TABLE eventlog_{cond} AS SELECT * FROM df_")
patients = sorted(id2trace.keys())
traces = list(id2trace[id] for id in patients)     
con.close()
```

```{r}
#| label: Loading event log in R (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info('Load {cond} eventlog')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog <- load_log(con, paste0("SELECT * FROM eventlog_",cond))
dbDisconnect(con, shutdown = TRUE)
```

Choosing patients with obesity and after some preprocessing we obtain a new event log to make the same analysis has done before.

```{r}
#| label: proces map and activity presence (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} process map')
make_process_map(evLog,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_pm_1_%s.png",
                                                     cond))))
make_process_map(evLog,0.2,gsub("src/analysis-scripts/","",
                                here("outputs",sprintf("evlog_pm_02_%s.png",
                                                     cond))))
log_info('Make activity presence of {cond} patients')
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()

```

![Event log's process map with all traces](../../outputs/evlog_pm_1_ob.png){#fig-pm1_ob fig-align="center" width="80%"}

![Event log's process map with most frequent traces covering 20%](../../outputs/evlog_pm_02_ob.png){#fig-pm02_ob fig-align="center" width="80%"}

![Percentage of patients traces an activity is present](../../outputs/activity_presence_ob.png){#fig-activity_presence_ob fig-align="center" width="80%"}

#### 6.2.2. Clustering traces

```{python}
#| label: dm calculation (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make distance matrix of %s patients", cond)
measure_f = Levenshtein.normalized_similarity
dm = calculate_dm_ED(traces,measure_f)
```

```{python}
#| label: dendograms (ob)
#| eval: TRUE
#| echo: FALSE
#| output: FALSE
logging.info("Make dendogram of %s patients", cond)
dendogram(dm,'../../outputs/dendogram_%s.png' % cond)
```

```{python}
#| label: kelbow (ob)
#| eval: TRUE
#| echo: FALSE
if len(traces)>25:
  n_clusters = kelbow(dm,cond,elbow_metric='distortion',locate_elbow=True)
#kelbow(dm,elbow_metric='calinski_harabasz',locate_elbow=False)
else:
  n_clusters=1
```

![Distance matrix's dendogram](../../outputs/dendogram_ob.png){#fig-dendogram_ob fig-align="center" width="80%"}

![Distance matrix's elbow method's graphic](../../outputs/distortion_ob.png){#fig-kelbow_ob fig-align="center" width="80%"}

```{python}
#| label: clustering (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make clustering of %s patients", cond)
con = duckdb.connect(db_path)
df_ = clust(n_clusters,dm,df_,id2trace,patients)
con.sql(f"CREATE OR REPLACE TABLE clust_{cond} AS SELECT DISTINCT ID,cluster FROM df_")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust AS SELECT \
  eventlog_{cond}.ID,date,nid,Event,cycle,actins,cluster FROM eventlog_{cond} \
  LEFT JOIN clust_{cond} ON eventlog_{cond}.ID = clust_{cond}.ID ")
con.sql(f"CREATE OR REPLACE VIEW cluster_histogram_{cond} AS\
  SELECT cluster, COUNT(DISTINCT ID) AS freq \
  FROM eventlog_{cond}_clust GROUP BY cluster")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust_filtered AS \
   SELECT * FROM eventlog_{cond}_clust \
  WHERE cluster IN (SELECT cluster FROM cluster_histogram_{cond} \
  WHERE freq>=25 OR freq>=(SELECT SUM(freq) * 0.05 \
  FROM cluster_histogram_{cond}))")

```

```{python}
#| label: trace explorer (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make trace explorer figures of %s patients", cond)
col_dic = trace_explorer(con,cond,color_dict=col_dic)
con.close()
```

```{r}
#| label: process explorer (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make process maps figures of different clusters of {cond} patients')
con <- dbConnect(duckdb(), dbdir = db_path)
process_map_by_cluster(
  load_log(con,
           paste0("SELECT * FROM eventlog_",cond,"_clust_filtered")),
  0.25,cond)
dbDisconnect(con, shutdown = TRUE)
```

::: {#fig-cluster0_ob .column-page layout-ncol="2"}
![5 most frequent traces](../../outputs/t_cluster_ob_0.png){#fig-traceexplorer0_ob}

![Process map covering 25% most frequent traces](../../outputs/pm_cluster_ob_0.png){#fig-processmap0_ob}

Cluster 0
:::

#### 6.2.3. Adherence to therapeutic guidelines

```{python}
#| label: create fitness by period table (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Create  %s patients prediction models", cond)
con = duckdb.connect(db_path)
id2treat_fitness_by_interval(con, cond,
            pn_file='./PN_%s.pnml' % cond,
            pn_png_file='../../outputs/PN_%s.png' % cond,
            ini_place='place100',fin_place='place111',
            fixed_period_time=90)
con.close()
```

```{r}
#| label: tbl-fitness_ob
#| tbl-cap: "Adherence to therapeutic guidelines of patients with obesity"
#| tbl-colwidths: [60,40]
log_info("Fitness performance {cond} patients")
con <- dbConnect(duckdb(), dbdir = db_path)
tbl_else_fitness <- dbGetQuery(con, paste0("SELECT  AVG(fitness) AS mean, \
        STDDEV(fitness) AS SD, \
        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY fitness) AS first_quartile, \
        MEDIAN(fitness) AS median, \
        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY fitness) AS third_quartile, \
        COUNT(*) AS n \
          FROM  (SELECT *,ROW_NUMBER() OVER (\
                PARTITION BY ID ORDER BY t_0 DESC) AS rn FROM period2fitness_",cond,") \
        WHERE rn=1"))
dbDisconnect(con, shutdown = TRUE)
kable(tbl_else_fitness, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

```{r}
#| label: treatment conformance analysis by different variables (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE

log_info("Create  {cond} patients fitness regressions")
con <- dbConnect(duckdb(), dbdir = db_path)
df <- dbGetQuery(con, paste0("SELECT p2f.ID,p2f.t_0,p2f.t_1,p2f.fitness,\
                             p2f.status,p2f.status2,\
                             piv.age_dx as age,\
                             CASE WHEN piv.age_dx<50 THEN '[0,50)'\
                             WHEN piv.age_dx>=50 AND piv.age_dx<60 THEN '[50,60)' \
                             WHEN piv.age_dx>=60 AND piv.age_dx<70 THEN '[60,70)' \
                             WHEN piv.age_dx>=70 AND piv.age_dx<80 THEN '[70,80)' \
                             WHEN piv.age_dx>=80 AND piv.age_dx<90 THEN '[80,90)' \
                             ELSE '[90,+)' END AS age_,\
                             piv.sex,piv.copayment,piv.charlson \
                             FROM period2fitness_",cond," p2f \
                             LEFT JOIN patient_incidents_view_ch piv \
                             ON p2f.ID=piv.patient_id"))
dbDisconnect(con, shutdown = TRUE)

df$sex <- as.factor(ifelse(df$sex == 0, 'Male', 'Female'))
df$age_ <- as.factor(df$age_)
df$ID2 <- as.numeric(as.factor(df$ID))
df$t_max <- ave(df$t_1, df$ID2, FUN = max)
df$t_min <- ave(df$t_0, df$ID2, FUN = min)
df$copayment <- as.factor(ifelse(df$copayment== 0,
                                 "less than 18000","more or equal than 18000"))
summary(lmer(fitness ~ sex +t_0+age_+copayment+(1 | ID), data=df))

```


```{python}
#| label: fitness boxplot (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Analyze conformance checking by clusters of %s patients", cond)
con = duckdb.connect(db_path)
treatments_clusters_boxplot(con,cond,
            output_png='../../outputs/fitness_by_cluster_%s.png' % cond)
con.close()
```

![Traces fitness distribution by cluster](../../outputs/fitness_by_cluster_ob.png){#fig-fitness_by_cluster_ob fig-align="center" width="80%"}

#### 6.2.4. Prediction of clinical outcomes

##### 6.2.4.1. Time Dependent Cox Model
::: {.justify}
In the next example, we choose fitness, age, sex and charlson's index to try to predict a complication in diabetes (understood a complication as death, a potentially avoidable hospitalization or a predominal clinical condition change to 'cvd','hf' or 'ckd') with a time dependet Cox model, and the summary of it is:
::: 

```{r}
#| label: Time dependent COX (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create time dependent Cox {cond} model")
time_dep_ob <- coxph(Surv(t_0, t_1, status) ~ age + sex + fitness + charlson,
               data=df)

summary(time_dep_ob)
```

##### 6.2.4.2. Joint Latent Class Model

Using same predictive variables a joint latent class model of two classes is made:

```{r}
#| label: JLCM model (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create JLCM {cond} model")
tryCatch(
{mj1 <- Jointlcmm(fixed= fitness ~ t_0 ,random =~ t_0, subject="ID2",
                 survival = Surv(t_min,t_max,status2) ~ age+sex+charlson, hazard="Weibull",
                 hazardtype="PH",ng=1,data=df, verbose=FALSE,maxiter=250)
### 2 latent class
mj2ob <- gridsearch(rep = 20, maxiter = 15, minit = mj1, 
                  Jointlcmm(fixed= fitness ~ t_0 ,mixture =~ t_0,
                            random=~t_0,subject="ID2",
                            survival = Surv(t_min,t_max,status2)~ age+sex+charlson,
                            hazard="Weibull",hazardtype="PH",
                            ng=2,data=df, verbose=FALSE),cl=4)

summary(mj2ob)

postprob(mj2ob)

df <- merge(df,mj2ob$pprobY %>%
              mutate(class = case_when(
                class == 1 ~ "class 1",
                class == 2 ~ "class 2")),
              by='ID2',all.x = FALSE)
d1 <- data.frame(t_0=seq(1,1100,length.out=100))
data.new <-data.frame(d1,age=65,sex='Female',charlson=1)
mj2ob.pred <- predictY(mj2ob, data.new , var.time = "t_0")

ggplot(data = df %>% filter(t_0<1100), aes(x = t_0, y = fitness, group = ID2))+ 
  geom_line(colour='grey') + 
  #stat_smooth(aes(group = 1),method = "lm",se=TRUE) +
  stat_summary(aes(group = 1), geom = "point", fun = mean, shape = 16, size = 2) + 
  geom_line(data=data.frame(mj2ob.pred$times,mj2ob.pred$pred,class='class 1'), aes(t_0, Ypred_class1,group = 1), color = "red", linetype = "dashed",size=1) +
  geom_line(data=data.frame(mj2ob.pred$times,mj2ob.pred$pred,class='class 2'), aes(t_0, Ypred_class2,group = 1), color = "red", linetype = "dashed",size=1) +
  facet_grid(. ~ class) +   
  labs(x = "Days", y = "Fitness", col = "class") + 
  guides(col = guide_legend(nrow = 3),)
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint1_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)


survfit(Surv(t_min, t_max, status2) ~ class, data=df %>%
          select(ID2,t_min,t_max,status2,class) %>% unique()) %>%
  autoplot(xlab = "Days", ylab = "Survival probability")
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint2_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)},
error = function(cond_) {
            message(conditionMessage(cond_))
        }
)

```

##### 6.2.4.3. Two time windows Cox Model

Moreover a Cox survival model with two time windows is implemented below:

```{r}
#| label: 2 windows cox (ob)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create two windows cox {cond} model")
df <- df %>% 
  filter(t_max > 270) %>% 
  filter(t_0==270) %>% 
  select(ID,fitness,status2,age,age_,sex,copayment,charlson,ID2,t_min,t_max)
df$status3 <- ifelse(df$t_max<=630 & df$status2==1, 1, 0)
df$t_max <- pmin(df$t_max-270,360)

cox2w_ob <- coxph(Surv(t_max, status3) ~ age + sex + fitness + charlson,
               data=df)

summary(cox2w_ob)
```

### 6.3. Frailty

#### 6.3.1. Treatment event log

```{python}
#| label: condition variable in python (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond = 'f'
```

```{r}
#| label: condition variable in r (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'f'
```

```{python}
#| label: Preprocessing of raw event log (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
con = duckdb.connect(db_path)
if notnan_p>0.98:
  logging.info("Generate event log of %s patients from prescriptions", cond)
  evlog_creation_by_prescriptions(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv')
else:
  logging.info("Generate event log of %s patients from dispensations", cond)
  evlog_creation_by_dispensations(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv',
    nac_path='./Nomenclator_de_Facturacion.csv')
```

```{python}
#| label: event log (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Filter event log of %s patients", cond)
df_ = con.sql(f"SELECT * FROM evlog_raw_{cond}").df()

df_, id2trace = df2dict(df_)
con.sql(f"CREATE OR REPLACE TABLE eventlog_{cond} AS SELECT * FROM df_")
patients = sorted(id2trace.keys())
traces = list(id2trace[id] for id in patients)     
con.close()
```

```{r}
#| label: Loading event log in R (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info('Load {cond} eventlog')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog <- load_log(con, paste0("SELECT * FROM eventlog_",cond))
dbDisconnect(con, shutdown = TRUE)
```

Choosing patients with frailty and after some preprocessing we obtain a new event log to make the same analysis has done before.

```{r}
#| label: proces map and activity presence (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} process map')
make_process_map(evLog,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_pm_1_%s.png",
                                                     cond))))
make_process_map(evLog,0.2,gsub("src/analysis-scripts/","",
                                here("outputs",sprintf("evlog_pm_02_%s.png",
                                                     cond))))
log_info('Make activity presence of {cond} patients')
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()

```

![Event log's process map with all traces](../../outputs/evlog_pm_1_f.png){#fig-pm1_f fig-align="center" width="80%"}

![Event log's process map with most frequent traces covering 20%](../../outputs/evlog_pm_02_f.png){#fig-pm02_f fig-align="center" width="80%"}

![Percentage of patients traces an activity is present](../../outputs/activity_presence_f.png){#fig-activity_presence_f fig-align="center" width="80%"}

#### 6.3.2. Clustering traces

```{python}
#| label: dm calculation (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make distance matrix of %s patients", cond)
measure_f = Levenshtein.normalized_similarity
dm = calculate_dm_ED(traces,measure_f)
```

```{python}
#| label: dendograms (f)
#| eval: TRUE
#| echo: FALSE
#| output: FALSE
logging.info("Make dendogram of %s patients", cond)
dendogram(dm,'../../outputs/dendogram_%s.png' % cond)
```

```{python}
#| label: kelbow (f)
#| eval: TRUE
#| echo: FALSE
if len(traces)>25:
  n_clusters = kelbow(dm,cond,elbow_metric='distortion',locate_elbow=True)
#kelbow(dm,elbow_metric='calinski_harabasz',locate_elbow=False)
else:
  n_clusters=1
```

![Distance matrix's dendogram](../../outputs/dendogram_f.png){#fig-dendogram fig-align="center" width="80%"}

![Distance matrix's elbow method's graphic](../../outputs/distortion_f.png){#fig-kelbow_f fig-align="center" width="80%"}

```{python}
#| label: clustering (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make clustering of %s patients", cond)
con = duckdb.connect(db_path)
df_ = clust(n_clusters,dm,df_,id2trace,patients)
con.sql(f"CREATE OR REPLACE TABLE clust_{cond} AS SELECT DISTINCT ID,cluster FROM df_")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust AS SELECT \
  eventlog_{cond}.ID,date,nid,Event,cycle,actins,cluster FROM eventlog_{cond} \
  LEFT JOIN clust_{cond} ON eventlog_{cond}.ID = clust_{cond}.ID ")
con.sql(f"CREATE OR REPLACE VIEW cluster_histogram_{cond} AS\
  SELECT cluster, COUNT(DISTINCT ID) AS freq \
  FROM eventlog_{cond}_clust GROUP BY cluster")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust_filtered AS \
   SELECT * FROM eventlog_{cond}_clust \
  WHERE cluster IN (SELECT cluster FROM cluster_histogram_{cond} \
  WHERE freq>=25 OR freq>=(SELECT SUM(freq) * 0.05 \
  FROM cluster_histogram_{cond}))")

```

```{python}
#| label: trace explorer (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make trace explorer figures of %s patients", cond)
col_dic = trace_explorer(con,cond,color_dict=col_dic)
con.close()
```

```{r}
#| label: process explorer (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make process maps figures of different clusters of {cond} patients')
con <- dbConnect(duckdb(), dbdir = db_path)
process_map_by_cluster(
  load_log(con,
           paste0("SELECT * FROM eventlog_",cond,"_clust_filtered")),
  0.25,cond)
dbDisconnect(con, shutdown = TRUE)
```

::: {#fig-cluster0_f .column-page layout-ncol="2"}
![5 most frequent traces](../../outputs/t_cluster_f_0.png){#fig-traceexplorer0}

![Process map covering 25% most frequent traces](../../outputs/pm_cluster_f_0.png){#fig-processmap0}

Cluster 0
:::

#### 6.3.3. Adherence to therapeutic guidelines

```{python}
#| label: create fitness by period table (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Create  %s patients prediction models", cond)
con = duckdb.connect(db_path)
id2treat_fitness_by_interval(con, cond,
            pn_file='./PN_%s.pnml' % cond,
            pn_png_file='../../outputs/PN_%s.png' % cond,
            ini_place='place100',fin_place='place111',
            fixed_period_time=90)
con.close()
```

```{r}
#| label: tbl-fitness_f
#| tbl-cap: "Adherence to therapeutic guidelines of patients with frailty"
#| tbl-colwidths: [60,40]
log_info("Fitness performance {cond} patients ")
con <- dbConnect(duckdb(), dbdir = db_path)
tbl_else_fitness <- dbGetQuery(con, paste0("SELECT  AVG(fitness) AS mean, \
        STDDEV(fitness) AS SD, \
        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY fitness) AS first_quartile, \
        MEDIAN(fitness) AS median, \
        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY fitness) AS third_quartile, \
        COUNT(*) AS n \
          FROM  (SELECT *,ROW_NUMBER() OVER (\
                PARTITION BY ID ORDER BY t_0 DESC) AS rn FROM period2fitness_",cond,") \
        WHERE rn=1"))
dbDisconnect(con, shutdown = TRUE)
kable(tbl_else_fitness, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

```{r}
#| label: treatment conformance analysis by different variables (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE

log_info("Create  {cond} patients fitness regressions")
con <- dbConnect(duckdb(), dbdir = db_path)
df <- dbGetQuery(con, paste0("SELECT p2f.ID,p2f.t_0,p2f.t_1,p2f.fitness,\
                             p2f.status,p2f.status2,\
                             piv.age_dx as age,\
                             CASE WHEN piv.age_dx<50 THEN '[0,50)'\
                             WHEN piv.age_dx>=50 AND piv.age_dx<60 THEN '[50,60)' \
                             WHEN piv.age_dx>=60 AND piv.age_dx<70 THEN '[60,70)' \
                             WHEN piv.age_dx>=70 AND piv.age_dx<80 THEN '[70,80)' \
                             WHEN piv.age_dx>=80 AND piv.age_dx<90 THEN '[80,90)' \
                             ELSE '[90,+)' END AS age_,\
                             piv.sex,piv.copayment,piv.charlson \
                             FROM period2fitness_",cond," p2f \
                             LEFT JOIN patient_incidents_view_ch piv \
                             ON p2f.ID=piv.patient_id"))
dbDisconnect(con, shutdown = TRUE)

df$sex <- as.factor(ifelse(df$sex == 0, 'Male', 'Female'))
df$age_ <- as.factor(df$age_)
df$ID2 <- as.numeric(as.factor(df$ID))
df$t_max <- ave(df$t_1, df$ID2, FUN = max)
df$t_min <- ave(df$t_0, df$ID2, FUN = min)
df$copayment <- as.factor(ifelse(df$copayment== 0,
                                 "less than 18000","more or equal than 18000"))
summary(lmer(fitness ~ sex +t_0+age_+copayment+(1 | ID), data=df))

```


```{python}
#| label: fitness boxplot (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Analyze conformance checking by clusters of %s patients", cond)
con = duckdb.connect(db_path)
treatments_clusters_boxplot(con,cond,
            output_png='../../outputs/fitness_by_cluster_%s.png' % cond)
con.close()
```

![Traces fitness distribution by cluster](../../outputs/fitness_by_cluster_f.png){#fig-fitness_by_cluster_f fig-align="center" width="80%"}

#### 6.3.4. Prediction of clinical outcomes

##### 6.3.4.1 Time Dependent Cox Model
::: {.justify}
In the next example, we choose fitness, age, sex and charlson's index to try to predict a complication in diabetes (understood a complication as death, a potentially avoidable hospitalization or a predominal clinical condition change to 'cvd','hf' or 'ckd') with a time dependet Cox model, and the summary of it is:
::: 

```{r}
#| label: Time dependent COX (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create time dependent Cox {cond} model")
time_dep_f <- coxph(Surv(t_0, t_1, status) ~ age + sex + fitness + charlson,
               data=df)

summary(time_dep_f)
```

##### 6.3.4.2. Joint Latent Class Model

Using same predictive variables a joint latent class model of two classes is made:

```{r}
#| label: JLCM model (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create JLCM {cond} model")
tryCatch(
{### 1 latent class

mj1 <- Jointlcmm(fixed= fitness ~ t_0 ,random =~ t_0, subject="ID2",
                 survival = Surv(t_min,t_max,status2) ~ age+sex+charlson, hazard="Weibull",
                 hazardtype="PH",ng=1,data=df, verbose=FALSE,maxiter=250)
### 2 latent class
mj2f <- gridsearch(rep = 20, maxiter = 15, minit = mj1, 
                  Jointlcmm(fixed= fitness ~ t_0 ,mixture =~ t_0,
                            random=~t_0,subject="ID2",
                            survival = Surv(t_min,t_max,status2)~ age+sex+charlson,
                            hazard="Weibull",hazardtype="PH",
                            ng=2,data=df, verbose=FALSE),cl=4)

summary(mj2f)

postprob(mj2f)

df <- merge(df,mj2f$pprobY %>%
              mutate(class = case_when(
                class == 1 ~ "class 1",
                class == 2 ~ "class 2")),
              by='ID2',all.x = FALSE)
d1 <- data.frame(t_0=seq(1,1100,length.out=100))
data.new <-data.frame(d1,age=65,sex='Female',charlson=1)
mj2f.pred <- predictY(mj2f, data.new , var.time = "t_0")

ggplot(data = df %>% filter(t_0<1100), aes(x = t_0, y = fitness, group = ID2))+ 
  geom_line(colour='grey') + 
  #stat_smooth(aes(group = 1),method = "lm",se=TRUE) +
  stat_summary(aes(group = 1), geom = "point", fun = mean, shape = 16, size = 2) + 
  geom_line(data=data.frame(mj2f.pred$times,mj2f.pred$pred,class='class 1'), aes(t_0, Ypred_class1,group = 1), color = "red", linetype = "dashed",size=1) +
  geom_line(data=data.frame(mj2f.pred$times,mj2f.pred$pred,class='class 2'), aes(t_0, Ypred_class2,group = 1), color = "red", linetype = "dashed",size=1) +
  facet_grid(. ~ class) +   
  labs(x = "Days", y = "Fitness", col = "class") + 
  guides(col = guide_legend(nrow = 3),)
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint1_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)


survfit(Surv(t_min, t_max, status2) ~ class, data=df %>%
          select(ID2,t_min,t_max,status2,class) %>% unique()) %>%
  autoplot(xlab = "Days", ylab = "Survival probability")
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint2_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)},
error = function(cond_) {
            message(conditionMessage(cond_))
        }
)

```

##### 6.3.4.3. Two time windows Cox Model

Moreover a Cox survival model with two time windows is implemented below:

```{r}
#| label: 2 windows cox (f)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create two windows cox {cond} model")
df <- df %>% 
  filter(t_max > 270) %>% 
  filter(t_0==270) %>% 
  select(ID,fitness,status2,age,age_,sex,copayment,charlson,ID2,t_min,t_max)
df$status3 <- ifelse(df$t_max<=630 & df$status2==1, 1, 0)
df$t_max <- pmin(df$t_max-270,360)

cox2w_f <- coxph(Surv(t_max, status3) ~ age + sex + fitness + charlson,
               data=df)

summary(cox2w_f)
```

### 6.4. Chronic kidney disease

#### 6.4.1. Treatment event log

```{python}
#| label: condition variable in python (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond = 'ckd'
```

```{r}
#| label: condition variable in r (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'ckd'
```

```{python}
#| label: Preprocessing of raw event log (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
con = duckdb.connect(db_path)
if notnan_p>0.98:
  logging.info("Generate event log of %s patients from prescriptions", cond)
  evlog_creation_by_prescriptions(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv')
else:
  logging.info("Generate event log of %s patients from dispensations", cond)
  evlog_creation_by_dispensations(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv',
    nac_path='./Nomenclator_de_Facturacion.csv')
```

```{python}
#| label: event log (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Filter event log of %s patients", cond)
df_ = con.sql(f"SELECT * FROM evlog_raw_{cond}").df()

df_, id2trace = df2dict(df_)
con.sql(f"CREATE OR REPLACE TABLE eventlog_{cond} AS SELECT * FROM df_")
patients = sorted(id2trace.keys())
traces = list(id2trace[id] for id in patients)     
con.close()
```

```{r}
#| label: Loading event log in R (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info('Load {cond} eventlog')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog <- load_log(con, paste0("SELECT * FROM eventlog_",cond))
dbDisconnect(con, shutdown = TRUE)
```

Choosing patients with chronic kidney disease and after some preprocessing we obtain a new event log to make the same analysis has done before.

```{r}
#| label: proces map and activity presence (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} process map')
make_process_map(evLog,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_pm_1_%s.png",
                                                     cond))))
make_process_map(evLog,0.2,gsub("src/analysis-scripts/","",
                                here("outputs",sprintf("evlog_pm_02_%s.png",
                                                     cond))))
log_info('Make activity presence of {cond} patients')
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()

```

![Event log's process map with all traces](../../outputs/evlog_pm_1_ckd.png){#fig-pm1_ckd fig-align="center" width="80%"}

![Event log's process map with most frequent traces covering 20%](../../outputs/evlog_pm_02_ckd.png){#fig-pm02_ckd fig-align="center" width="80%"}

![Percentage of patients traces an activity is present](../../outputs/activity_presence_ckd.png){#fig-activity_presence_ckd fig-align="center" width="80%"}

#### 6.4.2. Clustering traces

```{python}
#| label: dm calculation (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make distance matrix of %s patients", cond)
measure_f = Levenshtein.normalized_similarity
dm = calculate_dm_ED(traces,measure_f)
```

```{python}
#| label: dendograms (ckd)
#| eval: TRUE
#| echo: FALSE
#| output: FALSE
logging.info("Make dendogram of %s patients", cond)
dendogram(dm,'../../outputs/dendogram_%s.png' % cond)
```

```{python}
#| label: kelbow (ckd)
#| eval: TRUE
#| echo: FALSE
if len(traces)>25:
  n_clusters = kelbow(dm,cond,elbow_metric='distortion',locate_elbow=True)
#kelbow(dm,elbow_metric='calinski_harabasz',locate_elbow=False)
else:
  n_clusters=1
```

![Distance matrix's dendogram](../../outputs/dendogram_ckd.png){#fig-dendogram_ckd fig-align="center" width="80%"}

![Distance matrix's elbow method's graphic](../../outputs/distortion_ckd.png){#fig-kelbow_ckd fig-align="center" width="80%"}

```{python}
#| label: clustering (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make clustering of %s patients", cond)
con = duckdb.connect(db_path)
df_ = clust(n_clusters,dm,df_,id2trace,patients)
con.sql(f"CREATE OR REPLACE TABLE clust_{cond} AS SELECT DISTINCT ID,cluster FROM df_")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust AS SELECT \
  eventlog_{cond}.ID,date,nid,Event,cycle,actins,cluster FROM eventlog_{cond} \
  LEFT JOIN clust_{cond} ON eventlog_{cond}.ID = clust_{cond}.ID ")
con.sql(f"CREATE OR REPLACE VIEW cluster_histogram_{cond} AS\
  SELECT cluster, COUNT(DISTINCT ID) AS freq \
  FROM eventlog_{cond}_clust GROUP BY cluster")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust_filtered AS \
   SELECT * FROM eventlog_{cond}_clust \
  WHERE cluster IN (SELECT cluster FROM cluster_histogram_{cond} \
  WHERE freq>=25 OR freq>=(SELECT SUM(freq) * 0.05 \
  FROM cluster_histogram_{cond}))")

```

```{python}
#| label: trace explorer (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make trace explorer figures of %s patients", cond)
col_dic = trace_explorer(con,cond,color_dict=col_dic)
con.close()
```

```{r}
#| label: process explorer (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make process maps figures of different clusters of {cond} patients')
con <- dbConnect(duckdb(), dbdir = db_path)
process_map_by_cluster(
  load_log(con,
           paste0("SELECT * FROM eventlog_",cond,"_clust_filtered")),
  0.25,cond)
dbDisconnect(con, shutdown = TRUE)
```

::: {#fig-cluster0_ckd .column-page layout-ncol="2"}
![5 most frequent traces](../../outputs/t_cluster_ckd_0.png){#fig-traceexplorer0_ckd}

![Process map covering 25% most frequent traces](../../outputs/pm_cluster_ckd_0.png){#fig-processmap0_ckd}

Cluster 0
:::

#### 6.4.3. Adherence to therapeutic guidelines

```{python}
#| label: create fitness by period table (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Create  %s patients prediction models", cond)
con = duckdb.connect(db_path)
id2treat_fitness_by_interval(con, cond,
            pn_file='./PN_%s.pnml' % cond,
            pn_png_file='../../outputs/PN_%s.png' % cond,
            ini_place='place100',fin_place='place111',
            fixed_period_time=90)
con.close()
```

```{r}
#| label: tbl-fitness_ckd
#| tbl-cap: "Adherence to therapeutic guidelines of patients witho chronic kidney disease."
#| tbl-colwidths: [60,40]
log_info("Fitness performance {cond} patients ")
con <- dbConnect(duckdb(), dbdir = db_path)
tbl_else_fitness <- dbGetQuery(con, paste0("SELECT  AVG(fitness) AS mean, \
        STDDEV(fitness) AS SD, \
        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY fitness) AS first_quartile, \
        MEDIAN(fitness) AS median, \
        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY fitness) AS third_quartile, \
        COUNT(*) AS n \
          FROM  (SELECT *,ROW_NUMBER() OVER (\
                PARTITION BY ID ORDER BY t_0 DESC) AS rn FROM period2fitness_",cond,") \
        WHERE rn=1"))
dbDisconnect(con, shutdown = TRUE)
kable(tbl_else_fitness, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

```{r}
#| label: treatment conformance analysis by different variables (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE

log_info("Create  {cond} patients fitness regressions")
con <- dbConnect(duckdb(), dbdir = db_path)
df <- dbGetQuery(con, paste0("SELECT p2f.ID,p2f.t_0,p2f.t_1,p2f.fitness,\
                             p2f.status,p2f.status2,\
                             piv.age_dx as age,\
                             CASE WHEN piv.age_dx<50 THEN '[0,50)'\
                             WHEN piv.age_dx>=50 AND piv.age_dx<60 THEN '[50,60)' \
                             WHEN piv.age_dx>=60 AND piv.age_dx<70 THEN '[60,70)' \
                             WHEN piv.age_dx>=70 AND piv.age_dx<80 THEN '[70,80)' \
                             WHEN piv.age_dx>=80 AND piv.age_dx<90 THEN '[80,90)' \
                             ELSE '[90,+)' END AS age_,\
                             piv.sex,piv.copayment,piv.charlson \
                             FROM period2fitness_",cond," p2f \
                             LEFT JOIN patient_incidents_view_ch piv \
                             ON p2f.ID=piv.patient_id"))
dbDisconnect(con, shutdown = TRUE)

df$sex <- as.factor(ifelse(df$sex == 0, 'Male', 'Female'))
df$age_ <- as.factor(df$age_)
df$ID2 <- as.numeric(as.factor(df$ID))
df$t_max <- ave(df$t_1, df$ID2, FUN = max)
df$t_min <- ave(df$t_0, df$ID2, FUN = min)
df$copayment <- as.factor(ifelse(df$copayment== 0,
                                 "less than 18000","more or equal than 18000"))
summary(lmer(fitness ~ sex +t_0+age_+copayment+(1 | ID), data=df))

```


```{python}
#| label: fitness boxplot (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Analyze conformance checking by clusters of %s patients", cond)
con = duckdb.connect(db_path)
treatments_clusters_boxplot(con,cond,
            output_png='../../outputs/fitness_by_cluster_%s.png' % cond)
con.close()
```

![Traces fitness distribution by cluster](../../outputs/fitness_by_cluster_ckd.png){#fig-fitness_by_cluster_ckd fig-align="center" width="80%"}

#### 6.4.4. Prediction of clinical outcomes

##### 6.4.4.1. Time Dependent Cox Model
::: {.justify}
In the next example, we choose fitness, age, sex and charlson's index to try to predict a complication in diabetes (understood a complication as death, a potentially avoidable hospitalization or a predominal clinical condition change to 'cvd','hf' or 'ckd') with a time dependet Cox model, and the summary of it is:
::: 

```{r}
#| label: Time dependent COX (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create time dependent Cox {cond} model")
time_dep_ckd <- coxph(Surv(t_0, t_1, status) ~ age + sex + fitness + charlson,
               data=df)

summary(time_dep_ckd)
```

##### 6.4.4.2. Joint Latent Class Model

Using same predictive variables a joint latent class model of two classes is made:

```{r}
#| label: JLCM model (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create JLCM {cond} model")
tryCatch(
{### 1 latent class

mj1 <- Jointlcmm(fixed= fitness ~ t_0 ,random =~ t_0, subject="ID2",
                 survival = Surv(t_min,t_max,status2) ~ age+sex+charlson, hazard="Weibull",
                 hazardtype="PH",ng=1,data=df, verbose=FALSE,maxiter=400)
### 2 latent class
mj2ckd <- gridsearch(rep = 20, maxiter = 15, minit = mj1, 
                  Jointlcmm(fixed= fitness ~ t_0 ,mixture =~ t_0,
                            random=~t_0,subject="ID2",
                            survival = Surv(t_min,t_max,status2)~ age+sex+charlson,
                            hazard="Weibull",hazardtype="PH",
                            ng=2,data=df, verbose=FALSE),cl=4)

summary(mj2ckd)

postprob(mj2ckd)

df <- merge(df,mj2ckd$pprobY %>%
              mutate(class = case_when(
                class == 1 ~ "class 1",
                class == 2 ~ "class 2")),
              by='ID2',all.x = FALSE)
d1 <- data.frame(t_0=seq(1,1100,length.out=100))
data.new <-data.frame(d1,age=65,sex='Female',charlson=1)
mj2ckd.pred <- predictY(mj2ckd, data.new , var.time = "t_0")

ggplot(data = df %>% filter(t_0<1100), aes(x = t_0, y = fitness, group = ID2))+ 
  geom_line(colour='grey') + 
  #stat_smooth(aes(group = 1),method = "lm",se=TRUE) +
  stat_summary(aes(group = 1), geom = "point", fun = mean, shape = 16, size = 2) + 
  geom_line(data=data.frame(mj2ckd.pred$times,mj2ckd.pred$pred,class='class 1'), aes(t_0, Ypred_class1,group = 1), color = "red", linetype = "dashed",size=1) +
  geom_line(data=data.frame(mj2ckd.pred$times,mj2ckd.pred$pred,class='class 2'), aes(t_0, Ypred_class2,group = 1), color = "red", linetype = "dashed",size=1) +
  facet_grid(. ~ class) +   
  labs(x = "Days", y = "Fitness", col = "class") + 
  guides(col = guide_legend(nrow = 3),)
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint1_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)


survfit(Surv(t_min, t_max, status2) ~ class, data=df %>%
          select(ID2,t_min,t_max,status2,class) %>% unique()) %>%
  autoplot(xlab = "Days", ylab = "Survival probability")
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint2_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)},
error = function(cond_) {
            message(conditionMessage(cond_))
        }
)

```

##### 6.4.4.3. Two time windows Cox Model

Moreover a Cox survival model with two time windows is implemented below:

```{r}
#| label: 2 windows cox (ckd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create two windows cox {cond} model")
df <- df %>% 
  filter(t_max > 270) %>% 
  filter(t_0==270) %>% 
  select(ID,fitness,status2,age,age_,sex,copayment,charlson,ID2,t_min,t_max)
df$status3 <- ifelse(df$t_max<=630 & df$status2==1, 1, 0)
df$t_max <- pmin(df$t_max-270,360)

cox2w_ckd <- coxph(Surv(t_max, status3) ~ age + sex + fitness + charlson,
               data=df)

summary(cox2w_ckd)
```

### 6.5. Heart Failure

#### 6.5.1. Treatment event log

```{python}
#| label: condition variable in python (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond = 'hf'
```

```{r}
#| label: condition variable in r (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'hf'
```

```{python}
#| label: Preprocessing of raw event log (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
con = duckdb.connect(db_path)
if notnan_p>0.98:
  logging.info("Generate event log of %s patients from prescriptions", cond)
  evlog_creation_by_prescriptions(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv')
else:
  logging.info("Generate event log of %s patients from dispensations", cond)
  evlog_creation_by_dispensations(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv',
    nac_path='./Nomenclator_de_Facturacion.csv')
```

```{python}
#| label: event log (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Filter event log of %s patients", cond)
df_ = con.sql(f"SELECT * FROM evlog_raw_{cond}").df()

df_, id2trace = df2dict(df_)
con.sql(f"CREATE OR REPLACE TABLE eventlog_{cond} AS SELECT * FROM df_")
patients = sorted(id2trace.keys())
traces = list(id2trace[id] for id in patients)     
con.close()
```

```{r}
#| label: Loading event log in R (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info('Load {cond} eventlog')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog <- load_log(con, paste0("SELECT * FROM eventlog_",cond))
dbDisconnect(con, shutdown = TRUE)
```

Choosing patients with heart failure and after some preprocessing we obtain a new event log to make the same analysis has done before.

```{r}
#| label: proces map and activity presence (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} process map')
make_process_map(evLog,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_pm_1_%s.png",
                                                     cond))))
make_process_map(evLog,0.2,gsub("src/analysis-scripts/","",
                                here("outputs",sprintf("evlog_pm_02_%s.png",
                                                     cond))))
log_info('Make activity presence of {cond} patients')
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()
```

![Event log's process map with all traces](../../outputs/evlog_pm_1_hf.png){#fig-pm1_hf fig-align="center" width="80%"}

![Event log's process map with most frequent traces covering 20%](../../outputs/evlog_pm_02_hf.png){#fig-pm02_hf fig-align="center" width="80%"}

![Percentage of patients traces an activity is present](../../outputs/activity_presence_hf.png){#fig-activity_presence_hf fig-align="center" width="80%"}

#### 6.5.2. Clustering traces

```{python}
#| label: dm calculation (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make distance matrix of %s patients", cond)
measure_f = Levenshtein.normalized_similarity
dm = calculate_dm_ED(traces,measure_f)
```

```{python}
#| label: dendograms (hf)
#| eval: TRUE
#| echo: FALSE
#| output: FALSE
logging.info("Make dendogram of %s patients", cond)
dendogram(dm,'../../outputs/dendogram_%s.png' % cond)
```

```{python}
#| label: kelbow (hf)
#| eval: TRUE
#| echo: FALSE
if len(traces)>25:
  n_clusters = kelbow(dm,cond,elbow_metric='distortion',locate_elbow=True)
#kelbow(dm,elbow_metric='calinski_harabasz',locate_elbow=False)
else:
  n_clusters=1
```

![Distance matrix's dendogram](../../outputs/dendogram_hf.png){#fig-dendogram_hf fig-align="center" width="80%"}

![Distance matrix's elbow method's graphic](../../outputs/distortion_hf.png){#fig-kelbow_hf fig-align="center" width="80%"}

```{python}
#| label: clustering (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make clustering of %s patients", cond)
con = duckdb.connect(db_path)
df_ = clust(n_clusters,dm,df_,id2trace,patients)
con.sql(f"CREATE OR REPLACE TABLE clust_{cond} AS SELECT DISTINCT ID,cluster FROM df_")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust AS SELECT \
  eventlog_{cond}.ID,date,nid,Event,cycle,actins,cluster FROM eventlog_{cond} \
  LEFT JOIN clust_{cond} ON eventlog_{cond}.ID = clust_{cond}.ID ")
con.sql(f"CREATE OR REPLACE VIEW cluster_histogram_{cond} AS\
  SELECT cluster, COUNT(DISTINCT ID) AS freq \
  FROM eventlog_{cond}_clust GROUP BY cluster")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust_filtered AS \
   SELECT * FROM eventlog_{cond}_clust \
  WHERE cluster IN (SELECT cluster FROM cluster_histogram_{cond} \
  WHERE freq>=25 OR freq>=(SELECT SUM(freq) * 0.05 \
  FROM cluster_histogram_{cond}))")

```

```{python}
#| label: trace explorer (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make trace explorer figures of %s patients", cond)
col_dic = trace_explorer(con,cond,color_dict=col_dic)
con.close()
```

```{r}
#| label: process explorer (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make process maps figures of different clusters of {cond} patients')
con <- dbConnect(duckdb(), dbdir = db_path)
process_map_by_cluster(
  load_log(con,
           paste0("SELECT * FROM eventlog_",cond,"_clust_filtered")),
  0.25,cond)
dbDisconnect(con, shutdown = TRUE)
```

::: {#fig-cluster0_hf .column-page layout-ncol="2"}
![5 most frequent traces](../../outputs/t_cluster_hf_0.png){#fig-traceexplorer0_hf}

![Process map covering 25% most frequent traces](../../outputs/pm_cluster_hf_0.png){#fig-processmap0_hf}

Cluster 0
:::

#### 6.5.3. Adherence to therapeutic guidelines

```{python}
#| label: create fitness by period table (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Create  %s patients prediction models", cond)
con = duckdb.connect(db_path)
id2treat_fitness_by_interval(con, cond,
            pn_file='./PN_%s.pnml' % cond,
            pn_png_file='../../outputs/PN_%s.png' % cond,
            ini_place='place100',fin_place='place111',
            fixed_period_time=90)
con.close()
```

```{r}
#| label: tbl-fitness_hf
#| tbl-cap: "Adherence to therapeutic guidelines of patients with heart failure."
#| tbl-colwidths: [60,40]
log_info("Fitness performance {cond} patients ")
con <- dbConnect(duckdb(), dbdir = db_path)
tbl_else_fitness <- dbGetQuery(con, paste0("SELECT  AVG(fitness) AS mean, \
        STDDEV(fitness) AS SD, \
        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY fitness) AS first_quartile, \
        MEDIAN(fitness) AS median, \
        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY fitness) AS third_quartile, \
        COUNT(*) AS n \
          FROM  (SELECT *,ROW_NUMBER() OVER (\
                PARTITION BY ID ORDER BY t_0 DESC) AS rn FROM period2fitness_",cond,") \
        WHERE rn=1"))
dbDisconnect(con, shutdown = TRUE)
kable(tbl_else_fitness, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

```{r}
#| label: treatment conformance analysis by different variables (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE

log_info("Create  {cond} patients fitness regressions")
con <- dbConnect(duckdb(), dbdir = db_path)
df <- dbGetQuery(con, paste0("SELECT p2f.ID,p2f.t_0,p2f.t_1,p2f.fitness,\
                             p2f.status,p2f.status2,\
                             piv.age_dx as age,\
                             CASE WHEN piv.age_dx<50 THEN '[0,50)'\
                             WHEN piv.age_dx>=50 AND piv.age_dx<60 THEN '[50,60)' \
                             WHEN piv.age_dx>=60 AND piv.age_dx<70 THEN '[60,70)' \
                             WHEN piv.age_dx>=70 AND piv.age_dx<80 THEN '[70,80)' \
                             WHEN piv.age_dx>=80 AND piv.age_dx<90 THEN '[80,90)' \
                             ELSE '[90,+)' END AS age_,\
                             piv.sex,piv.copayment,piv.charlson \
                             FROM period2fitness_",cond," p2f \
                             LEFT JOIN patient_incidents_view_ch piv \
                             ON p2f.ID=piv.patient_id"))
dbDisconnect(con, shutdown = TRUE)

df$sex <- as.factor(ifelse(df$sex == 0, 'Male', 'Female'))
df$age_ <- as.factor(df$age_)
df$ID2 <- as.numeric(as.factor(df$ID))
df$t_max <- ave(df$t_1, df$ID2, FUN = max)
df$t_min <- ave(df$t_0, df$ID2, FUN = min)
df$copayment <- as.factor(ifelse(df$copayment== 0,
                                 "less than 18000","more or equal than 18000"))
summary(lmer(fitness ~ sex +t_0+age_+copayment+(1 | ID), data=df))

```


```{python}
#| label: fitness boxplot (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Analyze conformance checking by clusters of %s patients", cond)
con = duckdb.connect(db_path)
treatments_clusters_boxplot(con,cond,
            output_png='../../outputs/fitness_by_cluster_%s.png' % cond)
con.close()
```

![Traces fitness distribution by cluster](../../outputs/fitness_by_cluster_hf.png){#fig-fitness_by_cluster_hf fig-align="center" width="80%"}

#### 6.5.4. Prediction of clinical outcomes

##### 6.5.4.1. Time Dependent Cox Model
::: {.justify}
In the next example, we choose fitness, age, sex and charlson's index to try to predict a complication in diabetes (understood a complication as death, a potentially avoidable hospitalization or a predominal clinical condition change to 'cvd','hf' or 'ckd') with a time dependet Cox model, and the summary of it is:
::: 

```{r}
#| label: Time dependent COX (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create time dependent Cox {cond} model")
time_dep_hf <- coxph(Surv(t_0, t_1, status) ~ age + sex + fitness + charlson,
               data=df)

summary(time_dep_hf)
```

##### 6.5.4.2. Joint Latent Class Model

Using same predictive variables a joint latent class model of two classes is made:

```{r}
#| label: JLCM model (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create JLCM {cond} model")
tryCatch(
{### 1 latent class

mj1 <- Jointlcmm(fixed= fitness ~ t_0 ,random =~ t_0, subject="ID2",
                 survival = Surv(t_min,t_max,status2) ~ age+sex+charlson, hazard="Weibull",
                 hazardtype="PH",ng=1,data=df, verbose=FALSE,maxiter=400)
### 2 latent class
mj2hf <- gridsearch(rep = 20, maxiter = 15, minit = mj1, 
                  Jointlcmm(fixed= fitness ~ t_0 ,mixture =~ t_0,
                            random=~t_0,subject="ID2",
                            survival = Surv(t_min,t_max,status2)~ age+sex+charlson,
                            hazard="Weibull",hazardtype="PH",
                            ng=2,data=df, verbose=FALSE),cl=4)

summary(mj2hf)

postprob(mj2hf)

df <- merge(df,mj2hf$pprobY %>%
              mutate(class = case_when(
                class == 1 ~ "class 1",
                class == 2 ~ "class 2")),
              by='ID2',all.x = FALSE)
d1 <- data.frame(t_0=seq(1,1100,length.out=100))
data.new <-data.frame(d1,age=65,sex='Female',charlson=1)
mj2hf.pred <- predictY(mj2hf, data.new , var.time = "t_0")

ggplot(data = df %>% filter(t_0<1100), aes(x = t_0, y = fitness, group = ID2))+ 
  geom_line(colour='grey') + 
  #stat_smooth(aes(group = 1),method = "lm",se=TRUE) +
  stat_summary(aes(group = 1), geom = "point", fun = mean, shape = 16, size = 2) + 
  geom_line(data=data.frame(mj2hf.pred$times,mj2hf.pred$pred,class='class 1'), aes(t_0, Ypred_class1,group = 1), color = "red", linetype = "dashed",size=1) +
  geom_line(data=data.frame(mj2hf.pred$times,mj2hf.pred$pred,class='class 2'), aes(t_0, Ypred_class2,group = 1), color = "red", linetype = "dashed",size=1) +
  facet_grid(. ~ class) +   
  labs(x = "Days", y = "Fitness", col = "class") + 
  guides(col = guide_legend(nrow = 3),)
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint1_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)


survfit(Surv(t_min, t_max, status2) ~ class, data=df %>%
          select(ID2,t_min,t_max,status2,class) %>% unique()) %>%
  autoplot(xlab = "Days", ylab = "Survival probability")
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint2_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)},
error = function(cond_) {
            message(conditionMessage(cond_))
        }
)

```

##### 6.5.4.3. Two time windows Cox Model

Moreover a Cox survival model with two time windows is implemented below:

```{r}
#| label: 2 windows cox (hf)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create two windows cox {cond} model")
df <- df %>% 
  filter(t_max > 270) %>% 
  filter(t_0==270) %>% 
  select(ID,fitness,status2,age,age_,sex,copayment,charlson,ID2,t_min,t_max)
df$status3 <- ifelse(df$t_max<=630 & df$status2==1, 1, 0)
df$t_max <- pmin(df$t_max-270,360)

cox2w_hf <- coxph(Surv(t_max, status3) ~ age + sex + fitness + charlson,
               data=df)

summary(cox2w_hf)
```

### 6.6. CV Disease

#### 6.6.1. Treatment event log

```{python}
#| label: condition variable in python (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond = 'cvd'
```

```{r}
#| label: condition variable in r (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
cond <- 'cvd'
```

```{python}
#| label: Preprocessing of raw event log (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
con = duckdb.connect(db_path)
if notnan_p>0.98:
  logging.info("Generate event log of %s patients from prescriptions", cond)
  evlog_creation_by_prescriptions(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv')
else:
  logging.info("Generate event log of %s patients from dispensations", cond)
  evlog_creation_by_dispensations(
    con=con,
    cond=cond,
    code2drug_info_path='./diabetes_drugs.csv',
    nac_path='./Nomenclator_de_Facturacion.csv')
```

```{python}
#| label: event log (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Filter event log of %s patients", cond)
df_ = con.sql(f"SELECT * FROM evlog_raw_{cond}").df()

df_, id2trace = df2dict(df_)
con.sql(f"CREATE OR REPLACE TABLE eventlog_{cond} AS SELECT * FROM df_")
patients = sorted(id2trace.keys())
traces = list(id2trace[id] for id in patients)     
con.close()
```

```{r}
#| label: Loading event log in R (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info('Load {cond} eventlog')
con <- dbConnect(duckdb(), dbdir = db_path)
evLog <- load_log(con, paste0("SELECT * FROM eventlog_",cond))
dbDisconnect(con, shutdown = TRUE)
```

Choosing patients with a cardiovascular disease and after some preprocessing we obtain a new event log to make the same analysis has done before.

```{r}
#| label: proces map and activity presence (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make {cond} process map')
make_process_map(evLog,1,gsub("src/analysis-scripts/","",
                              here("outputs",sprintf("evlog_pm_1_%s.png",
                                                     cond))))
make_process_map(evLog,0.2,gsub("src/analysis-scripts/","",
                                here("outputs",sprintf("evlog_pm_02_%s.png",
                                                     cond))))
log_info('Make activity presence of {cond} patients')
png(filename=gsub("src/analysis-scripts/","",
                  here("outputs",sprintf("activity_presence_%s.png",
                                         cond))),
    width = 600, height = 750, units = "px")
plot(evLog %>% activity_presence()  )+scale_y_continuous(limits = c(0, 1))
dev.off()
```

![Event log's process map with all traces](../../outputs/evlog_pm_1_cvd.png){#fig-pm1_cvd fig-align="center" width="80%"}

![Event log's process map with most frequent traces covering 20%](../../outputs/evlog_pm_02_cvd.png){#fig-pm02_cvd fig-align="center" width="80%"}

![Percentage of patients traces an activity is present](../../outputs/activity_presence_cvd.png){#fig-activity_presence_cvd fig-align="center" width="80%"}

#### 6.6.2. Clustering traces

```{python}
#| label: dm calculation (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make distance matrix of %s patients", cond)
measure_f = Levenshtein.normalized_similarity
dm = calculate_dm_ED(traces,measure_f)
```

```{python}
#| label: dendograms (cvd)
#| eval: TRUE
#| echo: FALSE
#| output: FALSE
logging.info("Make dendogram of %s patients", cond)
dendogram(dm,'../../outputs/dendogram_%s.png' % cond)
```

```{python}
#| label: kelbow (cvd)
#| eval: TRUE
#| echo: FALSE
if len(traces)>25:
  n_clusters = kelbow(dm,cond,elbow_metric='distortion',locate_elbow=True)
#kelbow(dm,elbow_metric='calinski_harabasz',locate_elbow=False)
else:
  n_clusters=1
```

![Distance matrix's dendogram](../../outputs/dendogram_cvd.png){#fig-dendogram_cvd fig-align="center" width="80%"}

![Distance matrix's elbow method's graphic](../../outputs/distortion_cvd.png){#fig-kelbow_cvd fig-align="center" width="80%"}

```{python}
#| label: clustering (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make clustering of %s patients", cond)
con = duckdb.connect(db_path)
df_ = clust(n_clusters,dm,df_,id2trace,patients)
con.sql(f"CREATE OR REPLACE TABLE clust_{cond} AS SELECT DISTINCT ID,cluster FROM df_")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust AS SELECT \
  eventlog_{cond}.ID,date,nid,Event,cycle,actins,cluster FROM eventlog_{cond} \
  LEFT JOIN clust_{cond} ON eventlog_{cond}.ID = clust_{cond}.ID ")
con.sql(f"CREATE OR REPLACE VIEW cluster_histogram_{cond} AS\
  SELECT cluster, COUNT(DISTINCT ID) AS freq \
  FROM eventlog_{cond}_clust GROUP BY cluster")
con.sql(f"CREATE OR REPLACE VIEW eventlog_{cond}_clust_filtered AS \
   SELECT * FROM eventlog_{cond}_clust \
  WHERE cluster IN (SELECT cluster FROM cluster_histogram_{cond} \
  WHERE freq>=25 OR freq>=(SELECT SUM(freq) * 0.05 \
  FROM cluster_histogram_{cond}))")

```

```{python}
#| label: trace explorer (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Make trace explorer figures of %s patients", cond)
col_dic = trace_explorer(con,cond,color_dict=col_dic)
con.close()
```

```{r}
#| label: process explorer (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
log_info('Make process maps figures of different clusters of {cond} patients')
con <- dbConnect(duckdb(), dbdir = db_path)
process_map_by_cluster(
  load_log(con,
           paste0("SELECT * FROM eventlog_",cond,"_clust_filtered")),
  0.25,cond)
dbDisconnect(con, shutdown = TRUE)
```

::: {#fig-cluster0_cvd .column-page layout-ncol="2"}
![5 most frequent traces](../../outputs/t_cluster_cvd_0.png){#fig-traceexplorer0_cvd}

![Process map covering 25% most frequent traces](../../outputs/pm_cluster_cvd_0.png){#fig-processmap0_cvd}

Cluster 0
:::

#### 6.6.3. Adherence to therapeutic guidelines

```{python}
#| label: create fitness by period table (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Create  %s patients prediction models", cond)
con = duckdb.connect(db_path)
id2treat_fitness_by_interval(con, cond,
            pn_file='./PN_%s.pnml' % cond,
            pn_png_file='../../outputs/PN_%s.png' % cond,
            ini_place='place100',fin_place='place111',
            fixed_period_time=90)
con.close()
```

```{r}
#| label: tbl-fitness_cvd
#| tbl-cap: "Adherence to therapeutic guidelines of patients with cardiovascular disease."
#| tbl-colwidths: [60,40]
log_info("Fitness performance {cond} patients ")
con <- dbConnect(duckdb(), dbdir = db_path)
tbl_else_fitness <- dbGetQuery(con, paste0("SELECT  AVG(fitness) AS mean, \
        STDDEV(fitness) AS SD, \
        PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY fitness) AS first_quartile, \
        MEDIAN(fitness) AS median, \
        PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY fitness) AS third_quartile, \
        COUNT(*) AS n \
          FROM  (SELECT *,ROW_NUMBER() OVER (\
                PARTITION BY ID ORDER BY t_0 DESC) AS rn FROM period2fitness_",cond,") \
        WHERE rn=1"))
dbDisconnect(con, shutdown = TRUE)
kable(tbl_else_fitness, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

```{r}
#| label: treatment conformance analysis by different variables (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE

log_info("Create  {cond} patients fitness regressions")
con <- dbConnect(duckdb(), dbdir = db_path)
df <- dbGetQuery(con, paste0("SELECT p2f.ID,p2f.t_0,p2f.t_1,p2f.fitness,\
                             p2f.status,p2f.status2,\
                             piv.age_dx as age,\
                             CASE WHEN piv.age_dx<50 THEN '[0,50)'\
                             WHEN piv.age_dx>=50 AND piv.age_dx<60 THEN '[50,60)' \
                             WHEN piv.age_dx>=60 AND piv.age_dx<70 THEN '[60,70)' \
                             WHEN piv.age_dx>=70 AND piv.age_dx<80 THEN '[70,80)' \
                             WHEN piv.age_dx>=80 AND piv.age_dx<90 THEN '[80,90)' \
                             ELSE '[90,+)' END AS age_,\
                             piv.sex,piv.copayment,piv.charlson \
                             FROM period2fitness_",cond," p2f \
                             LEFT JOIN patient_incidents_view_ch piv \
                             ON p2f.ID=piv.patient_id"))
dbDisconnect(con, shutdown = TRUE)

df$sex <- as.factor(ifelse(df$sex == 0, 'Male', 'Female'))
df$age_ <- as.factor(df$age_)
df$ID2 <- as.numeric(as.factor(df$ID))
df$t_max <- ave(df$t_1, df$ID2, FUN = max)
df$t_min <- ave(df$t_0, df$ID2, FUN = min)
df$copayment <- as.factor(ifelse(df$copayment== 0,
                                 "less than 18000","more or equal than 18000"))
summary(lmer(fitness ~ sex +t_0+age_+copayment+(1 | ID), data=df))

```


```{python}
#| label: fitness boxplot (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: FALSE
logging.info("Analyze conformance checking by clusters of %s patients", cond)
con = duckdb.connect(db_path)
treatments_clusters_boxplot(con,cond,
            output_png='../../outputs/fitness_by_cluster_%s.png' % cond)
con.close()
```

![Traces fitness distribution by cluster](../../outputs/fitness_by_cluster_cvd.png){#fig-fitness_by_cluster_cvd fig-align="center" width="80%"}

#### 6.6.4. Prediction of clinical outcomes

##### 6.6.4.1. Time Dependent Cox Model
::: {.justify}
In the next example, we choose fitness, age, sex and charlson's index to try to predict a complication in diabetes (understood a complication as death, a potentially avoidable hospitalization or a predominal clinical condition change to 'cvd','hf' or 'ckd') with a time dependet Cox model, and the summary of it is:
::: 

```{r}
#| label: Time dependent COX (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create time dependent Cox {cond} model")
time_dep_cvd <- coxph(Surv(t_0, t_1, status) ~ age + sex + fitness + charlson,
               data=df)

summary(time_dep_cvd)
```

##### 6.6.4.2. Joint Latent Class Model

Using same predictive variables a joint latent class model of two classes is made:

```{r}
#| label: JLCM model (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create JLCM {cond} model")
tryCatch(
{### 1 latent class
mj1 <- Jointlcmm(fixed= fitness ~ t_0 ,random =~ t_0, subject="ID2",
                 survival = Surv(t_min,t_max,status2) ~ age+sex+charlson, hazard="Weibull",
                 hazardtype="PH",ng=1,data=df, verbose=FALSE,maxiter=250)
### 2 latent class
mj2cvd <- gridsearch(rep = 20, maxiter = 15, minit = mj1, 
                  Jointlcmm(fixed= fitness ~ t_0 ,mixture =~ t_0,
                            random=~t_0,subject="ID2",
                            survival = Surv(t_min,t_max,status2)~ age+sex+charlson,
                            hazard="Weibull",hazardtype="PH",
                            ng=2,data=df, verbose=FALSE),cl=4)

summary(mj2cvd)

postprob(mj2cvd)

df <- merge(df,mj2cvd$pprobY %>%
              mutate(class = case_when(
                class == 1 ~ "class 1",
                class == 2 ~ "class 2")),
              by='ID2',all.x = FALSE)
d1 <- data.frame(t_0=seq(1,1100,length.out=100))
data.new <-data.frame(d1,age=65,sex='Female',charlson=1)
mj2cvd.pred <- predictY(mj2cvd, data.new , var.time = "t_0")

ggplot(data = df %>% filter(t_0<1100), aes(x = t_0, y = fitness, group = ID2))+ 
  geom_line(colour='grey') + 
  #stat_smooth(aes(group = 1),method = "lm",se=TRUE) +
  stat_summary(aes(group = 1), geom = "point", fun = mean, shape = 16, size = 2) + 
  geom_line(data=data.frame(mj2cvd.pred$times,mj2cvd.pred$pred,class='class 1'), aes(t_0, Ypred_class1,group = 1), color = "red", linetype = "dashed",size=1) +
  geom_line(data=data.frame(mj2cvd.pred$times,mj2cvd.pred$pred,class='class 2'), aes(t_0, Ypred_class2,group = 1), color = "red", linetype = "dashed",size=1) +
  facet_grid(. ~ class) +   
  labs(x = "Days", y = "Fitness", col = "class") + 
  guides(col = guide_legend(nrow = 3),)
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint1_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)


survfit(Surv(t_min, t_max, status2) ~ class, data=df %>%
          select(ID2,t_min,t_max,status2,class) %>% unique()) %>%
  autoplot(xlab = "Days", ylab = "Survival probability")
ggsave(filename=gsub("src/analysis-scripts/","",
                      here("outputs",sprintf("joint2_%s.png",
                                             cond))),
        plot=last_plot(),width = 1000, height = 750, units = "px",dpi=150)},
error = function(cond_) {
            message(conditionMessage(cond_))
        }
)

```

##### 6.6.4.3. Two time windows Cox Model

Moreover a Cox survival model with two time windows is implemented below:

```{r}
#| label: 2 windows cox (cvd)
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
log_info("Create two windows cox {cond} model")
df <- df %>% 
  filter(t_max > 270) %>% 
  filter(t_0==270) %>% 
  select(ID,fitness,status2,age,age_,sex,copayment,charlson,ID2,t_min,t_max)
df$status3 <- ifelse(df$t_max<=630 & df$status2==1, 1, 0)
df$t_max <- pmin(df$t_max-270,360)

cox2w_cvd <- coxph(Surv(t_max, status3) ~ age + sex + fitness + charlson,
               data=df)

summary(cox2w_cvd)
```

## 7. Summary of prediction models

### 7.1. By adherence to process indicators

```{r}
#| label: tbl-modelsummary1
#| tbl-cap: "Process indicators models' summary. To interpret classes go to Figure 84"
#| tbl-colwidths: [60,40]
df_cond <- function(cond,m1,m2,m3,all){
  if(all){
  hazard_ratios <- data.frame(
  Group = c(rep(cond, 12)),
  Model = c(rep("Two time windows' Cox",4),rep("Time dependent Cox",4),rep("Joint latent class", 4)),
  n = c(m1$n,m1$n,m1$n,m1$n,m3$ns,m3$ns,
          m3$ns,m3$ns,m3$ns,m3$ns,m3$ns,m3$ns
  ),
  Variable = c("age", "sexMale", "fitness", "charlson", "age", "sexMale", "fitness", "charlson","age", "sexMale", "class1", "charlson"),
  HR = c(
    round(summary(m1)$conf.int[1,1],2),
    round(summary(m1)$conf.int[2,1],2),
    round(summary(m1)$conf.int[3,1],2),
    round(summary(m1)$conf.int[4,1],2),
    round(summary(m2)$conf.int[1,1],2),
    round(summary(m2)$conf.int[2,1],2),
    round(summary(m2)$conf.int[3,1],2),
    round(summary(m2)$conf.int[4,1],2),
    round(exp(coef(m3))[5],2),
    round(exp(coef(m3))[6],2),
    round(exp(coef(m3))[4],2),
    round(exp(coef(m3))[7],2)
  ),
    CI = c(
    paste0("(",round(summary(m1)$conf.int[1,3],2),",",
           round(summary(m1)$conf.int[1,4],2),")"),
    paste0("(",round(summary(m1)$conf.int[2,3],2),",",
           round(summary(m1)$conf.int[2,4],2),")"),
    paste0("(",round(summary(m1)$conf.int[3,3],2),",",
           round(summary(m1)$conf.int[3,4],2),")"),
    paste0("(",round(summary(m1)$conf.int[4,3],2),","
           ,round(summary(m1)$conf.int[4,4],2),")"),
    paste0("(",round(summary(m2)$conf.int[1,3],2),",",
           round(summary(m2)$conf.int[1,4],2),")"),
    paste0("(",round(summary(m2)$conf.int[2,3],2),",",
           round(summary(m2)$conf.int[2,4],2),")"),
    paste0("(",round(summary(m2)$conf.int[3,3],2),",",
           round(summary(m2)$conf.int[3,4],2),")"),
    paste0("(",round(summary(m2)$conf.int[4,3],2),",",
           round(summary(m2)$conf.int[4,4],2),")"),
    paste0("(",round(exp(confint(m3))[5,1],2),",",
       round(exp(confint(m3))[5,2],2),")"),
    paste0("(",round(exp(confint(m3))[6,1],2),",",
       round(exp(confint(m3))[6,2],2),")"),
    paste0("(",round(exp(confint(m3))[4,1],2),",",
       round(exp(confint(m3))[4,2],2),")"),
    paste0("(",round(exp(confint(m3))[7,1],2),",",
       round(exp(confint(m3))[7,2],2),")")
  )
  )
  } else {
  hazard_ratios <- data.frame(
  Group = c(rep(cond, 12)),
  Model = c(rep("Two time windows' Cox",4),rep("Time dependent Cox",4),rep("Joint latent class", 4)),
  n = c(m1$n,m1$n,m1$n,m1$n,"NaN","NaN",
          "NaN","NaN","NaN","NaN","NaN","NaN"
  ),
  Variable = c("age", "sexMale", "fitness", "charlson", "age", "sexMale", "fitness", "charlson","age", "sexMale", "class1", "charlson"),
  HR = c(
    round(summary(m1)$conf.int[1,1],2),
    round(summary(m1)$conf.int[2,1],2),
    round(summary(m1)$conf.int[3,1],2),
    round(summary(m1)$conf.int[4,1],2),
    round(summary(m2)$conf.int[1,1],2),
    round(summary(m2)$conf.int[2,1],2),
    round(summary(m2)$conf.int[3,1],2),
    round(summary(m2)$conf.int[4,1],2),
    '',
    '',
    '',
    ''
  ),
    CI = c(
    paste0("(",round(summary(m1)$conf.int[1,3],2),",",
           round(summary(m1)$conf.int[1,4],2),")"),
    paste0("(",round(summary(m1)$conf.int[2,3],2),",",
           round(summary(m1)$conf.int[2,4],2),")"),
    paste0("(",round(summary(m1)$conf.int[3,3],2),",",
           round(summary(m1)$conf.int[3,4],2),")"),
    paste0("(",round(summary(m1)$conf.int[4,3],2),","
           ,round(summary(m1)$conf.int[4,4],2),")"),
    paste0("(",round(summary(m2)$conf.int[1,3],2),",",
           round(summary(m2)$conf.int[1,4],2),")"),
    paste0("(",round(summary(m2)$conf.int[2,3],2),",",
           round(summary(m2)$conf.int[2,4],2),")"),
    paste0("(",round(summary(m2)$conf.int[3,3],2),",",
           round(summary(m2)$conf.int[3,4],2),")"),
    paste0("(",round(summary(m2)$conf.int[4,3],2),",",
           round(summary(m2)$conf.int[4,4],2),")"),
    '',
    '',
    '',
    ''
  )
  )
  }
  return(hazard_ratios)
}

results <- rbind(
  df_cond('No predominant condition',cox2w_else,time_dep_else,mj2else,exists('mj2else')),
  df_cond('Obesity',cox2w_ob,time_dep_ob,mj2ob,exists('mj2ob')),
  df_cond('Fragility',cox2w_f,time_dep_f,mj2f,exists('mj2f')),
  df_cond('Chronic kidney disease',cox2w_ckd,time_dep_ckd,mj2ckd,exists('mj2ckd')),
  df_cond('Heart failure',cox2w_hf,time_dep_hf,mj2hf,exists('mj2hf')),
  df_cond('Cardiovascular disease',cox2w_cvd,time_dep_cvd,mj2cvd,exists('mj2cvd')),
  df_cond('Process indicators',cox2w_PI,time_dep_PI,mj2PI,exists('mj2PI'))
) %>%
    mutate(
        Group = ifelse(row_number() == 1, Group, ifelse(Group == lag(Group), "", Group)),
        Model = ifelse(row_number() == 1, Model, ifelse(Model == lag(Model), "", Model)),
        n = ifelse(row_number() == 1, n, ifelse(n == lag(n), "", n))
    ) %>%
  rename('95% CI (LL,UL)' = CI)

kable(results[73:84,], row.names=FALSE, align=c("l", "l", rep("r",5)))

```

```{r}
#| label: get tbl-modelsummary2
#| eval: TRUE
#| echo: FALSE
#| warning: FALSE
#| output: TRUE
df_tab <- data.frame()
tryCatch(
{
df_pi$country <- ifelse(df_pi$country=='ESP', 'ESP', 'Others')
df_pi %>%
  mutate(copayment=factor(copayment,levels=c(0,1),
                    labels=c("less than 18000",
                             "more or equal than 18000"))) %>% select(ID,ID2,age,sex,copayment,charlson,t_max,
               class,initial_status,final_status,country) %>%
  distinct() %>%
  summary_factorlist("class",
                     c("age","sex","copayment","charlson","t_max",
                       "initial_status","final_status","country"),
                     total_col = TRUE,
                     cont="mean",
                     cont_cut=10,
                     na_include = TRUE,
                     na_to_prop =  FALSE,
                     include_col_totals_percent	=FALSE,
                     add_col_totals = TRUE)-> df_tab

},
error = function(e) {
            message(conditionMessage(e))
        }
)
```

```{r}
#| label: tbl-modelsummary2
#| tbl-cap: "Process indicators joint latent classes' summary. To interpret classes go to Figure 84."
#| tbl-colwidths: [60,40]
kable(df_tab, row.names=FALSE, align=c("l", "l", rep("r",5)))
```

::: {#fig-summary2 .column-page layout-ncol="2"}
![Process indicators' observed fitness trajectories of the patients (grey lines) a posteriori classified into the latent class with their mean fitness (points) and class-specidfic predicted fitness trajectory (red lines)](../../outputs/joint1_PI.png){#fig-pf1}

![Class-specific Kaplan-Meyer curves](../../outputs/joint2_PI.png){#fig-pf2}

Process Indicators' joint latent class model's plots panel
:::

### 7.2. By adherence to therapeutic guidelines

```{r}
#| label: tbl-modelsummary3
#| tbl-cap: "Models summary. To interpret classes go to Figure 85."
#| tbl-colwidths: [60,40]
kable(results[1:72,], row.names=FALSE, align=c("l", "l", rep("r",5)))
```

::: {#fig-summary .column-page layout-ncol="2"}
![Observed fitness trajectories of 'the'else' patients (grey lines) a posteriori classified into the latent class with their mean fitness (points) and class-specidfic predicted fitness trajectory (red lines)](../../outputs/joint1_else.png){#fig-elsef1}

!['else' patients' class-specific Kaplan-Meyer curves](../../outputs/joint2_else.png){#fig-elsef2}

![Observed fitness trajectories of obese patients (grey lines) a posteriori classified into the latent class with their mean fitness (points) and class-specidfic predicted fitness trajectory (red lines)](../../outputs/joint1_ob.png){#fig-obf1}

![Obese patients' class-specific Kaplan-Meyer curves](../../outputs/joint2_ob.png){#fig-obf2}

![Observed fitness trajectories of fragile patients (grey lines) a posteriori classified into the latent class with their mean fitness (points) and class-specidfic predicted fitness trajectory (red lines)](../../outputs/joint1_f.png){#fig-ff1}

![Fragile patients' class-specific Kaplan-Meyer curves](../../outputs/joint2_f.png){#fig-ff2}

![Observed fitness trajectories of ckd patients (grey lines) a posteriori classified into the latent class with their mean fitness (points) and class-specidfic predicted fitness trajectory (red lines)](../../outputs/joint1_ckd.png){#fig-ckdf1}

![ckd patients' class-specific Kaplan-Meyer curves](../../outputs/joint2_ckd.png){#fig-ckdf2}

![Observed fitness trajectories of hf patients (grey lines) a posteriori classified into the latent class with their mean fitness (points) and class-specidfic predicted fitness trajectory (red lines)](../../outputs/joint1_hf.png){#fig-hff1}

![hf patients' class-specific Kaplan-Meyer curves](../../outputs/joint2_hf.png){#fig-hff2}

![Observed fitness trajectories of cvd patients (grey lines) a posteriori classified into the latent class with their mean fitness (points) and class-specidfic predicted fitness trajectory (red lines)](../../outputs/joint1_cvd.png){#fig-cvdf1}

![cvd patients' class-specific Kaplan-Meyer curves](../../outputs/joint2_cvd.png){#fig-cvdf2}

Treatments' joint latent class models' plots panel
:::

## 8. Concept-Cost

```{python}
#| label: Get concept-cost table
con = duckdb.connect(db_path)

con.sql("SELECT DISTINCT trace,\
           COUNT(person) OVER (PARTITION BY trace) AS freq_trace, \
           AVG(duration_in_days) OVER (PARTITION BY trace) AS duration_mean, \
           quantile_cont(duration_in_days,0.5) OVER (PARTITION BY trace) AS duration_median, \
           STDDEV_POP(duration_in_days) OVER (PARTITION BY trace) AS duration_standard_error, \
           quantile_cont(duration_in_days,0.75) OVER (PARTITION BY trace) - \
               quantile_cont(duration_in_days,0.25) OVER (PARTITION BY trace) AS duration_iqr \
           FROM (select patient_id as person,STRING_AGG(health_service, ',' order by visit_date) as trace,\
             MIN(visit_date) as start_timestamp, MAX(visit_date) as complete_timestamp,\
             DATEDIFF('day',MIN(visit_date), MAX(visit_date)) as 'duration_in_days' \
             from ( \
             select *,ROW_NUMBER() over (order by patient_id,visit_date) as o \
             from (select patient_id,visit_date,case \
             when visit_type==1 and visit_loc==1 and visit_service=='APR' then 'general_practitioner_visit' \
             when visit_type==1 and visit_loc==2 and visit_service=='APR' then 'general_practitioner_visit_home_visit' \
             when visit_type==2 and visit_loc==1 and visit_service=='APR' then 'nurse_visit_first_visit' \
             when visit_type==2 and visit_loc==2 and visit_service=='APR' then 'nurse_visit_home_visit' \
             when visit_type==4 and visit_service=='APR' then 'accident_&_emergency_visit_health_center' \
             when visit_service=='CAR' then 'cardiology_visit' \
             when visit_service=='ALG' then 'allergology_visit' \
             when visit_service=='APA' then 'pathological_anatomy_visit' \
             when visit_service=='ANG' then 'angiology_visit_process_not_specified' \
             when visit_service=='DIG' then 'digestive_system_visit_process_not_specified' \
             when visit_service=='CCA' then 'cardiovascular_surgery_visit_process_not_specified' \
             when visit_service=='CIR' then 'general_surgery_visit_process_not_specified' \
             when visit_service=='CMF' then 'maxillofacial_surgery_visit_process_not_specified' \
             when visit_service=='TRA' then 'orthopedic_surgery_visit_process_not_specified' \
             when visit_service=='CPL' then 'plastic_surgery_visit_process_not_specified' \
             when visit_service=='DER' then 'dermatology_visit_process_not_specified' \
             when visit_service=='_____' then 'diagnostic_imaging_visit_process_not_specified' \
             when visit_service=='END' then 'endrocrinology_visit_process_not_specified' \
             when visit_service=='GRT' then 'geriatrics_visit_process_not_specified' \
             when visit_service=='HEM' then 'hematology_visit_process_not_specified' \
             when visit_service=='REH' then 'rehabilitation_service_visit_process_not_specified' \
             when visit_service=='MIR' then 'internal_medicine_visit_process_not_specified' \
             when visit_service=='NEF' then 'nephrology_visit_process_not_specified' \
             when visit_service=='NML' then 'pneumology_visit_process_not_specified' \
             when visit_service=='NRC' then 'neurosurgeon_visit_process_not_specified' \
             when visit_service=='NRL' then 'neurology_visit_process_not_specified' \
             when visit_service=='OBG' then 'obstetrics_visit_process_not_specified' \
             when visit_service=='_____' then 'dentistry_visit_process_not_specified' \
             when visit_service=='OFT' then 'ophthalmology_visit_process_not_specified' \
             when visit_service=='ORL' then 'otorhinolaryngologist_visit_process_not_specified' \
             when visit_service=='PSQ' then 'psychiatry_visit_process_not_specified' \
             when visit_service=='_____' then 'psycologist_visit' \
             when visit_service=='RDT' then 'radiotherapy_visit_process_not_specified' \
             when visit_service=='RAD' then 'radiology_visit_process_not_specified' \
             when visit_service=='REU' then 'rheumatology_visit_process_not_specified' \
             when visit_service=='URO' then 'urology_visit_process_not_specified' \
             when visit_service=='_____' then 'laboratory' \
             else 'specialist_visit'   end as health_service \
             from main.ss_use where health_service!='OTROS' \
             union all select patient_id, admission_date as visit_date, case \
             when contact_type==4 then 'minor_ambulatory_surgery' \
             when contact_type==5 then 'major_ambulatory_surgery' \
             when contact_type==6 then 'accident_&_emergency_visit_hospital' \
             else 'OTROS' end as health_service \
             from main.cmbd where health_service!='OTROS' \
             union all select distinct patient_id, param_date as visit_date, \
             'laboratory' as health_service from main.param \
             where param_name in ('col','hdl','ldl','hba1c') \
             union all SELECT patient_id, date AS visit_date, 'day_of_hospitalization' AS health_service FROM \
             (SELECT patient_id, unnest(date) AS date, contact_type FROM \
             (SELECT patient_id, date, contact_type \
             FROM (SELECT patient_id, \
             generate_series(admission_date, discharge_date, interval '1 day') AS date, contact_type \
             FROM main.cmbd WHERE contact_type IN (1,3)) AS expanded_activities \
             ORDER BY patient_id, date) AS expanded_dates ORDER BY patient_id, date) )\
             ) group by person order by person)"
             ).df().to_csv('../../outputs/aggregated_traces.csv',index=False)

con.close()

```

